{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf #tensorflow\n",
    "import numpy as np #numpy > save loss .. \n",
    "from collections import OrderedDict #layer ..\n",
    "import os, random #dir, random..\n",
    "import pickle #save & load\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path\n",
    "DATA_PATH = 'cifar10/cifar-10-batches-py/'\n",
    "CHECKPOINT = 'simple_res_net_0525.ckpt'\n",
    "SAVE_PATH = 'checkpoint/simple_res_net/'\n",
    "BOARD_PATH = './tensorboard/board_res_net'\n",
    "\n",
    "#parameters\n",
    "\n",
    "INPUT_SIDE = 32\n",
    "INPUT_SIZE = INPUT_SIDE * INPUT_SIDE\n",
    "N_CHANNEL = 3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 10000\n",
    "LR = 0.01\n",
    "LR_DECAY_RATE = 0.5\n",
    "\n",
    "LIST_CLASS=['airplane', 'automobile', 'birds', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "N_CLASSES = len(LIST_CLASS)\n",
    "\n",
    "#train&test batch\n",
    "train_file=['data_batch_1','data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5']\n",
    "test_file=['cifar10/cifar-10-batches-py/test_batch']\n",
    "\n",
    "#input & output \n",
    "#x = tf.placeholder(\"float\", [BATCH_SIZE, INPUT_SIZE * N_CHANNEL]) #batch x image size\n",
    "#y = tf.placeholder(\"float\", [BATCH_SIZE, N_CLASSES]) #batch x class`\n",
    "\n",
    "#loss & accuracy save (pickle)\n",
    "OUT_FILE_NAME = 'RES_NET_CIFAR10_0525.txt'\n",
    "loss_out = open('LOSS'+OUT_FILE_NAME, 'w')\n",
    "accr_out = open('ACCURACY'+OUT_FILE_NAME, 'w')\n",
    "\n",
    "\n",
    "print(\"input image size : {}\".format(INPUT_SIZE))\n",
    "print(\"image channel : {}\".format(N_CHANNEL))\n",
    "print(\"batch size : {}\".format(BATCH_SIZE))\n",
    "print(\"num of class : {}\".format(N_CLASSES))\n",
    "print(\"training epochs : {}\".format(EPOCHS))\n",
    "print(\"learning rate : {}\".format(LR))\n",
    "print(\"learning decay rate : {}\".format(LR_DECAY_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#npz - python numpy 파일 포맷. > dictionary로 불러옴 (Save several arrays into a single file in uncompressed .npz format)\n",
    "def load_npz(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "    \n",
    "## Make batch_iterator for npz data\n",
    "def make_batch_index(_data, batch_size=128, allow_small_batch=True):\n",
    "    num_images = len(_data[b'data']) #데이터 갯수\n",
    "    start_idx = list(range(0, num_images, batch_size)) #각 배치별 시작 인덱스 리스트\n",
    "    end_idx = list(range(batch_size, num_images + 1, batch_size))#각 배치별 끝 인덱스 \n",
    "    if allow_small_batch and end_idx[-1] < num_images : #스몰배치 허용시 마지막 배치\n",
    "        start_idx.append(end_idx[-1])\n",
    "        end_idx.append(num_images)\n",
    "    return zip(start_idx, end_idx)\n",
    "\n",
    "#one hot encoding\n",
    "def one_hot_encode(x, numclass):\n",
    "    return np.eye(numclass)[x] #numclass 크기의 항등행렬 생성 \n",
    "\n",
    "#############################################################################################################\n",
    "######################################아래는 방식변환중\n",
    "#############################################################################################################\n",
    "\n",
    "#CIFAR 데이터 읽어오기 \n",
    "def read_dataset(filename_queue):\n",
    "    class DataRecord(object):\n",
    "        pass\n",
    "    \n",
    "    result = DataRecord()\n",
    "    \n",
    "    label_bytes = 1\n",
    "    result.height = 32\n",
    "    result.width = 32\n",
    "    result.depth = 3\n",
    "    image_bytes = result.height * result.width * result.depth\n",
    "    record_bytes = label_bytes + image_bytes\n",
    "    \n",
    "    reader = tf.FixedLengthRecordReader(record_bytes = record_bytes)\n",
    "    result.key, value = reader.read(filename_queue)\n",
    "    print (value)\n",
    "    record_bytes = tf.decode_raw(value, tf.uint8)\n",
    "    \n",
    "    result.label = tf.cast(tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32) #input, begin, end로 잘라냄 > 0~1\n",
    "    \n",
    "    depth_major = tf.reshape(tf.strided_slice(record_bytes, [label_bytes], # 1부터 image_bytes까지 image를 잘라낸 후 \n",
    "                                              [label_bytes + image_bytes]), #channel x height x width로 변환함.\n",
    "                             [result.depth, result.height, result.width])\n",
    "    \n",
    "    result.uint8image = tf.transpose(depth_major, [1,2,0]) #channel x height x width >>> height x width x chennl로 변경\n",
    "    \n",
    "    return result\n",
    "\n",
    "#label, image 세팅해줌 \n",
    "def _generate_image_and_label_batch(image, label, min_queue_examples,\n",
    "                                    batch_size, shuffle):\n",
    "    \"\"\"Construct a queued batch of images and labels.\n",
    "    Args:\n",
    "      image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "      label: 1-D Tensor of type.int32\n",
    "      min_queue_examples: int32, minimum number of samples to retain\n",
    "        in the queue that provides of batches of examples.\n",
    "      batch_size: Number of images per batch.\n",
    "      shuffle: boolean indicating whether to use a shuffling queue.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    # Create a queue that shuffles the examples, and then\n",
    "    # read 'batch_size' images + labels from the example queue.\n",
    "    num_preprocess_threads = 16 #프로세스 스레드 \n",
    "    if shuffle: #셔플 하면 \n",
    "        images, label_batch = tf.train.shuffle_batch([image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size,\n",
    "            min_after_dequeue=min_queue_examples) #이거만 해주면 batch와 동일함. \n",
    "    #Minimum number elements in the queue after a dequeue, used to ensure a level of mixing of elements.\n",
    "    else:\n",
    "        images, label_batch = tf.train.batch([image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "    # Display the training images in the visualizer.\n",
    "    tf.summary.image('images', images) #걍 보드용인듯\n",
    "\n",
    "    return images, tf.reshape(label_batch, [batch_size])\n",
    "\n",
    "\n",
    "def distorted_inputs(data_dir, batch_size): #좀 드럽게 인풋받아오기 \n",
    "    \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "    Args:\n",
    "      data_dir: Path to the CIFAR-10 data directory.\n",
    "      batch_size: Number of images per batch.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    filenames = [os.path.join(data_dir, 'data_batch_%d' % i) for i in range(1, 6)] \n",
    "    for f in filenames:\n",
    "        if not tf.gfile.Exists(f):\n",
    "            raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "    # Create a queue that produces the filenames to read.\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "    # Read examples from files in the filename queue.\n",
    "    read_input = read_dataset(filename_queue)\n",
    "    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "    height = 32\n",
    "    width = 32\n",
    "\n",
    "    # Image processing for training the network.  Note the many random\n",
    "    # distortions applied to the image.\n",
    "\n",
    "    # Randomly crop a [height, width] section of the image.\n",
    "    distorted_image = tf.random_crop(reshaped_image, [height, width, 3])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "\n",
    "    # Because these operations are not commutative, consider randomizing\n",
    "    # the order their operation.\n",
    "    distorted_image = tf.image.random_brightness(distorted_image,\n",
    "                                               max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(distorted_image,\n",
    "                                             lower=0.2, upper=1.8)\n",
    "\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    float_image = tf.image.per_image_standardization(distorted_image)\n",
    "\n",
    "    # Set the shapes of tensors.\n",
    "    float_image.set_shape([height, width, 3])\n",
    "    read_input.label.set_shape([1])\n",
    "\n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * min_fraction_of_examples_in_queue)\n",
    "    print('Filling queue with %d CIFAR images before starting to train. '\n",
    "         'This will take a few minutes.' % min_queue_examples)\n",
    "\n",
    "    # Generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(float_image, read_input.label,\n",
    "                                         min_queue_examples, batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "print(\"FUNCTIONS READY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NETWORK PARAMETERS\n",
    "\n",
    "stddev = 0.1\n",
    "\n",
    "weights = {\n",
    "     'conv' : tf.Variable(tf.random_normal([3, 3, N_CHANNEL, 16], stddev=stddev), name='conv'),\n",
    "    'conv1_1x1' : tf.Variable(tf.random_normal([1, 1, 16, 4], stddev=stddev, name='conv1_1x1')),\n",
    "    'conv1_3x3' : tf.Variable(tf.random_normal([3, 3, 4, 4], stddev=stddev, name='conv1_3x3')),\n",
    "    'conv1_1x1_16' : tf.Variable(tf.random_normal([1, 1, 4, 16], stddev=stddev, name='conv1_1x1_16')),\n",
    "    'conv2_1x1' : tf.Variable(tf.random_normal([1, 1, 16, 4], stddev=stddev, name='conv2_1x1')),\n",
    "    'conv2_3x3' : tf.Variable(tf.random_normal([3, 3, 4, 4], stddev=stddev, name='conv2_3x3')),\n",
    "    'conv2_1x1_16' : tf.Variable(tf.random_normal([1, 1, 4, 16], stddev=stddev, name='conv2_1x1_16')),\n",
    "    \n",
    "    # conv 16 + conv2 16 = 32filters \n",
    "    \n",
    "    'conv3_1x1' : tf.Variable(tf.random_normal([1, 1, 32, 8], stddev=stddev, name='conv3_1x1')),\n",
    "    'conv3_3x3' : tf.Variable(tf.random_normal([3, 3, 8, 8], stddev=stddev, name='conv3_3x3')),\n",
    "    'conv3_1x1_32' : tf.Variable(tf.random_normal([1, 1, 8, 32], stddev=stddev, name='conv3_1x1_32')),\n",
    "    'conv4_1x1' : tf.Variable(tf.random_normal([1, 1, 32, 8], stddev=stddev, name='conv4_1x1')),\n",
    "    'conv4_3x3' : tf.Variable(tf.random_normal([3, 3, 8, 8], stddev=stddev, name='conv4_3x3')),\n",
    "    'conv4_1x1_32' : tf.Variable(tf.random_normal([1, 1, 8, 32], stddev=stddev, name='conv4_1x1_32')),\n",
    "    \n",
    "    # conv2 지난거32 + conv4 32 = 64\n",
    "    \n",
    "    'conv5_1x1' : tf.Variable(tf.random_normal([1, 1, 64, 16], stddev=stddev, name='conv5_1x1')),\n",
    "    'conv5_3x3' : tf.Variable(tf.random_normal([3, 3, 16, 16], stddev=stddev, name='conv5_3x3')),\n",
    "    'conv5_1x1_64' : tf.Variable(tf.random_normal([1, 1, 16, 64], stddev=stddev, name='conv5_1x1_64')),\n",
    "    'conv6_1x1' : tf.Variable(tf.random_normal([1, 1, 64, 16], stddev=stddev, name='conv6_1x1')),\n",
    "    'conv6_3x3' : tf.Variable(tf.random_normal([3, 3, 16, 16], stddev=stddev, name='conv6_3x3')),\n",
    "    'conv6_1x1_64' : tf.Variable(tf.random_normal([1, 1, 16, 64], stddev=stddev, name='conv6_1x1_64')),\n",
    "    \n",
    "    #conv4 지난거 64 + conv6 64 = 128\n",
    "    \n",
    "    'dense1' : tf.Variable(tf.random_normal([16*16*128, 1000], stddev=stddev, name='dense1')),\n",
    "    'dense2' : tf.Variable(tf.random_normal([1000, N_CLASSES], stddev=stddev, name='dense2'))    \n",
    "}\n",
    "biases = {\n",
    "    'conv' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv_b')),\n",
    "    'conv1_1x1' : tf.Variable(tf.random_normal([4], stddev=stddev, name='conv1_1x1_b')),\n",
    "    'conv1_3x3' : tf.Variable(tf.random_normal([4], stddev=stddev, name='conv1_3x3_b')),\n",
    "    'conv1_1x1_16' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv1_1x1_16_b')),\n",
    "    'conv2_1x1' : tf.Variable(tf.random_normal([4], stddev=stddev, name='conv2_1x1_b')),\n",
    "    'conv2_3x3' :tf.Variable(tf.random_normal([4], stddev=stddev, name='conv2_3x3_b')),\n",
    "    'conv2_1x1_16' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv2_1x1_16_b')),\n",
    "    \n",
    "    'conv3_1x1' : tf.Variable(tf.random_normal([8], stddev=stddev, name='conv3_1x1_b')),\n",
    "    'conv3_3x3' : tf.Variable(tf.random_normal([8], stddev=stddev, name='conv3_3x3_b')),\n",
    "    'conv3_1x1_32' : tf.Variable(tf.random_normal([32], stddev=stddev, name='conv3_1x1_32_b')),\n",
    "    'conv4_1x1' : tf.Variable(tf.random_normal([8], stddev=stddev, name='conv4_1x1_b')),\n",
    "    'conv4_3x3' : tf.Variable(tf.random_normal([8], stddev=stddev, name='conv4_3x3_b')),\n",
    "    'conv4_1x1_32' : tf.Variable(tf.random_normal([32], stddev=stddev, name='conv4_1x1_32_b')),\n",
    "    \n",
    "    'conv5_1x1' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv5_1x1_b')),\n",
    "    'conv5_3x3' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv5_3x3_b')),\n",
    "    'conv5_1x1_64' : tf.Variable(tf.random_normal([64], stddev=stddev, name='conv5_1x1_64_b')),\n",
    "    'conv6_1x1' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv6_1x1_b')),\n",
    "    'conv6_3x3' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv6_3x3_b')),\n",
    "    'conv6_1x1_64' : tf.Variable(tf.random_normal([64], stddev=stddev, name='conv6_1x1_64_b')),\n",
    "    \n",
    "    'dense1' : tf.Variable(tf.random_normal([1000], stddev=stddev, name='dense1_b')),\n",
    "    'dense2' : tf.Variable(tf.random_normal([N_CLASSES], stddev=stddev, name='dense2_b'))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model\n",
    "#http://laonple.blog.me/220764986252 - bottleneck \n",
    "#conv 3x3\n",
    "#conv (1x1, 3x3, 1x1) - relu > 16\n",
    "#conv (1x1, 3x3, 1x1) relu > 32\n",
    "#conv (1x1, 3x3, 1x1) relu > 64\n",
    "#avg pooling \n",
    "#fc\n",
    "#softmax\n",
    "def ResNet(img_width, img_height, img_channel, _x, _w, _b, scope='ResNet'):\n",
    "    network = OrderedDict() #network layers\n",
    "\n",
    "    # X RESHAPE\n",
    "    _x_r = tf.reshape(_x, shape=[-1,img_width,img_height, img_channel])\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        with tf.name_scope('conv') as scope:\n",
    "            conv = tf.nn.conv2d(_x_r, _w['conv'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv = tf.nn.bias_add(conv, _b['conv'])\n",
    "            conv = tf.nn.relu(conv)\n",
    "            network['conv'] = conv\n",
    "        \n",
    "        #16\n",
    "        with tf.name_scope('conv2') as scope:\n",
    "            conv1_1x1 = tf.nn.conv2d(conv, _w['conv1_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv1_1x1 = tf.nn.bias_add(conv1_1x1, _b['conv1_1x1'])\n",
    "            conv1_1x1 = tf.nn.relu(conv1_1x1)\n",
    "            conv1_3x3 = tf.nn.conv2d(conv1_1x1, _w['conv1_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv1_3x3 = tf.nn.bias_add(conv1_3x3, _b['conv1_3x3'])\n",
    "            conv1_3x3 = tf.nn.relu(conv1_3x3)\n",
    "            conv1_1x1_16 = tf.nn.conv2d(conv1_3x3, _w['conv1_1x1_16'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv1_1x1_16 = tf.nn.bias_add(conv1_1x1_16, _b['conv1_1x1_16'])\n",
    "            conv1_1x1_16 = tf.nn.relu(conv1_1x1_16)\n",
    "            network['conv1_1x1_16'] = conv1_1x1_16\n",
    "        \n",
    "        #16\n",
    "        with tf.name_scope('conv3') as scope:\n",
    "            conv2_1x1 = tf.nn.conv2d(conv1_1x1_16, _w['conv2_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv2_1x1 = tf.nn.bias_add(conv2_1x1, _b['conv2_1x1'])\n",
    "            conv2_1x1 = tf.nn.relu(conv2_1x1)\n",
    "            conv2_3x3 = tf.nn.conv2d(conv2_1x1, _w['conv2_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv2_3x3 = tf.nn.bias_add(conv2_3x3, _b['conv2_3x3'])\n",
    "            conv2_3x3 = tf.nn.relu(conv2_3x3)\n",
    "            conv2_1x1_16 = tf.nn.conv2d(conv2_3x3, _w['conv2_1x1_16'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv2_1x1_16 = tf.nn.bias_add(conv2_1x1_16, _b['conv2_1x1_16'])\n",
    "            #print(conv2_1x1_16.shape)\n",
    "            #32\n",
    "            conv2_1x1_16 = tf.concat([conv, conv2_1x1_16], 3) \n",
    "            conv2_1x1_16 = tf.nn.relu(conv2_1x1_16)\n",
    "            network['conv2_1x1_16'] = conv2_1x1_16\n",
    "       \n",
    "        #print(conv2_1x1_16.shape)\n",
    "        #32       32 x 32 x 16+16 >>> \n",
    "        with tf.name_scope('conv4') as scope:\n",
    "            conv3_1x1 = tf.nn.conv2d(conv2_1x1_16, _w['conv3_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv3_1x1 = tf.nn.bias_add(conv3_1x1, _b['conv3_1x1'])\n",
    "            conv3_1x1 = tf.nn.relu(conv3_1x1)\n",
    "            conv3_3x3 = tf.nn.conv2d(conv3_1x1, _w['conv3_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv3_3x3 = tf.nn.bias_add(conv3_3x3, _b['conv3_3x3'])\n",
    "            conv3_3x3 = tf.nn.relu(conv3_3x3)\n",
    "            conv3_1x1_32 = tf.nn.conv2d(conv3_3x3, _w['conv3_1x1_32'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv3_1x1_32 = tf.nn.bias_add(conv3_1x1_32, _b['conv3_1x1_32'])\n",
    "            conv3_1x1_32 = tf.nn.relu(conv3_1x1_32)\n",
    "            network['conv3_1x1_32'] = conv3_1x1_32\n",
    "        \n",
    "        with tf.name_scope('conv5') as scope:\n",
    "            conv4_1x1 = tf.nn.conv2d(conv3_1x1_32, _w['conv4_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv4_1x1 = tf.nn.bias_add(conv4_1x1, _b['conv4_1x1'])\n",
    "            conv4_1x1 = tf.nn.relu(conv4_1x1)\n",
    "            conv4_3x3 = tf.nn.conv2d(conv4_1x1, _w['conv4_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv4_3x3 = tf.nn.bias_add(conv4_3x3, _b['conv4_3x3'])\n",
    "            conv4_3x3 = tf.nn.relu(conv4_3x3)\n",
    "            conv4_1x1_32 = tf.nn.conv2d(conv4_3x3, _w['conv4_1x1_32'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv4_1x1_32 = tf.nn.bias_add(conv4_1x1_32, _b['conv4_1x1_32'])\n",
    "\n",
    "            #64\n",
    "            conv4_1x1_32 = tf.concat([conv2_1x1_16, conv4_1x1_32 ], 3)\n",
    "            conv4_1x1_32 = tf.nn.relu(conv4_1x1_32)\n",
    "            network['conv4_1x1_32'] = conv4_1x1_32\n",
    "    \n",
    "        with tf.name_scope('conv6') as scope:\n",
    "            conv5_1x1 = tf.nn.conv2d(conv4_1x1_32, _w['conv5_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv5_1x1 = tf.nn.bias_add(conv5_1x1, _b['conv5_1x1'])\n",
    "            conv5_1x1 = tf.nn.relu(conv5_1x1)\n",
    "            conv5_3x3 = tf.nn.conv2d(conv5_1x1, _w['conv5_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv5_3x3 = tf.nn.bias_add(conv5_3x3, _b['conv5_3x3'])\n",
    "            conv5_3x3 = tf.nn.relu(conv5_3x3)\n",
    "            conv5_1x1_64 = tf.nn.conv2d(conv5_3x3, _w['conv5_1x1_64'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv5_1x1_64 = tf.nn.bias_add(conv5_1x1_64, _b['conv5_1x1_64'])\n",
    "            conv5_1x1_64 = tf.nn.relu(conv5_1x1_64)\n",
    "            network['conv5_1x1_64'] = conv5_1x1_64\n",
    "        \n",
    "        with tf.name_scope('conv7') as scope:\n",
    "            conv6_1x1 = tf.nn.conv2d(conv5_1x1_64, _w['conv6_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv6_1x1 = tf.nn.bias_add(conv6_1x1, _b['conv6_1x1'])\n",
    "            conv6_1x1 = tf.nn.relu(conv6_1x1)\n",
    "            conv6_3x3 = tf.nn.conv2d(conv6_1x1, _w['conv6_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv6_3x3 = tf.nn.bias_add(conv6_3x3, _b['conv6_3x3'])\n",
    "            conv6_3x3 = tf.nn.relu(conv6_3x3)\n",
    "            conv6_1x1_64 = tf.nn.conv2d(conv6_3x3, _w['conv6_1x1_64'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv6_1x1_64 = tf.nn.bias_add(conv6_1x1_64, _b['conv6_1x1_64'])\n",
    "\n",
    "            #128\n",
    "            conv6_1x1_64 = tf.concat([conv4_1x1_32, conv6_1x1_64],3)\n",
    "            conv6_1x1_64 = tf.nn.relu(conv6_1x1_64)\n",
    "            network['conv6_1x1_64'] = conv6_1x1_64\n",
    "        \n",
    "        with tf.name_scope('pool') as scope:\n",
    "            pool = tf.nn.avg_pool(conv6_1x1_64, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "            network['pool'] = pool\n",
    "        \n",
    "        with tf.name_scope('dense1') as scope:\n",
    "            dense = tf.reshape(pool, [-1, _w['dense1'].get_shape().as_list()[0]])\n",
    "            dense1 = tf.add(tf.matmul(dense, _w['dense1']), _b['dense1'])\n",
    "            dense1 = tf.nn.relu(dense1)\n",
    "            network['dense1'] = dense1\n",
    "            \n",
    "        with tf.name_scope('logit') as scope:\n",
    "            logit = tf.add(tf.matmul(dense1, _w['dense2']), _b['dense2'])\n",
    "            network['logit'] = logit\n",
    "        \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHECK LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images, labels = distorted_inputs('cifar10/cifar-10-batches-py/', 64)\n",
    "print(images.shape)\n",
    "labels = tf.cast(labels, tf.int64)\n",
    "print(labels.shape)\n",
    "\n",
    "out = ResNet(INPUT_SIDE, INPUT_SIDE, N_CHANNEL, images, weights, biases, 'ResNet')\n",
    "for key, value in out.items():\n",
    "    print (key, value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SESSION / SAVER / TENSORBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SESSION INITIALIZE\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "#SAVER\n",
    "saver = tf.train.Saver(max_to_keep=3) #최근 3개까지만 저장\n",
    "save_step = 100 #save for 100 epoch\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "    \n",
    "#restore checkpoint\n",
    "checkpoint = tf.train.latest_checkpoint(SAVE_PATH)\n",
    "if checkpoint is not None:\n",
    "    print(checkpoint)\n",
    "    #saver.restore(sess, checkpoint)\n",
    "    \n",
    "#TENSOR BOARD\n",
    "summary_op = tf.summary.merge_all()\n",
    "summary_writer = tf.summary.FileWriter(BOARD_PATH, sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSS & OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=out['logit']))\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "print(\"LOSS FUNCTION\")\n",
    "\n",
    "#learning rate\n",
    "global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "learning_rate = tf.train.exponential_decay(learning_rate=LR,\n",
    "                                           global_step=global_step,\n",
    "                                           decay_steps=500,\n",
    "                                           decay_rate=LR_DECAY_RATE,\n",
    "                                           staircase=True,\n",
    "                                           name=\"learning_rate\")\n",
    "learning_rate = tf.maximum(learning_rate, 0.0001)\n",
    "tf.summary.scalar(\"learning_rate\", learning_rate)\n",
    "print(\"LERANING RATE : {}\".format(learning_rate))\n",
    "\n",
    "#optimizer\n",
    "adam = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "sgd = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "#print(\"OPTIMIZER 1 : {}\".format(adam))\n",
    "#print(\"OPTIMIZER 2 : {}\".format(sgd))\n",
    "\n",
    "corr = tf.equal(tf.argmax(out['logit'], 1), tf.argmax(labels,1))\n",
    "accr = tf.reduce_mean(tf.cast(corr, \"float\"))\n",
    "tf.summary.scalar(\"accuracy\", accr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training\n",
    "loss_for_plot = []\n",
    "acc_for_plot = []\n",
    "print('start')\n",
    "for epoch in range(EPOCHS):\n",
    "    print(epoch)\n",
    "    sample_list_new = random.sample(train_file, len(train_file)) #변환할 부분 - training file shuffle\n",
    "    nNumBatch = 0 #배치수\n",
    "    AvgBatchCost = 0 #batch cost\n",
    "    \n",
    "    #for index, file_name in enumerate(sample_list_new): #sample file list 돌면서 index, filename을 받아온다\n",
    "        #file_name = DATA_PATH + file_name #해당 파일 이름\n",
    "        #load_data = load_npz(file_name) #해당 파일 이름으로 불러온다. \n",
    "        #batch_index = make_batch_index(load_data, BATCH_SIZE, False) #배치의 시작과 끝 인덱스를 zip으로 받아온다. \n",
    "        \n",
    "    #for start, end in batch_index:\n",
    "            #batch_xs = load_data[b'data'][start:end] #start~end까지의 x데이터(image)를 준비\n",
    "            #batch_ys = one_hot_encode(load_data[b'labels'][start:end], N_CLASSES) # label을 원핫인코딩으로 변환해줌. \n",
    "            #print(batch_xs.shape)\n",
    "            #feed_dictionary = {x : batch_xs, y : batch_ys} #feed dict에 x, y준비\n",
    "\n",
    "            #실제 실행 -> optimizer 고를듯..\n",
    "            #sess.run(adam, feed_dict = feed_dictionary)\n",
    "    nNumBatch += 1\n",
    "    if epoch < EPOCHS*0.5:\n",
    "        _, tmp_cost = sess.run([adam, loss]) #optimizer는 결과값중요하지 않으니 _로 받고, cost를 받음\n",
    "    else:\n",
    "        _, tmp_cost = sess.run([sgd, loss]) \n",
    "            \n",
    "    AvgBatchCost += tmp_cost\n",
    "            \n",
    "        #매 배치가 끝난 후 \n",
    "    if nNumBatch % 100 == 0: #100개 배치마다 출력\n",
    "            train_acc = sess.run(accr)\n",
    "            print('\\t[%d nNumBatch] train_cost = %g, acc = %g'%(nNumBatch, AvgBatchCost/nNumBatch, train_acc))\n",
    "            loss_for_plot.append(AvgBatchCost/nNumBatch)\n",
    "            acc_for_plot.append(train_acc)\n",
    "\n",
    "        \n",
    "    if epoch % 10 == 0: #10epoch마다 테스트데이터를 이용해 테스트\n",
    "        save_path = saver.save(sess, SAVE_PATH+CHECKPOINT, global_step=epoch) #10epoch마다 저장\n",
    "        print(save_path)\n",
    "        test_acc = 0\n",
    "        avg_acc = 0\n",
    "        num_batch = 0\n",
    "        load_testdata=load_npz(test_file[0]) #test를 위한 테스트에디터 로드\n",
    "        \n",
    "        testdata_label = one_hot_encode(load_testdata[b'labels'], N_CLASSES)\n",
    "        test_batch_index = make_batch_index(load_testdata, BATCH_SIZE, False)\n",
    "\n",
    "        for start, end in test_batch_index:\n",
    "            num_batch += 1\n",
    "            batch_xs = load_testdata[b'data'][start:end]\n",
    "            batch_ys = one_hot_encode(load_testdata[b'labels'][start:end], N_CLASSES)\n",
    "            test_acc = sess.run(accr, feed_dict={x:batch_xs,y:batch_ys})\n",
    "            avg_acc += test_acc\n",
    "            \n",
    "        print('[%d epoch]test acc=%g'%(epoch, avg_acc/num_batch))\n",
    "        summary_writer.add_summary(avg_acc/num_batch ,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(loss_for_plot, file=loss_out)\n",
    "print(acc_for_plot, file=accr_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train():\n",
    "    \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "\n",
    "        # Get images and labels for CIFAR-10.\n",
    "        images, labels = distorted_inputs()\n",
    "\n",
    "        # Build a Graph that computes the logits predictions from the\n",
    "        # inference model.\n",
    "        logits = cifar10.inference(images)\n",
    "\n",
    "        # Calculate loss.\n",
    "        loss = cifar10.loss(logits, labels)\n",
    "\n",
    "        # Build a Graph that trains the model with one batch of examples and\n",
    "        # updates the model parameters.\n",
    "        train_op = cifar10.train(loss, global_step)\n",
    "\n",
    "        class _LoggerHook(tf.train.SessionRunHook):\n",
    "            \"\"\"Logs loss and runtime.\"\"\"\n",
    "\n",
    "            def begin(self):\n",
    "                self._step = -1\n",
    "                self._start_time = time.time()\n",
    "\n",
    "            def before_run(self, run_context):\n",
    "                self._step += 1\n",
    "                return tf.train.SessionRunArgs(loss)  # Asks for loss value.\n",
    "\n",
    "            def after_run(self, run_context, run_values):\n",
    "                if self._step % FLAGS.log_frequency == 0:\n",
    "                    current_time = time.time()\n",
    "                    duration = current_time - self._start_time\n",
    "                    self._start_time = current_time\n",
    "\n",
    "                    loss_value = run_values.results\n",
    "                    examples_per_sec = FLAGS.log_frequency * FLAGS.batch_size / duration\n",
    "                    sec_per_batch = float(duration / FLAGS.log_frequency)\n",
    "\n",
    "                    format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
    "                                'sec/batch)')\n",
    "                    print (format_str % (datetime.now(), self._step, loss_value,\n",
    "                                       examples_per_sec, sec_per_batch))\n",
    "\n",
    "        with tf.train.MonitoredTrainingSession(\n",
    "            checkpoint_dir=FLAGS.train_dir,\n",
    "            hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),\n",
    "                   tf.train.NanTensorHook(loss),\n",
    "                   _LoggerHook()],\n",
    "            config=tf.ConfigProto(log_device_placement=FLAGS.log_device_placement)) as mon_sess:\n",
    "            while not mon_sess.should_stop():\n",
    "                mon_sess.run(train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Builds the CIFAR-10 network.\n",
    "Summary of available functions:\n",
    " # Compute input images and labels for training. If you would like to run\n",
    " # evaluations, use inputs() instead.\n",
    " inputs, labels = distorted_inputs()\n",
    " # Compute inference on the model inputs to make a prediction.\n",
    " predictions = inference(inputs)\n",
    " # Compute the total loss of the prediction with respect to the labels.\n",
    " loss = loss(predictions, labels)\n",
    " # Create a graph to run one step of training with respect to the loss.\n",
    " train_op = train(loss, global_step)\n",
    "\"\"\"\n",
    "# pylint: disable=missing-docstring\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "\n",
    "import cifar10_input\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# Basic model parameters.\n",
    "tf.app.flags.DEFINE_integer('batch_size', 128,\n",
    "                            \"\"\"Number of images to process in a batch.\"\"\")\n",
    "tf.app.flags.DEFINE_string('data_dir', '/tmp/cifar10_data',\n",
    "                           \"\"\"Path to the CIFAR-10 data directory.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('use_fp16', False,\n",
    "                            \"\"\"Train the model using fp16.\"\"\")\n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "IMAGE_SIZE = cifar10_input.IMAGE_SIZE\n",
    "NUM_CLASSES = cifar10_input.NUM_CLASSES\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n",
    "\n",
    "\n",
    "# Constants describing the training process.\n",
    "MOVING_AVERAGE_DECAY = 0.9999     # The decay to use for the moving average.\n",
    "NUM_EPOCHS_PER_DECAY = 350.0      # Epochs after which learning rate decays.\n",
    "LEARNING_RATE_DECAY_FACTOR = 0.1  # Learning rate decay factor.\n",
    "INITIAL_LEARNING_RATE = 0.1       # Initial learning rate.\n",
    "\n",
    "# If a model is trained with multiple GPUs, prefix all Op names with tower_name\n",
    "# to differentiate the operations. Note that this prefix is removed from the\n",
    "# names of the summaries when visualizing a model.\n",
    "TOWER_NAME = 'tower'\n",
    "\n",
    "DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "\n",
    "\n",
    "def _activation_summary(x):\n",
    "  \"\"\"Helper to create summaries for activations.\n",
    "  Creates a summary that provides a histogram of activations.\n",
    "  Creates a summary that measures the sparsity of activations.\n",
    "  Args:\n",
    "    x: Tensor\n",
    "  Returns:\n",
    "    nothing\n",
    "  \"\"\"\n",
    "  # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training\n",
    "  # session. This helps the clarity of presentation on tensorboard.\n",
    "  tensor_name = re.sub('%s_[0-9]*/' % TOWER_NAME, '', x.op.name)\n",
    "  tf.summary.histogram(tensor_name + '/activations', x)\n",
    "  tf.summary.scalar(tensor_name + '/sparsity',\n",
    "                                       tf.nn.zero_fraction(x))\n",
    "\n",
    "\n",
    "def _variable_on_cpu(name, shape, initializer):\n",
    "  \"\"\"Helper to create a Variable stored on CPU memory.\n",
    "  Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    initializer: initializer for Variable\n",
    "  Returns:\n",
    "    Variable Tensor\n",
    "  \"\"\"\n",
    "  with tf.device('/cpu:0'):\n",
    "    dtype = tf.float16 if FLAGS.use_fp16 else tf.float32\n",
    "    var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)\n",
    "  return var\n",
    "\n",
    "\n",
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "  \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "  Note that the Variable is initialized with a truncated normal distribution.\n",
    "  A weight decay is added only if one is specified.\n",
    "  Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    stddev: standard deviation of a truncated Gaussian\n",
    "    wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "        decay is not added for this Variable.\n",
    "  Returns:\n",
    "    Variable Tensor\n",
    "  \"\"\"\n",
    "  dtype = tf.float16 if FLAGS.use_fp16 else tf.float32\n",
    "  var = _variable_on_cpu(\n",
    "      name,\n",
    "      shape,\n",
    "      tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))\n",
    "  if wd is not None:\n",
    "    weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "    tf.add_to_collection('losses', weight_decay)\n",
    "  return var\n",
    "\n",
    "\n",
    "def distorted_inputs():\n",
    "  \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "  Raises:\n",
    "    ValueError: If no data_dir\n",
    "  \"\"\"\n",
    "  if not FLAGS.data_dir:\n",
    "    raise ValueError('Please supply a data_dir')\n",
    "  data_dir = os.path.join(FLAGS.data_dir, 'cifar-10-batches-bin')\n",
    "  images, labels = cifar10_input.distorted_inputs(data_dir=data_dir,\n",
    "                                                  batch_size=FLAGS.batch_size)\n",
    "  if FLAGS.use_fp16:\n",
    "    images = tf.cast(images, tf.float16)\n",
    "    labels = tf.cast(labels, tf.float16)\n",
    "  return images, labels\n",
    "\n",
    "\n",
    "def inputs(eval_data):\n",
    "  \"\"\"Construct input for CIFAR evaluation using the Reader ops.\n",
    "  Args:\n",
    "    eval_data: bool, indicating if one should use the train or eval data set.\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "  Raises:\n",
    "    ValueError: If no data_dir\n",
    "  \"\"\"\n",
    "  if not FLAGS.data_dir:\n",
    "    raise ValueError('Please supply a data_dir')\n",
    "  data_dir = os.path.join(FLAGS.data_dir, 'cifar-10-batches-bin')\n",
    "  images, labels = cifar10_input.inputs(eval_data=eval_data,\n",
    "                                        data_dir=data_dir,\n",
    "                                        batch_size=FLAGS.batch_size)\n",
    "  if FLAGS.use_fp16:\n",
    "    images = tf.cast(images, tf.float16)\n",
    "    labels = tf.cast(labels, tf.float16)\n",
    "  return images, labels\n",
    "\n",
    "\n",
    "def inference(images):\n",
    "  \"\"\"Build the CIFAR-10 model.\n",
    "  Args:\n",
    "    images: Images returned from distorted_inputs() or inputs().\n",
    "  Returns:\n",
    "    Logits.\n",
    "  \"\"\"\n",
    "  # We instantiate all variables using tf.get_variable() instead of\n",
    "  # tf.Variable() in order to share variables across multiple GPU training runs.\n",
    "  # If we only ran this model on a single GPU, we could simplify this function\n",
    "  # by replacing all instances of tf.get_variable() with tf.Variable().\n",
    "  #\n",
    "  # conv1\n",
    "  with tf.variable_scope('conv1') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[5, 5, 3, 64],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "    _activation_summary(conv1)\n",
    "\n",
    "  # pool1\n",
    "  pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool1')\n",
    "  # norm1\n",
    "  norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm1')\n",
    "\n",
    "  # conv2\n",
    "  with tf.variable_scope('conv2') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[5, 5, 64, 64],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "    _activation_summary(conv2)\n",
    "\n",
    "  # norm2\n",
    "  norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm2')\n",
    "  # pool2\n",
    "  pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],\n",
    "                         strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "\n",
    "  # local3\n",
    "  with tf.variable_scope('local3') as scope:\n",
    "    # Move everything into depth so we can perform a single matrix multiply.\n",
    "    reshape = tf.reshape(pool2, [FLAGS.batch_size, -1])\n",
    "    dim = reshape.get_shape()[1].value\n",
    "    weights = _variable_with_weight_decay('weights', shape=[dim, 384],\n",
    "                                          stddev=0.04, wd=0.004)\n",
    "    biases = _variable_on_cpu('biases', [384], tf.constant_initializer(0.1))\n",
    "    local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
    "    _activation_summary(local3)\n",
    "\n",
    "  # local4\n",
    "  with tf.variable_scope('local4') as scope:\n",
    "    weights = _variable_with_weight_decay('weights', shape=[384, 192],\n",
    "                                          stddev=0.04, wd=0.004)\n",
    "    biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1))\n",
    "    local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)\n",
    "    _activation_summary(local4)\n",
    "\n",
    "  # linear layer(WX + b),\n",
    "  # We don't apply softmax here because\n",
    "  # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits\n",
    "  # and performs the softmax internally for efficiency.\n",
    "  with tf.variable_scope('softmax_linear') as scope:\n",
    "    weights = _variable_with_weight_decay('weights', [192, NUM_CLASSES],\n",
    "                                          stddev=1/192.0, wd=0.0)\n",
    "    biases = _variable_on_cpu('biases', [NUM_CLASSES],\n",
    "                              tf.constant_initializer(0.0))\n",
    "    softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
    "    _activation_summary(softmax_linear)\n",
    "\n",
    "  return softmax_linear\n",
    "\n",
    "\n",
    "def loss(logits, labels):\n",
    "  \"\"\"Add L2Loss to all the trainable variables.\n",
    "  Add summary for \"Loss\" and \"Loss/avg\".\n",
    "  Args:\n",
    "    logits: Logits from inference().\n",
    "    labels: Labels from distorted_inputs or inputs(). 1-D tensor\n",
    "            of shape [batch_size]\n",
    "  Returns:\n",
    "    Loss tensor of type float.\n",
    "  \"\"\"\n",
    "  # Calculate the average cross entropy loss across the batch.\n",
    "  labels = tf.cast(labels, tf.int64)\n",
    "  cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "      labels=labels, logits=logits, name='cross_entropy_per_example')\n",
    "  cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "  tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "  # The total loss is defined as the cross entropy loss plus all of the weight\n",
    "  # decay terms (L2 loss).\n",
    "  return tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "\n",
    "\n",
    "def _add_loss_summaries(total_loss):\n",
    "  \"\"\"Add summaries for losses in CIFAR-10 model.\n",
    "  Generates moving average for all losses and associated summaries for\n",
    "  visualizing the performance of the network.\n",
    "  Args:\n",
    "    total_loss: Total loss from loss().\n",
    "  Returns:\n",
    "    loss_averages_op: op for generating moving averages of losses.\n",
    "  \"\"\"\n",
    "  # Compute the moving average of all individual losses and the total loss.\n",
    "  loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
    "  losses = tf.get_collection('losses')\n",
    "  loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
    "\n",
    "  # Attach a scalar summary to all individual losses and the total loss; do the\n",
    "  # same for the averaged version of the losses.\n",
    "  for l in losses + [total_loss]:\n",
    "    # Name each loss as '(raw)' and name the moving average version of the loss\n",
    "    # as the original loss name.\n",
    "    tf.summary.scalar(l.op.name + ' (raw)', l)\n",
    "    tf.summary.scalar(l.op.name, loss_averages.average(l))\n",
    "\n",
    "  return loss_averages_op\n",
    "\n",
    "\n",
    "def train(total_loss, global_step):\n",
    "  \"\"\"Train CIFAR-10 model.\n",
    "  Create an optimizer and apply to all trainable variables. Add moving\n",
    "  average for all trainable variables.\n",
    "  Args:\n",
    "    total_loss: Total loss from loss().\n",
    "    global_step: Integer Variable counting the number of training steps\n",
    "      processed.\n",
    "  Returns:\n",
    "    train_op: op for training.\n",
    "  \"\"\"\n",
    "  # Variables that affect learning rate.\n",
    "  num_batches_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / FLAGS.batch_size\n",
    "  decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)\n",
    "\n",
    "  # Decay the learning rate exponentially based on the number of steps.\n",
    "  lr = tf.train.exponential_decay(INITIAL_LEARNING_RATE,\n",
    "                                  global_step,\n",
    "                                  decay_steps,\n",
    "                                  LEARNING_RATE_DECAY_FACTOR,\n",
    "                                  staircase=True)\n",
    "  tf.summary.scalar('learning_rate', lr)\n",
    "\n",
    "  # Generate moving averages of all losses and associated summaries.\n",
    "  loss_averages_op = _add_loss_summaries(total_loss)\n",
    "\n",
    "  # Compute gradients.\n",
    "  with tf.control_dependencies([loss_averages_op]):\n",
    "    opt = tf.train.GradientDescentOptimizer(lr)\n",
    "    grads = opt.compute_gradients(total_loss)\n",
    "\n",
    "  # Apply gradients.\n",
    "  apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "  # Add histograms for trainable variables.\n",
    "  for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.op.name, var)\n",
    "\n",
    "  # Add histograms for gradients.\n",
    "  for grad, var in grads:\n",
    "    if grad is not None:\n",
    "      tf.summary.histogram(var.op.name + '/gradients', grad)\n",
    "\n",
    "  # Track the moving averages of all trainable variables.\n",
    "  variable_averages = tf.train.ExponentialMovingAverage(\n",
    "      MOVING_AVERAGE_DECAY, global_step)\n",
    "  variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "  with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "    train_op = tf.no_op(name='train')\n",
    "\n",
    "  return train_op\n",
    "\n",
    "\n",
    "def maybe_download_and_extract():\n",
    "  \"\"\"Download and extract the tarball from Alex's website.\"\"\"\n",
    "  dest_directory = FLAGS.data_dir\n",
    "  if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "  filename = DATA_URL.split('/')[-1]\n",
    "  filepath = os.path.join(dest_directory, filename)\n",
    "  if not os.path.exists(filepath):\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename,\n",
    "          float(count * block_size) / float(total_size) * 100.0))\n",
    "      sys.stdout.flush()\n",
    "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "  extracted_dir_path = os.path.join(dest_directory, 'cifar-10-batches-bin')\n",
    "  if not os.path.exists(extracted_dir_path):\n",
    "    tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "Contact GitHub API Training Shop Blog About\n",
    "© 2017 GitHub, Inc. Terms Privacy Security Status Help"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
