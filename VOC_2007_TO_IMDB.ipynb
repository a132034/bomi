{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'dataset_name', 'pascalvoc',\n",
    "    'The name of the dataset to convert.')\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'dataset_dir', './data/VOCdevkit/VOC2007/',\n",
    "    'Directory where the original dataset is stored.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOC_LABELS = {\n",
    "    'none': (0, 'Background'),\n",
    "    'aeroplane': (1, 'Vehicle'),\n",
    "    'bicycle': (2, 'Vehicle'),\n",
    "    'bird': (3, 'Animal'),\n",
    "    'boat': (4, 'Vehicle'),\n",
    "    'bottle': (5, 'Indoor'),\n",
    "    'bus': (6, 'Vehicle'),\n",
    "    'car': (7, 'Vehicle'),\n",
    "    'cat': (8, 'Animal'),\n",
    "    'chair': (9, 'Indoor'),\n",
    "    'cow': (10, 'Animal'),\n",
    "    'diningtable': (11, 'Indoor'),\n",
    "    'dog': (12, 'Animal'),\n",
    "    'horse': (13, 'Animal'),\n",
    "    'motorbike': (14, 'Vehicle'),\n",
    "    'person': (15, 'Person'),\n",
    "    'pottedplant': (16, 'Indoor'),\n",
    "    'sheep': (17, 'Animal'),\n",
    "    'sofa': (18, 'Indoor'),\n",
    "    'train': (19, 'Vehicle'),\n",
    "    'tvmonitor': (20, 'Indoor'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Original dataset organisation.\n",
    "DIRECTORY_ANNOTATIONS = 'Annotations/'\n",
    "DIRECTORY_IMAGES = 'JPEGImages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _process_image(directory, name):\n",
    "    \"\"\"Process a image and annotation file.\n",
    "    Args:\n",
    "      filename: string, path to an image file e.g., '/path/to/example.JPG'.\n",
    "      coder: instance of ImageCoder to provide TensorFlow image coding utils.\n",
    "    Returns:\n",
    "      image_buffer: string, JPEG encoding of RGB image.\n",
    "      height: integer, image height in pixels.\n",
    "      width: integer, image width in pixels.\n",
    "    \"\"\"\n",
    "    # Read the image file.\n",
    "    filename = directory + DIRECTORY_IMAGES + name + '.jpg' #파일네임 \n",
    "    image_data = tf.read_file(filename) #리드 \n",
    "    print(type(image_data))\n",
    "    print(image_data)\n",
    "    print(image_data.shape)\n",
    "\n",
    "    # Read the XML annotation file.\n",
    "    filename = os.path.join(directory, DIRECTORY_ANNOTATIONS, name + '.xml') #엑스엠엘\n",
    "    tree = ET.parse(filename) #파싱준비\n",
    "    root = tree.getroot() #루트얻어옴 \n",
    "\n",
    "    # Image shape.\n",
    "    size = root.find('size')\n",
    "    shape = [int(size.find('height').text),\n",
    "             int(size.find('width').text),\n",
    "             int(size.find('depth').text)]\n",
    "    \n",
    "    # Find annotations.\n",
    "    bboxes = []\n",
    "    labels = []\n",
    "    labels_text = []\n",
    "    difficult = []\n",
    "    truncated = []\n",
    "    for obj in root.findall('object'): #object 다 찾아서 넣음 바운딩박스/라벨(번호)/라벨텍스트(이름)/voc에 있는 특징? 어려운거?/좀짤린거\n",
    "        label = obj.find('name').text\n",
    "        labels.append(int(VOC_LABELS[label][0]))\n",
    "        labels_text.append(label.encode('ascii'))\n",
    "\n",
    "        if obj.find('difficult'):\n",
    "            difficult.append(int(obj.find('difficult').text))\n",
    "        else:\n",
    "            difficult.append(0)\n",
    "        if obj.find('truncated'):\n",
    "            truncated.append(int(obj.find('truncated').text))\n",
    "        else:\n",
    "            truncated.append(0)\n",
    "\n",
    "        bbox = obj.find('bndbox')\n",
    "        bboxes.append((float(bbox.find('ymin').text) / shape[0],\n",
    "                       float(bbox.find('xmin').text) / shape[1],\n",
    "                       float(bbox.find('ymax').text) / shape[0],\n",
    "                       float(bbox.find('xmax').text) / shape[1]\n",
    "                       ))\n",
    "    return image_data, shape, bboxes, labels, labels_text, difficult, truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5011\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(FLAGS.dataset_dir, DIRECTORY_ANNOTATIONS)\n",
    "filenames = sorted(os.listdir(path))\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"ReadFile_1:0\", shape=(), dtype=string)\n",
      "()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'ReadFile_1:0' shape=() dtype=string>,\n",
       " [333, 500, 3],\n",
       " [(0.14114114114114115, 0.726, 0.3213213213213213, 0.864),\n",
       "  (0.27627627627627627, 0.432, 0.9069069069069069, 0.614),\n",
       "  (0.4444444444444444, 0.328, 0.7327327327327328, 0.454)],\n",
       " [20, 15, 15],\n",
       " [b'tvmonitor', b'person', b'person'],\n",
       " [0, 0, 0],\n",
       " [0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_name = '000041'\n",
    "_process_image(FLAGS.dataset_dir, img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imdb(object):\n",
    "    #image data base. 뭐를 넣을까.\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self._name = name #이미지 이름\n",
    "        self._classes = [] #각 클래스별 인덱스들\n",
    "        self._rois = {} #각 클래스별 좌표들\n",
    "        self._image_idx = [] #이미지 번호\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self._classes\n",
    "    \n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return len(self._classes)\n",
    "    \n",
    "    @property\n",
    "    def rois(self):\n",
    "        return self._rois\n",
    "    \n",
    "    @property\n",
    "    def image_idx(self):\n",
    "        return self._image_idx\n",
    "    \n",
    "    def read_from_directory(self, data_path=None):\n",
    "        #data path 잡음\n",
    "        #갯수 읽어옴\n",
    "        #포문 돌면서 다 imdb에 읽어옴\n",
    "        return\n",
    "\n",
    "    def read_batch(self, shuffle=True):\n",
    "        #읽어온 imdb를 배치해줌.\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
