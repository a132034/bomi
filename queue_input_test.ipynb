{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf #tensorflow\n",
    "import numpy as np #numpy > save loss .. \n",
    "from collections import OrderedDict #layer ..\n",
    "import os, random #dir, random..\n",
    "import pickle #save & load\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = 'cifar10/cifar-10-batches-py/'\n",
    "CHECKPOINT = 'simple_res_net_0525.ckpt'\n",
    "SAVE_PATH = 'checkpoint/simple_res_net/'\n",
    "BOARD_PATH = './tensorboard/board_res_net'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTIONS READY\n"
     ]
    }
   ],
   "source": [
    "#npz - python numpy 파일 포맷. > dictionary로 불러옴 (Save several arrays into a single file in uncompressed .npz format)\n",
    "def load_npz(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "    \n",
    "## Make batch_iterator for npz data\n",
    "def make_batch_index(_data, batch_size=128, allow_small_batch=True):\n",
    "    num_images = len(_data[b'data']) #데이터 갯수\n",
    "    start_idx = list(range(0, num_images, batch_size)) #각 배치별 시작 인덱스 리스트\n",
    "    end_idx = list(range(batch_size, num_images + 1, batch_size))#각 배치별 끝 인덱스 \n",
    "    if allow_small_batch and end_idx[-1] < num_images : #스몰배치 허용시 마지막 배치\n",
    "        start_idx.append(end_idx[-1])\n",
    "        end_idx.append(num_images)\n",
    "    return zip(start_idx, end_idx)\n",
    "\n",
    "#one hot encoding\n",
    "def one_hot_encode(x, numclass):\n",
    "    return np.eye(numclass)[x] #numclass 크기의 항등행렬 생성 \n",
    "\n",
    "#############################################################################################################\n",
    "######################################아래는 방식변환중\n",
    "#############################################################################################################\n",
    "\n",
    "#CIFAR 데이터 읽어오기 \n",
    "def read_dataset(filename_queue):\n",
    "    class DataRecord(object):\n",
    "        pass\n",
    "    \n",
    "    result = DataRecord()\n",
    "    \n",
    "    label_bytes = 1\n",
    "    result.height = 32\n",
    "    result.width = 32\n",
    "    result.depth = 3\n",
    "    image_bytes = result.height * result.width * result.depth\n",
    "    record_bytes = label_bytes + image_bytes\n",
    "    \n",
    "    reader = tf.FixedLengthRecordReader(record_bytes = record_bytes)\n",
    "    result.key, value = reader.read(filename_queue)\n",
    "    print(\"key & value\")\n",
    "    print(result.key)\n",
    "    print (value)\n",
    "    record_bytes = tf.decode_raw(value, tf.uint8)\n",
    "    \n",
    "    result.label = tf.cast(tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32) #input, begin, end로 잘라냄 > 0~1\n",
    "    print(result.label)\n",
    "    depth_major = tf.reshape(tf.strided_slice(record_bytes, [label_bytes], # 1부터 image_bytes까지 image를 잘라낸 후 \n",
    "                                              [label_bytes + image_bytes]), #channel x height x width로 변환함.\n",
    "                             [result.depth, result.height, result.width])\n",
    "    \n",
    "    result.uint8image = tf.transpose(depth_major, [1,2,0]) #channel x height x width >>> height x width x chennl로 변경\n",
    "    \n",
    "    return result\n",
    "\n",
    "#label, image 세팅해줌 \n",
    "def _generate_image_and_label_batch(image, label, min_queue_examples,\n",
    "                                    batch_size, shuffle):\n",
    "    \"\"\"Construct a queued batch of images and labels.\n",
    "    Args:\n",
    "      image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "      label: 1-D Tensor of type.int32\n",
    "      min_queue_examples: int32, minimum number of samples to retain\n",
    "        in the queue that provides of batches of examples.\n",
    "      batch_size: Number of images per batch.\n",
    "      shuffle: boolean indicating whether to use a shuffling queue.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    # Create a queue that shuffles the examples, and then\n",
    "    # read 'batch_size' images + labels from the example queue.\n",
    "    num_preprocess_threads = 16 #프로세스 스레드 \n",
    "    if shuffle: #셔플 하면 \n",
    "        images, label_batch = tf.train.shuffle_batch([image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size,\n",
    "            min_after_dequeue=min_queue_examples) #이거만 해주면 batch와 동일함. \n",
    "    #Minimum number elements in the queue after a dequeue, used to ensure a level of mixing of elements.\n",
    "    else:\n",
    "        images, label_batch = tf.train.batch([image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "    # Display the training images in the visualizer.\n",
    "    tf.summary.image('images', images) #걍 보드용인듯\n",
    "    \n",
    "    print(\"label_batch\")\n",
    "    print(label_batch)\n",
    "    return images, tf.reshape(label_batch, [batch_size])\n",
    "\n",
    "\n",
    "def distorted_inputs(data_dir, batch_size): #좀 드럽게 인풋받아오기 \n",
    "    \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "    Args:\n",
    "      data_dir: Path to the CIFAR-10 data directory.\n",
    "      batch_size: Number of images per batch.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    filenames = [os.path.join(data_dir, 'data_batch_%d' % i) for i in range(1, 6)] \n",
    "    for f in filenames:\n",
    "        if not tf.gfile.Exists(f):\n",
    "            raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "    # Create a queue that produces the filenames to read.\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "    # Read examples from files in the filename queue.\n",
    "    read_input = read_dataset(filename_queue)\n",
    "    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "    height = 32\n",
    "    width = 32\n",
    "\n",
    "    # Image processing for training the network.  Note the many random\n",
    "    # distortions applied to the image.\n",
    "\n",
    "    # Randomly crop a [height, width] section of the image.\n",
    "    distorted_image = tf.random_crop(reshaped_image, [height, width, 3])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "\n",
    "    # Because these operations are not commutative, consider randomizing\n",
    "    # the order their operation.\n",
    "    distorted_image = tf.image.random_brightness(distorted_image,\n",
    "                                               max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(distorted_image,\n",
    "                                             lower=0.2, upper=1.8)\n",
    "\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    float_image = tf.image.per_image_standardization(distorted_image)\n",
    "\n",
    "    # Set the shapes of tensors.\n",
    "    float_image.set_shape([height, width, 3])\n",
    "    read_input.label.set_shape([1])\n",
    "\n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(10000 * min_fraction_of_examples_in_queue)\n",
    "    print('Filling queue with %d CIFAR images before starting to train. '\n",
    "         'This will take a few minutes.' % min_queue_examples)\n",
    "\n",
    "    # Generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(float_image, read_input.label,\n",
    "                                         min_queue_examples, batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "print(\"FUNCTIONS READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NETWORK PARAMETERS\n",
    "\n",
    "stddev = 0.1\n",
    "\n",
    "weights = {\n",
    "     'conv' : tf.Variable(tf.random_normal([3, 3, 3, 16], stddev=stddev), name='conv'),\n",
    "    'conv1_1x1' : tf.Variable(tf.random_normal([1, 1, 16, 4], stddev=stddev, name='conv1_1x1')),\n",
    "    'conv1_3x3' : tf.Variable(tf.random_normal([3, 3, 4, 4], stddev=stddev, name='conv1_3x3')),\n",
    "    'conv1_1x1_16' : tf.Variable(tf.random_normal([1, 1, 4, 16], stddev=stddev, name='conv1_1x1_16')),\n",
    "    'conv2_1x1' : tf.Variable(tf.random_normal([1, 1, 16, 4], stddev=stddev, name='conv2_1x1')),\n",
    "    'conv2_3x3' : tf.Variable(tf.random_normal([3, 3, 4, 4], stddev=stddev, name='conv2_3x3')),\n",
    "    'conv2_1x1_16' : tf.Variable(tf.random_normal([1, 1, 4, 16], stddev=stddev, name='conv2_1x1_16')),\n",
    "    \n",
    "    # conv 16 + conv2 16 = 32filters \n",
    "    \n",
    "    'conv3_1x1' : tf.Variable(tf.random_normal([1, 1, 32, 8], stddev=stddev, name='conv3_1x1')),\n",
    "    'conv3_3x3' : tf.Variable(tf.random_normal([3, 3, 8, 8], stddev=stddev, name='conv3_3x3')),\n",
    "    'conv3_1x1_32' : tf.Variable(tf.random_normal([1, 1, 8, 32], stddev=stddev, name='conv3_1x1_32')),\n",
    "    'conv4_1x1' : tf.Variable(tf.random_normal([1, 1, 32, 8], stddev=stddev, name='conv4_1x1')),\n",
    "    'conv4_3x3' : tf.Variable(tf.random_normal([3, 3, 8, 8], stddev=stddev, name='conv4_3x3')),\n",
    "    'conv4_1x1_32' : tf.Variable(tf.random_normal([1, 1, 8, 32], stddev=stddev, name='conv4_1x1_32')),\n",
    "    \n",
    "    # conv2 지난거32 + conv4 32 = 64\n",
    "    \n",
    "    'conv5_1x1' : tf.Variable(tf.random_normal([1, 1, 64, 16], stddev=stddev, name='conv5_1x1')),\n",
    "    'conv5_3x3' : tf.Variable(tf.random_normal([3, 3, 16, 16], stddev=stddev, name='conv5_3x3')),\n",
    "    'conv5_1x1_64' : tf.Variable(tf.random_normal([1, 1, 16, 64], stddev=stddev, name='conv5_1x1_64')),\n",
    "    'conv6_1x1' : tf.Variable(tf.random_normal([1, 1, 64, 16], stddev=stddev, name='conv6_1x1')),\n",
    "    'conv6_3x3' : tf.Variable(tf.random_normal([3, 3, 16, 16], stddev=stddev, name='conv6_3x3')),\n",
    "    'conv6_1x1_64' : tf.Variable(tf.random_normal([1, 1, 16, 64], stddev=stddev, name='conv6_1x1_64')),\n",
    "    \n",
    "    #conv4 지난거 64 + conv6 64 = 128\n",
    "    \n",
    "    'dense1' : tf.Variable(tf.random_normal([16*16*128, 1000], stddev=stddev, name='dense1')),\n",
    "    'dense2' : tf.Variable(tf.random_normal([1000, 10], stddev=stddev, name='dense2'))    \n",
    "}\n",
    "biases = {\n",
    "    'conv' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv_b')),\n",
    "    'conv1_1x1' : tf.Variable(tf.random_normal([4], stddev=stddev, name='conv1_1x1_b')),\n",
    "    'conv1_3x3' : tf.Variable(tf.random_normal([4], stddev=stddev, name='conv1_3x3_b')),\n",
    "    'conv1_1x1_16' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv1_1x1_16_b')),\n",
    "    'conv2_1x1' : tf.Variable(tf.random_normal([4], stddev=stddev, name='conv2_1x1_b')),\n",
    "    'conv2_3x3' :tf.Variable(tf.random_normal([4], stddev=stddev, name='conv2_3x3_b')),\n",
    "    'conv2_1x1_16' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv2_1x1_16_b')),\n",
    "    \n",
    "    'conv3_1x1' : tf.Variable(tf.random_normal([8], stddev=stddev, name='conv3_1x1_b')),\n",
    "    'conv3_3x3' : tf.Variable(tf.random_normal([8], stddev=stddev, name='conv3_3x3_b')),\n",
    "    'conv3_1x1_32' : tf.Variable(tf.random_normal([32], stddev=stddev, name='conv3_1x1_32_b')),\n",
    "    'conv4_1x1' : tf.Variable(tf.random_normal([8], stddev=stddev, name='conv4_1x1_b')),\n",
    "    'conv4_3x3' : tf.Variable(tf.random_normal([8], stddev=stddev, name='conv4_3x3_b')),\n",
    "    'conv4_1x1_32' : tf.Variable(tf.random_normal([32], stddev=stddev, name='conv4_1x1_32_b')),\n",
    "    \n",
    "    'conv5_1x1' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv5_1x1_b')),\n",
    "    'conv5_3x3' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv5_3x3_b')),\n",
    "    'conv5_1x1_64' : tf.Variable(tf.random_normal([64], stddev=stddev, name='conv5_1x1_64_b')),\n",
    "    'conv6_1x1' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv6_1x1_b')),\n",
    "    'conv6_3x3' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv6_3x3_b')),\n",
    "    'conv6_1x1_64' : tf.Variable(tf.random_normal([64], stddev=stddev, name='conv6_1x1_64_b')),\n",
    "    \n",
    "    'dense1' : tf.Variable(tf.random_normal([1000], stddev=stddev, name='dense1_b')),\n",
    "    'dense2' : tf.Variable(tf.random_normal([10], stddev=stddev, name='dense2_b'))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model\n",
    "#http://laonple.blog.me/220764986252 - bottleneck \n",
    "#conv 3x3\n",
    "#conv (1x1, 3x3, 1x1) - relu > 16\n",
    "#conv (1x1, 3x3, 1x1) relu > 32\n",
    "#conv (1x1, 3x3, 1x1) relu > 64\n",
    "#avg pooling \n",
    "#fc\n",
    "#softmax\n",
    "def ResNet(img_width, img_height, img_channel, _x, _w, _b, scope='ResNet'):\n",
    "    network = OrderedDict() #network layers\n",
    "\n",
    "    # X RESHAPE\n",
    "    _x_r = tf.reshape(_x, shape=[-1,img_width,img_height, img_channel])\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        with tf.name_scope('conv') as scope:\n",
    "            conv = tf.nn.conv2d(_x_r, _w['conv'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv = tf.nn.bias_add(conv, _b['conv'])\n",
    "            conv = tf.nn.relu(conv)\n",
    "            network['conv'] = conv\n",
    "        \n",
    "        #16\n",
    "        with tf.name_scope('conv2') as scope:\n",
    "            conv1_1x1 = tf.nn.conv2d(conv, _w['conv1_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv1_1x1 = tf.nn.bias_add(conv1_1x1, _b['conv1_1x1'])\n",
    "            conv1_1x1 = tf.nn.relu(conv1_1x1)\n",
    "            conv1_3x3 = tf.nn.conv2d(conv1_1x1, _w['conv1_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv1_3x3 = tf.nn.bias_add(conv1_3x3, _b['conv1_3x3'])\n",
    "            conv1_3x3 = tf.nn.relu(conv1_3x3)\n",
    "            conv1_1x1_16 = tf.nn.conv2d(conv1_3x3, _w['conv1_1x1_16'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv1_1x1_16 = tf.nn.bias_add(conv1_1x1_16, _b['conv1_1x1_16'])\n",
    "            conv1_1x1_16 = tf.nn.relu(conv1_1x1_16)\n",
    "            network['conv1_1x1_16'] = conv1_1x1_16\n",
    "        \n",
    "        #16\n",
    "        with tf.name_scope('conv3') as scope:\n",
    "            conv2_1x1 = tf.nn.conv2d(conv1_1x1_16, _w['conv2_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv2_1x1 = tf.nn.bias_add(conv2_1x1, _b['conv2_1x1'])\n",
    "            conv2_1x1 = tf.nn.relu(conv2_1x1)\n",
    "            conv2_3x3 = tf.nn.conv2d(conv2_1x1, _w['conv2_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv2_3x3 = tf.nn.bias_add(conv2_3x3, _b['conv2_3x3'])\n",
    "            conv2_3x3 = tf.nn.relu(conv2_3x3)\n",
    "            conv2_1x1_16 = tf.nn.conv2d(conv2_3x3, _w['conv2_1x1_16'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv2_1x1_16 = tf.nn.bias_add(conv2_1x1_16, _b['conv2_1x1_16'])\n",
    "            #print(conv2_1x1_16.shape)\n",
    "            #32\n",
    "            conv2_1x1_16 = tf.concat([conv, conv2_1x1_16], 3) \n",
    "            conv2_1x1_16 = tf.nn.relu(conv2_1x1_16)\n",
    "            network['conv2_1x1_16'] = conv2_1x1_16\n",
    "       \n",
    "        #print(conv2_1x1_16.shape)\n",
    "        #32       32 x 32 x 16+16 >>> \n",
    "        with tf.name_scope('conv4') as scope:\n",
    "            conv3_1x1 = tf.nn.conv2d(conv2_1x1_16, _w['conv3_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv3_1x1 = tf.nn.bias_add(conv3_1x1, _b['conv3_1x1'])\n",
    "            conv3_1x1 = tf.nn.relu(conv3_1x1)\n",
    "            conv3_3x3 = tf.nn.conv2d(conv3_1x1, _w['conv3_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv3_3x3 = tf.nn.bias_add(conv3_3x3, _b['conv3_3x3'])\n",
    "            conv3_3x3 = tf.nn.relu(conv3_3x3)\n",
    "            conv3_1x1_32 = tf.nn.conv2d(conv3_3x3, _w['conv3_1x1_32'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv3_1x1_32 = tf.nn.bias_add(conv3_1x1_32, _b['conv3_1x1_32'])\n",
    "            conv3_1x1_32 = tf.nn.relu(conv3_1x1_32)\n",
    "            network['conv3_1x1_32'] = conv3_1x1_32\n",
    "        \n",
    "        with tf.name_scope('conv5') as scope:\n",
    "            conv4_1x1 = tf.nn.conv2d(conv3_1x1_32, _w['conv4_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv4_1x1 = tf.nn.bias_add(conv4_1x1, _b['conv4_1x1'])\n",
    "            conv4_1x1 = tf.nn.relu(conv4_1x1)\n",
    "            conv4_3x3 = tf.nn.conv2d(conv4_1x1, _w['conv4_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv4_3x3 = tf.nn.bias_add(conv4_3x3, _b['conv4_3x3'])\n",
    "            conv4_3x3 = tf.nn.relu(conv4_3x3)\n",
    "            conv4_1x1_32 = tf.nn.conv2d(conv4_3x3, _w['conv4_1x1_32'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv4_1x1_32 = tf.nn.bias_add(conv4_1x1_32, _b['conv4_1x1_32'])\n",
    "\n",
    "            #64\n",
    "            conv4_1x1_32 = tf.concat([conv2_1x1_16, conv4_1x1_32 ], 3)\n",
    "            conv4_1x1_32 = tf.nn.relu(conv4_1x1_32)\n",
    "            network['conv4_1x1_32'] = conv4_1x1_32\n",
    "    \n",
    "        with tf.name_scope('conv6') as scope:\n",
    "            conv5_1x1 = tf.nn.conv2d(conv4_1x1_32, _w['conv5_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv5_1x1 = tf.nn.bias_add(conv5_1x1, _b['conv5_1x1'])\n",
    "            conv5_1x1 = tf.nn.relu(conv5_1x1)\n",
    "            conv5_3x3 = tf.nn.conv2d(conv5_1x1, _w['conv5_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv5_3x3 = tf.nn.bias_add(conv5_3x3, _b['conv5_3x3'])\n",
    "            conv5_3x3 = tf.nn.relu(conv5_3x3)\n",
    "            conv5_1x1_64 = tf.nn.conv2d(conv5_3x3, _w['conv5_1x1_64'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv5_1x1_64 = tf.nn.bias_add(conv5_1x1_64, _b['conv5_1x1_64'])\n",
    "            conv5_1x1_64 = tf.nn.relu(conv5_1x1_64)\n",
    "            network['conv5_1x1_64'] = conv5_1x1_64\n",
    "        \n",
    "        with tf.name_scope('conv7') as scope:\n",
    "            conv6_1x1 = tf.nn.conv2d(conv5_1x1_64, _w['conv6_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv6_1x1 = tf.nn.bias_add(conv6_1x1, _b['conv6_1x1'])\n",
    "            conv6_1x1 = tf.nn.relu(conv6_1x1)\n",
    "            conv6_3x3 = tf.nn.conv2d(conv6_1x1, _w['conv6_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv6_3x3 = tf.nn.bias_add(conv6_3x3, _b['conv6_3x3'])\n",
    "            conv6_3x3 = tf.nn.relu(conv6_3x3)\n",
    "            conv6_1x1_64 = tf.nn.conv2d(conv6_3x3, _w['conv6_1x1_64'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv6_1x1_64 = tf.nn.bias_add(conv6_1x1_64, _b['conv6_1x1_64'])\n",
    "\n",
    "            #128\n",
    "            conv6_1x1_64 = tf.concat([conv4_1x1_32, conv6_1x1_64],3)\n",
    "            conv6_1x1_64 = tf.nn.relu(conv6_1x1_64)\n",
    "            network['conv6_1x1_64'] = conv6_1x1_64\n",
    "        \n",
    "        with tf.name_scope('pool') as scope:\n",
    "            pool = tf.nn.avg_pool(conv6_1x1_64, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "            network['pool'] = pool\n",
    "        \n",
    "        with tf.name_scope('dense1') as scope:\n",
    "            dense = tf.reshape(pool, [-1, _w['dense1'].get_shape().as_list()[0]])\n",
    "            dense1 = tf.add(tf.matmul(dense, _w['dense1']), _b['dense1'])\n",
    "            dense1 = tf.nn.relu(dense1)\n",
    "            network['dense1'] = dense1\n",
    "            \n",
    "        with tf.name_scope('logit') as scope:\n",
    "            logit = tf.add(tf.matmul(dense1, _w['dense2']), _b['dense2'])\n",
    "            network['logit'] = logit\n",
    "        \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key & value\n",
      "Tensor(\"ReaderReadV2_9:0\", shape=(), dtype=string)\n",
      "Tensor(\"ReaderReadV2_9:1\", shape=(), dtype=string)\n",
      "Tensor(\"Cast_30:0\", dtype=int32)\n",
      "Filling queue with 4000 CIFAR images before starting to train. This will take a few minutes.\n",
      "label_batch\n",
      "Tensor(\"shuffle_batch_6:1\", shape=(64, 1), dtype=int32)\n",
      "Tensor(\"shuffle_batch_6:0\", shape=(64, 32, 32, 3), dtype=float32)\n",
      "(64, 32, 32, 3)\n",
      "(64,)\n",
      "conv Tensor(\"ResNet_3/conv/Relu:0\", shape=(64, 32, 32, 16), dtype=float32)\n",
      "conv1_1x1_16 Tensor(\"ResNet_3/conv2/Relu_2:0\", shape=(64, 32, 32, 16), dtype=float32)\n",
      "conv2_1x1_16 Tensor(\"ResNet_3/conv3/Relu_2:0\", shape=(64, 32, 32, 32), dtype=float32)\n",
      "conv3_1x1_32 Tensor(\"ResNet_3/conv4/Relu_2:0\", shape=(64, 32, 32, 32), dtype=float32)\n",
      "conv4_1x1_32 Tensor(\"ResNet_3/conv5/Relu_2:0\", shape=(64, 32, 32, 64), dtype=float32)\n",
      "conv5_1x1_64 Tensor(\"ResNet_3/conv6/Relu_2:0\", shape=(64, 32, 32, 64), dtype=float32)\n",
      "conv6_1x1_64 Tensor(\"ResNet_3/conv7/Relu_2:0\", shape=(64, 32, 32, 128), dtype=float32)\n",
      "pool Tensor(\"ResNet_3/pool/AvgPool:0\", shape=(64, 16, 16, 128), dtype=float32)\n",
      "dense1 Tensor(\"ResNet_3/dense1/Relu:0\", shape=(64, 1000), dtype=float32)\n",
      "logit Tensor(\"ResNet_3/logit/Add:0\", shape=(64, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "images, labels = distorted_inputs(DATA_PATH, 64)\n",
    "print(images)\n",
    "print(images.shape)\n",
    "labels = tf.cast(labels, tf.int64)\n",
    "print(labels.shape)\n",
    "\n",
    "out = ResNet(32, 32, 3, images, weights, biases, 'ResNet')\n",
    "for key, value in out.items():\n",
    "    print (key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key & value\n",
      "Tensor(\"ReaderReadV2_10:0\", shape=(), dtype=string)\n",
      "Tensor(\"ReaderReadV2_10:1\", shape=(), dtype=string)\n",
      "Tensor(\"Cast_35:0\", dtype=int32)\n",
      "Filling queue with 4000 CIFAR images before starting to train. This will take a few minutes.\n",
      "label_batch\n",
      "Tensor(\"shuffle_batch_7:1\", shape=(64, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "images, labels = distorted_inputs(DATA_PATH, 64)\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=out['logit']))\n",
    "opt = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)\n",
    "corr = tf.equal(tf.argmax(out['logit'], 1), tf.argmax(labels,1))\n",
    "accr = tf.reduce_mean(tf.cast(corr, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 32, 32, 3)\n",
      "(64,)\n",
      "[178  80  44  29 113 136 102  95 213  98 136  31 130 255  76  58 179 151\n",
      "  67  51 105 165  92  23 133  84  45 236  89  40 246 198  70 237 253 100\n",
      "  45 185 241 129  31  80  11 143  95 145 226 252 203 132 201 254 181  15\n",
      " 255 108 143  87 255  65 124  21 192  55]\n",
      "(64, 32, 32, 3)\n",
      "(64,)\n",
      "[212 156  64 148  78  79 111 163 120 120 196  72  61 132  48 156  78  36\n",
      "  48 180 103  58 119 174 166 119  76 184 131 208  54 102 207 103 152  54\n",
      " 165 103  78 129 119  76  58  65 113  76  41  85  53  58 207 181  63 139\n",
      " 170  53 230 127 239 108  20  23 155 109]\n",
      "(64, 32, 32, 3)\n",
      "(64,)\n",
      "[  4  82  91  51 199 109 113 166 252 103 231 116  76 171  12 211 132  14\n",
      " 112  18  87 111 103 198 132 121  57  12 174   3 198 191 140 217  80  89\n",
      "  92 165  60 140 138 145 201 156  87  57  29 132 113  92 155 119 113  38\n",
      "  34 145  41 127  89 228  56 213 181 145]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    coord = tf.train.Coordinator()\n",
    "    thresds = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    for i in range(3):\n",
    "        la, label = sess.run([images, labels])\n",
    "        print(la.shape)\n",
    "        print(label.shape)\n",
    "        print(label)\n",
    "        \n",
    "        #_ = sess.run(opt)\n",
    "        #if i % 10 == 0:\n",
    "           # print(str(i) + \" > loss : \" + str(loss) + \", accr : \" + str(accr))\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(thresds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input & output \n",
    "x = tf.placeholder(\"float\", [64, 32*32 * 3]) #batch x image size\n",
    "y = tf.placeholder(\"float\", [63, 10]) #batch x class`\n",
    "\n",
    "#train&test batch\n",
    "train_file=['data_batch_1','data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5']\n",
    "test_file=['cifar10/cifar-10-batches-py/test_batch']\n",
    "LIST_CLASS=['airplane', 'automobile', 'birds', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10/cifar-10-batches-py/data_batch_1\n"
     ]
    }
   ],
   "source": [
    "file_name = DATA_PATH + train_file[0] #해당 파일 이름\n",
    "print(file_name)\n",
    "load_data = load_npz(file_name) #해당 파일 이름으로 불러온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-6b241c428f2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    coord = tf.train.Coordinator()\n",
    "    thresds = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    for i in range(5):\n",
    "        la = sess.run(images)\n",
    "        print(la)\n",
    "        \n",
    "        #_ = sess.run(opt)\n",
    "        #if i % 10 == 0:\n",
    "           # print(str(i) + \" > loss : \" + str(loss) + \", accr : \" + str(accr))\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(thresds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
