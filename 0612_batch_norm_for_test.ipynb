{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf #tensorflow\n",
    "import numpy as np #numpy > save loss .. \n",
    "from collections import OrderedDict #layer ..\n",
    "import os, random #dir, random..\n",
    "import pickle #save & load\n",
    "import math #xavier..\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path\n",
    "day = str(datetime.date.today().day)\n",
    "#DATA_PATH = './cifar10/cifar-10-batches-py/' #python pickle\n",
    "DATA_PATH = './cifar10/cifar-10-batches-bin/' #binary\n",
    "CHECKPOINT = 'simple_res_net_train_'+day+'.ckpt'\n",
    "CHECKPOINT_PATH = './checkpoint/res_'+day+'/'\n",
    "BOARD_PATH = './tensorboard/board_res_'+day+'/'\n",
    "#TEST_FILE_PATH='./cifar10/cifar-10-batches-py/test_batch' #python pickle\n",
    "print(DATA_PATH)\n",
    "print(CHECKPOINT)\n",
    "print(CHECKPOINT_PATH)\n",
    "print(BOARD_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "\n",
    "INPUT_SIDE = 32\n",
    "INPUT_SIZE = INPUT_SIDE * INPUT_SIDE\n",
    "N_CHANNEL = 3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 500\n",
    "LR = 0.1\n",
    "LR_DECAY_RATE = 0.5\n",
    "\n",
    "LABEL_BYTES = 1 \n",
    "NUM_EXAMPLES_PER_EPOCH = 50000 #NUMBER OF TRAIN DATA SET\n",
    "NUM_BATCHES_PER_EPOCH = NUM_EXAMPLES_PER_EPOCH / BATCH_SIZE\n",
    "NUM_TESTSET_PER_EPOCH = 10000\n",
    "NUM_TEST_BATCHES_PER_EPOCH = NUM_TESTSET_PER_EPOCH / BATCH_SIZE\n",
    "\n",
    "LIST_CLASS=['airplane', 'automobile', 'birds', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "N_CLASSES = len(LIST_CLASS)\n",
    "\n",
    "training = tf.placeholder(tf.bool)\n",
    "\n",
    "#loss & accuracy save\n",
    "TRAIN_OUT_FILE_NAME = 'RES_NET_CIFAR10_'+day+'.log'\n",
    "train_loss_out = open('TRAIN_LOSS'+TRAIN_OUT_FILE_NAME, 'w')\n",
    "train_accr_out = open('TRAIN_ACCURACY'+TRAIN_OUT_FILE_NAME, 'w')\n",
    "\n",
    "TEST_OUT_FILE_NAME = 'RES_NET_CIFAR10_'+day+'.log'\n",
    "test_accr_out = open('TEST_ACCURACY'+TEST_OUT_FILE_NAME, 'w')\n",
    "\n",
    "print(\"input image size : {}\".format(INPUT_SIZE))\n",
    "print(\"image channel : {}\".format(N_CHANNEL))\n",
    "print(\"batch size : {}\".format(BATCH_SIZE))\n",
    "print(\"num of class : {}\".format(N_CLASSES))\n",
    "print(\"training epochs : {}\".format(EPOCHS))\n",
    "print(\"learning rate : {}\".format(LR))\n",
    "print(\"learning decay rate : {}\".format(LR_DECAY_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_norm_for_dense_layer(x, n_out, phase_train):\n",
    "    \"\"\"\n",
    "    batch normalization for dense layer \n",
    "    \"\"\"\n",
    "    with tf.variable_scope('bn'):\n",
    "        beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "                                     name='beta', trainable=True)\n",
    "        gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "                                      name='gamma', trainable=True)\n",
    "        batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
    "        ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "        def mean_var_with_update():\n",
    "            ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "            with tf.control_dependencies([ema_apply_op]):\n",
    "                return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "        mean, var = tf.cond(phase_train,\n",
    "                            mean_var_with_update,\n",
    "                            lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3)\n",
    "    return normed\n",
    "    \n",
    "def batch_norm(x, n_out, phase_train):\n",
    "    \"\"\"\n",
    "    Batch normalization on convolutional maps.\n",
    "    Ref.: http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow\n",
    "    Args:\n",
    "        x:           Tensor, 4D BHWD input maps\n",
    "        n_out:       integer, depth of input maps\n",
    "        phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "        scope:       string, variable scope\n",
    "    Return:\n",
    "        normed:      batch-normalized maps\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('bn'):\n",
    "        beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "                                     name='beta', trainable=True)\n",
    "        gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "                                      name='gamma', trainable=True)\n",
    "        batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "        ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "        def mean_var_with_update():\n",
    "            ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "            with tf.control_dependencies([ema_apply_op]):\n",
    "                return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "        mean, var = tf.cond(phase_train,\n",
    "                            mean_var_with_update,\n",
    "                            lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3)\n",
    "    return normed\n",
    "\n",
    "#xavier initialization\n",
    "def xavier_init(n_inputs, n_outputs, uniform=True):\n",
    "    \"\"\"Set the parameter initialization using the method described.\n",
    "    This method is designed to keep the scale of the gradients roughly the same\n",
    "    in all layers.\n",
    "    Xavier Glorot and Yoshua Bengio (2010):\n",
    "           Understanding the difficulty of training deep feedforward neural\n",
    "           networks. International conference on artificial intelligence and\n",
    "           statistics.\n",
    "    Args:\n",
    "    n_inputs: The number of input nodes into each output.\n",
    "    n_outputs: The number of output nodes for each input.\n",
    "    uniform: If true use a uniform distribution, otherwise use a normal.\n",
    "    Returns:\n",
    "    An initializer.\n",
    "    \"\"\"\n",
    "    if uniform:\n",
    "        # 6 was used in the paper.\n",
    "        init_range = math.sqrt(6.0 / (n_inputs + n_outputs))\n",
    "        return tf.random_uniform_initializer(-init_range, init_range)\n",
    "    else:\n",
    "        # 3 gives us approximately the same limits as above since this repicks\n",
    "        # values greater than 2 standard deviations from the mean.\n",
    "        stddev = math.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "        return tf.truncated_normal_initializer(stddev=stddev)\n",
    "\n",
    "#CIFAR 데이터 읽어오기 \n",
    "def read_dataset(filename_queue):\n",
    "    class DataRecord(object):\n",
    "        pass\n",
    "    \n",
    "    result = DataRecord()\n",
    "    \n",
    "    label_bytes = LABEL_BYTES\n",
    "    result.height = INPUT_SIDE\n",
    "    result.width = INPUT_SIDE\n",
    "    result.depth = N_CHANNEL\n",
    "    image_bytes = result.height * result.width * result.depth\n",
    "    record_bytes = label_bytes + image_bytes\n",
    "    \n",
    "    reader = tf.FixedLengthRecordReader(record_bytes = record_bytes)\n",
    "    result.key, value = reader.read(filename_queue)\n",
    "    print (value)\n",
    "    record_bytes = tf.decode_raw(value, tf.uint8)\n",
    "    \n",
    "    result.label = tf.cast(tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32) #input, begin, end로 잘라냄 > 0~1\n",
    "    \n",
    "    depth_major = tf.reshape(tf.strided_slice(record_bytes, [label_bytes], # 1부터 image_bytes까지 image를 잘라낸 후 \n",
    "                                              [label_bytes + image_bytes]), #channel x height x width로 변환함.\n",
    "                             [result.depth, result.height, result.width])\n",
    "    \n",
    "    result.uint8image = tf.transpose(depth_major, [1,2,0]) #channel x height x width >>> height x width x chennl로 변경\n",
    "    \n",
    "    return result\n",
    "\n",
    "#label, image 세팅해줌 \n",
    "def _generate_image_and_label_batch(image, label, min_queue_examples,\n",
    "                                    batch_size, shuffle):\n",
    "    \"\"\"Construct a queued batch of images and labels.\n",
    "    Args:\n",
    "      image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "      label: 1-D Tensor of type.int32\n",
    "      min_queue_examples: int32, minimum number of samples to retain\n",
    "        in the queue that provides of batches of examples.\n",
    "      batch_size: Number of images per batch.\n",
    "      shuffle: boolean indicating whether to use a shuffling queue.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    # Create a queue that shuffles the examples, and then\n",
    "    # read 'batch_size' images + labels from the example queue.\n",
    "    num_preprocess_threads = 16 #프로세스 스레드 \n",
    "    if shuffle: #셔플 하면 \n",
    "        images, label_batch = tf.train.shuffle_batch([image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size,\n",
    "            min_after_dequeue=min_queue_examples) #이거만 해주면 batch와 동일함. \n",
    "    #Minimum number elements in the queue after a dequeue, used to ensure a level of mixing of elements.\n",
    "    else:\n",
    "        images, label_batch = tf.train.batch([image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "    # Display the training images in the visualizer.\n",
    "    tf.summary.image('images', images) #걍 보드용인듯\n",
    "\n",
    "    return images, tf.reshape(label_batch, [batch_size])\n",
    "\n",
    "\n",
    "def distorted_inputs(data_dir, batch_size): #좀 드럽게 인풋받아오기 \n",
    "    \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "    Args:\n",
    "      data_dir: Path to the CIFAR-10 data directory.\n",
    "      batch_size: Number of images per batch.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)] \n",
    "    for f in filenames:\n",
    "        if not tf.gfile.Exists(f):\n",
    "            raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "    # Create a queue that produces the filenames to read.\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "    # Read examples from files in the filename queue.\n",
    "    read_input = read_dataset(filename_queue)\n",
    "    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "    height = INPUT_SIDE\n",
    "    width = INPUT_SIDE\n",
    "\n",
    "    # Image processing for training the network.  Note the many random\n",
    "    # distortions applied to the image.\n",
    "\n",
    "    # Randomly crop a [height, width] section of the image.\n",
    "    distorted_image = tf.random_crop(reshaped_image, [height, width, 3]) # 랜덤으로 이미지를 크롭 h x w x c\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    distorted_image = tf.image.random_flip_left_right(distorted_image) # 또 랜덤으로 좌우 플립 random_flip_up_down도 있긴 함\n",
    "    #이런 느낌..? 으로 맥스텔타가지고 유니폼으로 어쩌구저쩌구\n",
    "    #delta = random_ops.random_uniform([], -max_delta, max_delta, seed=seed)\n",
    "    #return adjust_brightness(image, delta)\n",
    "\n",
    "    # Because these operations are not commutative, consider randomizing\n",
    "    # the order their operation.\n",
    "    distorted_image = tf.image.random_brightness(distorted_image,    #랜덤으로 밝기 조절 \n",
    "                                               max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(distorted_image,      #콘트라스트 조절 랜덤. 기존 픽셀값의 최소 0.2 최대 1.8\n",
    "                                             lower=0.2, upper=1.8)\n",
    "\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    float_image = tf.image.per_image_standardization(distorted_image) #표준화시킴. mean으로빼고 var로 나눔\n",
    "\n",
    "    # Set the shapes of tensors.\n",
    "    float_image.set_shape([height, width, 3])\n",
    "    read_input.label.set_shape([1])\n",
    "\n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH * min_fraction_of_examples_in_queue)\n",
    "    print('Filling queue with %d CIFAR images before starting to train. '\n",
    "         'This will take a few minutes.' % min_queue_examples)\n",
    "\n",
    "    # Generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(float_image, read_input.label,\n",
    "                                         min_queue_examples, batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "\n",
    "def inputs(eval_data, data_dir, batch_size):\n",
    "    \"\"\"Construct input for CIFAR evaluation using the Reader ops.\n",
    "    Args:\n",
    "    eval_data: bool, indicating if one should use the train or eval data set.\n",
    "    data_dir: Path to the CIFAR-10 data directory.\n",
    "    batch_size: Number of images per batch.\n",
    "    Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    if not eval_data:\n",
    "        filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n",
    "                     for i in xrange(1, 6)]\n",
    "        num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH\n",
    "    else:\n",
    "        filenames = [os.path.join(data_dir, 'test_batch.bin')]\n",
    "        num_examples_per_epoch = NUM_TESTSET_PER_EPOCH\n",
    "\n",
    "    for f in filenames:\n",
    "        if not tf.gfile.Exists(f):\n",
    "             raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "    # Create a queue that produces the filenames to read.\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "    # Read examples from files in the filename queue.\n",
    "    read_input = read_dataset(filename_queue)\n",
    "    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "    height = INPUT_SIDE\n",
    "    width = INPUT_SIDE\n",
    "\n",
    "    # Image processing for evaluation.\n",
    "    # Crop the central [height, width] of the image.\n",
    "    resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,\n",
    "                                                         height, width)\n",
    "\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    float_image = tf.image.per_image_standardization(resized_image)\n",
    "\n",
    "    # Set the shapes of tensors.\n",
    "    float_image.set_shape([height, width, 3])\n",
    "    read_input.label.set_shape([1])\n",
    "\n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH * min_fraction_of_examples_in_queue)\n",
    "\n",
    "    # Generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(float_image, read_input.label,\n",
    "                                         min_queue_examples, batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "\n",
    "print(\"FUNCTIONS READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NETWORK PARAMETERS\n",
    "\n",
    "stddev = 0.1\n",
    "\n",
    "weights = {\n",
    "    #'conv' : tf.Variable(tf.random_normal([3, 3, N_CHANNEL, 16], stddev=stddev), name='conv'),\n",
    "    'conv' : tf.get_variable(name=\"conv\", shape=[3, 3, N_CHANNEL, 16], initializer=xavier_init(N_CHANNEL, 16)),\n",
    "    'conv1_1x1' : tf.get_variable(name=\"conv1_1x1\", shape=[1, 1, 16, 4], initializer=xavier_init(16, 4)),\n",
    "    'conv1_3x3' : tf.get_variable(name=\"conv1_3x3\", shape=[3, 3, 4, 4], initializer=xavier_init(4, 4)),\n",
    "    'conv1_1x1_16' : tf.get_variable(name=\"conv1_1x1_16\", shape=[1, 1, 4, 16], initializer=xavier_init(4, 16)),\n",
    "    'conv2_1x1' : tf.get_variable(name=\"conv2_1x1\", shape=[1, 1, 16, 4], initializer=xavier_init(16, 4)),\n",
    "    'conv2_3x3' : tf.get_variable(name=\"conv2_3x3\", shape=[3, 3, 4, 4], initializer=xavier_init(4, 4)),\n",
    "    'conv2_1x1_16' : tf.get_variable(name=\"conv2_1x1_16\", shape=[1, 1, 4, 16], initializer=xavier_init(4, 16)),\n",
    "    \n",
    "    # conv 16 + conv2 16 = 32filters \n",
    "    \n",
    "    'conv3_1x1' : tf.get_variable(name=\"conv3_1x1\", shape=[1, 1, 32, 8], initializer=xavier_init(32, 8)),\n",
    "    'conv3_3x3' : tf.get_variable(name=\"conv3_3x3\", shape=[3, 3, 8, 8], initializer=xavier_init(8, 8)),\n",
    "    'conv3_1x1_32' : tf.get_variable(name=\"conv3_1x1_32\", shape=[1, 1, 8, 32], initializer=xavier_init(8, 32)),\n",
    "    'conv4_1x1' : tf.get_variable(name=\"conv4_1x1\", shape=[1, 1, 32, 8], initializer=xavier_init(32, 8)),\n",
    "    'conv4_3x3' : tf.get_variable(name=\"conv4_3x3\", shape=[3, 3, 8, 8], initializer=xavier_init(8, 8)),\n",
    "    'conv4_1x1_32' : tf.get_variable(name=\"conv4_1x1_32\", shape=[1, 1, 8, 32], initializer=xavier_init(8, 32)),\n",
    "    \n",
    "    # conv2 지난거32 + conv4 32 = 64\n",
    "    \n",
    "    'conv5_1x1' : tf.get_variable(name=\"conv5_1x1\", shape=[1, 1, 64, 16], initializer=xavier_init(64, 16)),\n",
    "    'conv5_3x3' : tf.get_variable(name=\"conv5_3x3\", shape=[3, 3, 16, 16], initializer=xavier_init(16, 16)),\n",
    "    'conv5_1x1_64' : tf.get_variable(name=\"conv5_1x1_64\", shape=[1, 1, 16, 64], initializer=xavier_init(16, 64)),\n",
    "    'conv6_1x1' : tf.get_variable(name=\"conv6_1x1\", shape=[1, 1, 64, 16], initializer=xavier_init(64, 16)),\n",
    "    'conv6_3x3' : tf.get_variable(name=\"conv6_3x3\", shape=[3, 3, 16, 16], initializer=xavier_init(16, 16)),\n",
    "    'conv6_1x1_64' : tf.get_variable(name=\"conv6_1x1_64\", shape=[1, 1, 16, 64], initializer=xavier_init(16, 64)),\n",
    "    \n",
    "    #conv4 지난거 64 + conv6 64 = 128\n",
    "    \n",
    "    'dense1' : tf.get_variable(name=\"dense1\", shape=[16*16*128, 1000], initializer=xavier_init(16*16*128, 1000)),\n",
    "    'dense2' : tf.get_variable(name=\"dense2\", shape=[1000, N_CLASSES], initializer=xavier_init(1000, N_CLASSES))    \n",
    "}\n",
    "#conv net biases 현재 사용하지 않음. \n",
    "biases = {\n",
    "    'conv' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv_b')),\n",
    "    'conv1_1x1' : tf.Variable(tf.random_normal([4], stddev=stddev, name='conv1_1x1_b')),\n",
    "    'conv1_3x3' : tf.Variable(tf.random_normal([4], stddev=stddev, name='conv1_3x3_b')),\n",
    "    'conv1_1x1_16' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv1_1x1_16_b')),\n",
    "    'conv2_1x1' : tf.Variable(tf.random_normal([4], stddev=stddev, name='conv2_1x1_b')),\n",
    "    'conv2_3x3' :tf.Variable(tf.random_normal([4], stddev=stddev, name='conv2_3x3_b')),\n",
    "    'conv2_1x1_16' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv2_1x1_16_b')),\n",
    "    \n",
    "    'conv3_1x1' : tf.Variable(tf.random_normal([8], stddev=stddev, name='conv3_1x1_b')),\n",
    "    'conv3_3x3' : tf.Variable(tf.random_normal([8], stddev=stddev, name='conv3_3x3_b')),\n",
    "    'conv3_1x1_32' : tf.Variable(tf.random_normal([32], stddev=stddev, name='conv3_1x1_32_b')),\n",
    "    'conv4_1x1' : tf.Variable(tf.random_normal([8], stddev=stddev, name='conv4_1x1_b')),\n",
    "    'conv4_3x3' : tf.Variable(tf.random_normal([8], stddev=stddev, name='conv4_3x3_b')),\n",
    "    'conv4_1x1_32' : tf.Variable(tf.random_normal([32], stddev=stddev, name='conv4_1x1_32_b')),\n",
    "    \n",
    "    'conv5_1x1' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv5_1x1_b')),\n",
    "    'conv5_3x3' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv5_3x3_b')),\n",
    "    'conv5_1x1_64' : tf.Variable(tf.random_normal([64], stddev=stddev, name='conv5_1x1_64_b')),\n",
    "    'conv6_1x1' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv6_1x1_b')),\n",
    "    'conv6_3x3' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv6_3x3_b')),\n",
    "    'conv6_1x1_64' : tf.Variable(tf.random_normal([64], stddev=stddev, name='conv6_1x1_64_b')),\n",
    "    \n",
    "    'dense1' : tf.Variable(tf.random_normal([1000], stddev=stddev, name='dense1_b')),\n",
    "    'dense2' : tf.Variable(tf.random_normal([N_CLASSES], stddev=stddev, name='dense2_b'))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model\n",
    "#http://laonple.blog.me/220764986252 - bottleneck \n",
    "#conv 3x3\n",
    "#conv (1x1, 3x3, 1x1) - relu > 16\n",
    "#conv (1x1, 3x3, 1x1) relu > 32\n",
    "#conv (1x1, 3x3, 1x1) relu > 64\n",
    "#avg pooling \n",
    "#fc\n",
    "#softmax\n",
    "def ResNet(img_width, img_height, img_channel, _x, _w, _b, scope='ResNet', training=None, reuse=None):\n",
    "    network = OrderedDict() #network layers\n",
    "\n",
    "    # X RESHAPE\n",
    "    _x_r = tf.reshape(_x, shape=[-1,img_width,img_height, img_channel])\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        with tf.name_scope('conv') as scope:\n",
    "            conv = tf.nn.conv2d(_x_r, _w['conv'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv = batch_norm(conv, 16, training)\n",
    "            #conv = tf.layers.batch_normalization(conv, training=training, name='bn_conv')\n",
    "            conv = tf.nn.relu(conv)\n",
    "            network['conv'] = conv\n",
    "        \n",
    "        #16\n",
    "        with tf.name_scope('conv2') as scope:\n",
    "            conv1_1x1 = tf.nn.conv2d(conv, _w['conv1_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv1_1x1 = tf.nn.relu(conv1_1x1)\n",
    "            conv1_3x3 = tf.nn.conv2d(conv1_1x1, _w['conv1_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv1_3x3 = tf.nn.relu(conv1_3x3)\n",
    "            conv1_1x1_16 = tf.nn.conv2d(conv1_3x3, _w['conv1_1x1_16'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv1_1x1_16 = tf.layers.batch_normalization(conv1_1x1_16, training=training, name='bn_conv1')\n",
    "            conv1_1x1_16 = batch_norm(conv1_1x1_16, 16, training)\n",
    "            conv1_1x1_16 = tf.nn.relu(conv1_1x1_16)\n",
    "            network['conv1_1x1_16'] = conv1_1x1_16\n",
    "        \n",
    "        #16\n",
    "        with tf.name_scope('conv3') as scope:\n",
    "            conv2_1x1 = tf.nn.conv2d(conv1_1x1_16, _w['conv2_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv2_1x1 = tf.nn.relu(conv2_1x1)\n",
    "            conv2_3x3 = tf.nn.conv2d(conv2_1x1, _w['conv2_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv2_3x3 = tf.nn.relu(conv2_3x3)\n",
    "            conv2_1x1_16 = tf.nn.conv2d(conv2_3x3, _w['conv2_1x1_16'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv2_1x1_16 = tf.layers.batch_normalization(conv2_1x1_16, training=training, name='bn_conv2')\n",
    "            conv2_1x1_16 = batch_norm(conv2_1x1_16, 16, training)\n",
    "            #32\n",
    "            conv2_1x1_16 = tf.concat([conv, conv2_1x1_16], 3) \n",
    "            conv2_1x1_16 = tf.nn.relu(conv2_1x1_16)\n",
    "            network['conv2_1x1_16'] = conv2_1x1_16\n",
    "       \n",
    "        #32       32 x 32 x 16+16 >>> \n",
    "        with tf.name_scope('conv4') as scope:\n",
    "            conv3_1x1 = tf.nn.conv2d(conv2_1x1_16, _w['conv3_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv3_1x1 = tf.nn.relu(conv3_1x1)\n",
    "            conv3_3x3 = tf.nn.conv2d(conv3_1x1, _w['conv3_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv3_3x3 = tf.nn.relu(conv3_3x3)\n",
    "            conv3_1x1_32 = tf.nn.conv2d(conv3_3x3, _w['conv3_1x1_32'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv3_1x1_32 = tf.layers.batch_normalization(conv3_1x1_32, training=training, name='bn_conv3')\n",
    "            conv3_1x1_32 = batch_norm(conv3_1x1_32, 32, training)\n",
    "            conv3_1x1_32 = tf.nn.relu(conv3_1x1_32)\n",
    "            network['conv3_1x1_32'] = conv3_1x1_32\n",
    "        \n",
    "        with tf.name_scope('conv5') as scope:\n",
    "            conv4_1x1 = tf.nn.conv2d(conv3_1x1_32, _w['conv4_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv4_1x1 = tf.nn.relu(conv4_1x1)\n",
    "            conv4_3x3 = tf.nn.conv2d(conv4_1x1, _w['conv4_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv4_3x3 = tf.nn.relu(conv4_3x3)\n",
    "            conv4_1x1_32 = tf.nn.conv2d(conv4_3x3, _w['conv4_1x1_32'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv4_1x1_32 = tf.layers.batch_normalization(conv4_1x1_32, training=training, name='bn_conv4')\n",
    "            conv4_1x1_32 = batch_norm(conv4_1x1_32, 32, training)\n",
    "\n",
    "            #64\n",
    "            conv4_1x1_32 = tf.concat([conv2_1x1_16, conv4_1x1_32 ], 3)\n",
    "            conv4_1x1_32 = tf.nn.relu(conv4_1x1_32)\n",
    "            network['conv4_1x1_32'] = conv4_1x1_32\n",
    "    \n",
    "        with tf.name_scope('conv6') as scope:\n",
    "            conv5_1x1 = tf.nn.conv2d(conv4_1x1_32, _w['conv5_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv5_1x1 = tf.nn.relu(conv5_1x1)\n",
    "            conv5_3x3 = tf.nn.conv2d(conv5_1x1, _w['conv5_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv5_3x3 = tf.nn.relu(conv5_3x3)\n",
    "            conv5_1x1_64 = tf.nn.conv2d(conv5_3x3, _w['conv5_1x1_64'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv5_1x1_64 = tf.layers.batch_normalization(conv5_1x1_64, training=training, name='bn_conv5')\n",
    "            conv5_1x1_64 = batch_norm(conv5_1x1_64, 64, training)\n",
    "            conv5_1x1_64 = tf.nn.relu(conv5_1x1_64)\n",
    "            network['conv5_1x1_64'] = conv5_1x1_64\n",
    "        \n",
    "        with tf.name_scope('conv7') as scope:\n",
    "            conv6_1x1 = tf.nn.conv2d(conv5_1x1_64, _w['conv6_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv6_1x1 = tf.nn.relu(conv6_1x1)\n",
    "            conv6_3x3 = tf.nn.conv2d(conv6_1x1, _w['conv6_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv6_3x3 = tf.nn.relu(conv6_3x3)\n",
    "            conv6_1x1_64 = tf.nn.conv2d(conv6_3x3, _w['conv6_1x1_64'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv6_1x1_64 = tf.layers.batch_normalization(conv6_1x1_64, training=training, name='bn_conv6')\n",
    "            conv6_1x1_64 = batch_norm(conv6_1x1_64, 64, training)\n",
    "            \n",
    "            #128\n",
    "            conv6_1x1_64 = tf.concat([conv4_1x1_32, conv6_1x1_64],3)\n",
    "            conv6_1x1_64 = tf.nn.relu(conv6_1x1_64)\n",
    "            network['conv6_1x1_64'] = conv6_1x1_64\n",
    "        \n",
    "        with tf.name_scope('pool') as scope:\n",
    "            pool = tf.nn.avg_pool(conv6_1x1_64, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "            network['pool'] = pool\n",
    "            \n",
    "        def dropout(pool):\n",
    "            return tf.nn.dropout(pool, 0.5, name='dropout')\n",
    "        def none(pool):\n",
    "            return pool\n",
    "        \n",
    "        #with tf.name_scope('dropout') as scope:      \n",
    "            #pool = tf.cond(training, lambda: dropout(pool), lambda: none(pool))\n",
    "        \n",
    "        with tf.name_scope('dense1') as scope:\n",
    "            dense = tf.reshape(pool, [-1, _w['dense1'].get_shape().as_list()[0]])\n",
    "            dense1 = tf.add(tf.matmul(dense, _w['dense1']), _b['dense1'])\n",
    "            #dense1 =  tf.layers.batch_normalization(dense1, training=training, name='bn_dense')\n",
    "            dense1 = batch_norm_for_dense_layer(dense1, 1000, training)\n",
    "            dense1 = tf.nn.relu(dense1)\n",
    "            network['dense1'] = dense1\n",
    "            \n",
    "        with tf.name_scope('logit') as scope:\n",
    "            logit = tf.add(tf.matmul(dense1, _w['dense2']), _b['dense2'])\n",
    "            network['logit'] = logit\n",
    "            \n",
    "        \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for train\n",
    "images, labels = distorted_inputs(DATA_PATH, BATCH_SIZE)\n",
    "labels = tf.one_hot(indices=labels, depth=N_CLASSES, on_value=1, off_value=0, axis=1)\n",
    "print(labels.shape)\n",
    "\n",
    "out = ResNet(INPUT_SIDE, INPUT_SIDE, N_CHANNEL, images, weights, biases, 'ResNet', training)\n",
    "\n",
    "for key, value in out.items():\n",
    "    print (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=out['logit']))\n",
    "tf.summary.scalar(\"loss\", loss) #save loss \n",
    "print(\"LOSS FUNCTION\")\n",
    "\n",
    "learning_rate = tf.placeholder(dtype=tf.float32)\n",
    "learning_rate = tf.maximum(learning_rate, 0.0001)\n",
    "tf.summary.scalar(\"learning_rate\", learning_rate) #learning rate\n",
    "print(\"LERANING RATE : {}\".format(learning_rate))\n",
    "\n",
    "#optimizer\n",
    "adam = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "sgd = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "\n",
    "corr = tf.equal(tf.argmax(out['logit'], 1), tf.argmax(labels,1))\n",
    "accr = tf.reduce_mean(tf.cast(corr, \"float\"))\n",
    "tf.summary.scalar(\"accuracy\", accr) #save accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SESSION INITIALIZE\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "#SAVER\n",
    "saver = tf.train.Saver(max_to_keep=3) #최근 3개까지만 저장\n",
    "save_step = 100 #save for 100 epoch\n",
    "if not os.path.exists(CHECKPOINT_PATH):\n",
    "    os.makedirs(CHECKPOINT_PATH)\n",
    "print(CHECKPOINT_PATH)\n",
    "    \n",
    "#restore checkpoint\n",
    "checkpoint = tf.train.latest_checkpoint(CHECKPOINT_PATH)\n",
    "if checkpoint is not None:\n",
    "    print(checkpoint)\n",
    "    #saver.restore(sess, checkpoint)\n",
    "    \n",
    "#TENSOR BOARD\n",
    "summary_op = tf.summary.merge_all()\n",
    "summary_writer = tf.summary.FileWriter(BOARD_PATH, sess.graph)\n",
    "\n",
    "#QUEUE\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "\n",
    "print(\"initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training\n",
    "train_loss_for_plot = []\n",
    "train_acc_for_plot = []\n",
    "test_loss_for_plot = []\n",
    "test_acc_for_plot = []\n",
    "\n",
    "print('start')\n",
    "for epoch in range(EPOCHS):\n",
    "    print(epoch)\n",
    "    global_stop = epoch #lr decay\n",
    "    nNumBatch = 0 # batch 수\n",
    "    AvgBatchCost = 0 #cost 합산\n",
    "    for i in range(int(NUM_BATCHES_PER_EPOCH)):\n",
    "        nNumBatch += 1\n",
    "        if epoch < EPOCHS * 0.5:\n",
    "            _, tmp_cost = sess.run([adam, loss], feed_dict={training: True, learning_rate : LR})\n",
    "        else:\n",
    "            #print('use sgd')\n",
    "            _, tmp_cost = sess.run([sgd, loss], feed_dict={training: True, learning_rate : LR})\n",
    "            \n",
    "        AvgBatchCost += tmp_cost\n",
    "    \n",
    "        if nNumBatch % 100 == 0:#print\n",
    "            train_acc = sess.run(accr, feed_dict={training: True, learning_rate : LR})\n",
    "            print('\\t[%d nNumBatch] train cost = %g, acc = %g' %(nNumBatch, AvgBatchCost/nNumBatch, train_acc ))\n",
    "            print('\\t\\t learning rate = %g'%(LR))\n",
    "            train_loss_for_plot.append(AvgBatchCost/nNumBatch)\n",
    "            train_acc_for_plot.append(train_acc)\n",
    "            \n",
    "    if epoch % 10 == 0: #test\n",
    "        if epoch % 350 == 0: #learning_rate decay\n",
    "            LR = np.maximum(LR*LR_DECAY_RATE, 0.0001)\n",
    "        save_path = saver.save(sess, CHECKPOINT_PATH + CHECKPOINT, global_step=epoch)\n",
    "        print(save_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "489\n",
    "\t[100 nNumBatch] train cost = 0.145597, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[200 nNumBatch] train cost = 0.140672, acc = 0.921875\n",
    "\t\t learning rate = 0.025\n",
    "\t[300 nNumBatch] train cost = 0.136403, acc = 0.984375\n",
    "\t\t learning rate = 0.025\n",
    "\t[400 nNumBatch] train cost = 0.137039, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[500 nNumBatch] train cost = 0.137608, acc = 0.984375\n",
    "\t\t learning rate = 0.025\n",
    "\t[600 nNumBatch] train cost = 0.136599, acc = 0.921875\n",
    "\t\t learning rate = 0.025\n",
    "\t[700 nNumBatch] train cost = 0.135711, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "490\n",
    "\t[100 nNumBatch] train cost = 0.12827, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[200 nNumBatch] train cost = 0.13435, acc = 0.921875\n",
    "\t\t learning rate = 0.025\n",
    "\t[300 nNumBatch] train cost = 0.132003, acc = 0.90625\n",
    "\t\t learning rate = 0.025\n",
    "\t[400 nNumBatch] train cost = 0.132804, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[500 nNumBatch] train cost = 0.132613, acc = 0.90625\n",
    "\t\t learning rate = 0.025\n",
    "\t[600 nNumBatch] train cost = 0.132854, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[700 nNumBatch] train cost = 0.13302, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "./checkpoint/res_13simple_res_net_train_13.ckpt-490\n",
    "491\n",
    "\t[100 nNumBatch] train cost = 0.124551, acc = 0.984375\n",
    "\t\t learning rate = 0.025\n",
    "\t[200 nNumBatch] train cost = 0.13069, acc = 0.921875\n",
    "\t\t learning rate = 0.025\n",
    "\t[300 nNumBatch] train cost = 0.128858, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[400 nNumBatch] train cost = 0.130519, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[500 nNumBatch] train cost = 0.128711, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[600 nNumBatch] train cost = 0.127134, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[700 nNumBatch] train cost = 0.128334, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "492\n",
    "\t[100 nNumBatch] train cost = 0.143408, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[200 nNumBatch] train cost = 0.138828, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[300 nNumBatch] train cost = 0.138844, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[400 nNumBatch] train cost = 0.136855, acc = 0.9375\n",
    "\t\t learning rate = 0.025\n",
    "\t[500 nNumBatch] train cost = 0.13883, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[600 nNumBatch] train cost = 0.13962, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[700 nNumBatch] train cost = 0.13871, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "493\n",
    "\t[100 nNumBatch] train cost = 0.158883, acc = 0.984375\n",
    "\t\t learning rate = 0.025\n",
    "\t[200 nNumBatch] train cost = 0.140503, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[300 nNumBatch] train cost = 0.136878, acc = 0.9375\n",
    "\t\t learning rate = 0.025\n",
    "\t[400 nNumBatch] train cost = 0.135711, acc = 0.875\n",
    "\t\t learning rate = 0.025\n",
    "\t[500 nNumBatch] train cost = 0.136133, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[600 nNumBatch] train cost = 0.135822, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[700 nNumBatch] train cost = 0.133217, acc = 0.9375\n",
    "\t\t learning rate = 0.025\n",
    "494\n",
    "\t[100 nNumBatch] train cost = 0.134596, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[200 nNumBatch] train cost = 0.133625, acc = 0.9375\n",
    "\t\t learning rate = 0.025\n",
    "\t[300 nNumBatch] train cost = 0.135847, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[400 nNumBatch] train cost = 0.136833, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[500 nNumBatch] train cost = 0.138569, acc = 0.984375\n",
    "\t\t learning rate = 0.025\n",
    "\t[600 nNumBatch] train cost = 0.136164, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[700 nNumBatch] train cost = 0.136959, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "495\n",
    "\t[100 nNumBatch] train cost = 0.14163, acc = 0.90625\n",
    "\t\t learning rate = 0.025\n",
    "\t[200 nNumBatch] train cost = 0.138531, acc = 0.9375\n",
    "\t\t learning rate = 0.025\n",
    "\t[300 nNumBatch] train cost = 0.134399, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[400 nNumBatch] train cost = 0.133423, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[500 nNumBatch] train cost = 0.134911, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[600 nNumBatch] train cost = 0.134009, acc = 0.984375\n",
    "\t\t learning rate = 0.025\n",
    "\t[700 nNumBatch] train cost = 0.1344, acc = 1\n",
    "\t\t learning rate = 0.025\n",
    "496\n",
    "\t[100 nNumBatch] train cost = 0.121793, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[200 nNumBatch] train cost = 0.130601, acc = 0.9375\n",
    "\t\t learning rate = 0.025\n",
    "\t[300 nNumBatch] train cost = 0.128526, acc = 0.921875\n",
    "\t\t learning rate = 0.025\n",
    "\t[400 nNumBatch] train cost = 0.130992, acc = 0.9375\n",
    "\t\t learning rate = 0.025\n",
    "\t[500 nNumBatch] train cost = 0.131741, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[600 nNumBatch] train cost = 0.131921, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[700 nNumBatch] train cost = 0.133577, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "497\n",
    "\t[100 nNumBatch] train cost = 0.132565, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[200 nNumBatch] train cost = 0.132672, acc = 1\n",
    "\t\t learning rate = 0.025\n",
    "\t[300 nNumBatch] train cost = 0.133455, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[400 nNumBatch] train cost = 0.132323, acc = 0.984375\n",
    "\t\t learning rate = 0.025\n",
    "\t[500 nNumBatch] train cost = 0.131533, acc = 0.984375\n",
    "\t\t learning rate = 0.025\n",
    "\t[600 nNumBatch] train cost = 0.134091, acc = 0.9375\n",
    "\t\t learning rate = 0.025\n",
    "\t[700 nNumBatch] train cost = 0.135591, acc = 0.875\n",
    "\t\t learning rate = 0.025\n",
    "498\n",
    "\t[100 nNumBatch] train cost = 0.131679, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[200 nNumBatch] train cost = 0.1323, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[300 nNumBatch] train cost = 0.13487, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[400 nNumBatch] train cost = 0.136457, acc = 0.890625\n",
    "\t\t learning rate = 0.025\n",
    "\t[500 nNumBatch] train cost = 0.137181, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[600 nNumBatch] train cost = 0.136403, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[700 nNumBatch] train cost = 0.134424, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "499\n",
    "\t[100 nNumBatch] train cost = 0.135501, acc = 0.9375\n",
    "\t\t learning rate = 0.025\n",
    "\t[200 nNumBatch] train cost = 0.136786, acc = 0.984375\n",
    "\t\t learning rate = 0.025\n",
    "\t[300 nNumBatch] train cost = 0.135682, acc = 0.96875\n",
    "\t\t learning rate = 0.025\n",
    "\t[400 nNumBatch] train cost = 0.134176, acc = 0.9375\n",
    "\t\t learning rate = 0.025\n",
    "\t[500 nNumBatch] train cost = 0.133838, acc = 0.9375\n",
    "\t\t learning rate = 0.025\n",
    "\t[600 nNumBatch] train cost = 0.133217, acc = 0.953125\n",
    "\t\t learning rate = 0.025\n",
    "\t[700 nNumBatch] train cost = 0.13238, acc = 1\n",
    "\t\t learning rate = 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "print('thread is stopped')\n",
    "sess.close()\n",
    "print('session closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 피드딕트로 넣어줘야 함. 이건 이미지 불러오고 corr, accuracy 까지 다 변경해야함\n",
    "# 2. 다 해서 돌린다음에 안되는거같다 싶으면 nn -> layers.batch_norm으로 변경\n",
    "# 3. 테스트 끝나면 대략 2000~3000에폭 돌려서 ckpt 가져와서 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_loss_for_plot, file=train_loss_out)\n",
    "print(train_acc_for_plot, file=train_accr_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LOSS\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "y = loss_for_plot\n",
    "plt.plot(x,y, color=\"red\")\n",
    "plt.plot()\n",
    "plt.xlabel(\"batch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"LOSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ACCURACY\n",
    "x = np.linspace(0, len(y_ac), len(y_ac))\n",
    "y_ac = acc_for_plot\n",
    "plt.plot(x,y_ac, color=\"blue\")\n",
    "plt.plot()\n",
    "plt.xlabel(\"batch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"ACCURACY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load test data\n",
    "images_test, labels_test = inputs(eval_data=True, data_dir=DATA_PATH, batch_size=BATCH_SIZE )\n",
    "labels_test = tf.one_hot(indices=labels_test, depth=N_CLASSES, on_value=1, off_value=0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sesstion initialize\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "#queue\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord, sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#restore checkpoint\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "CHECKPOINT_PATH = './checkpoint'\n",
    "#./checkpoint/res_13simple_res_net_train_13.ckpt-490\n",
    "checkpoint = tf.train.latest_checkpoint(CHECKPOINT_PATH)\n",
    "if checkpoint is not None:\n",
    "    print(checkpoint)\n",
    "    saver.restore(sess, checkpoint)\n",
    "    print('restored')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = ResNet(INPUT_SIDE, INPUT_SIDE, N_CHANNEL, images_test, weights, biases, 'ResNet', training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_test = tf.equal(tf.argmax(test['logit'], 1), tf.argmax(labels_test,1))\n",
    "accr_test = tf.reduce_mean(tf.cast(corr_test, \"float\"))\n",
    "tf.summary.scalar(\"test_accuracy\", accr_test) #save accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "test_acc_for_plot = []\n",
    "\n",
    "\n",
    "print('start')\n",
    "for step in range(int(EPOCHS/10)):\n",
    "    test_acc = sess.run(accr_test, feed_dict={training: False})\n",
    "    print('[%d EPOCH] TEST ACC = %g%%' %(step, test_acc*100))\n",
    "    test_acc_for_plot.append(test_acc)\n",
    "    \n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(test_acc_for_plot, file=test_accr_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = test_acc_for_plot\n",
    "x = np.linspace(0, len(y), len(y))\n",
    "\n",
    "plt.plot(x,y, color=\"red\")\n",
    "plt.plot()\n",
    "plt.xlabel(\".\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"LOSS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHOW TRAINED FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "print('thread is stopped')\n",
    "sess.close()\n",
    "print('session closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sesstion initialize\n",
    "init = tf.global_variables_initializer()\n",
    "init_local = tf.local_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#restore checkpoint\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "CHECKPOINT_PATH = './checkpoint'\n",
    "#./checkpoint/res_13simple_res_net_train_13.ckpt-490\n",
    "checkpoint = tf.train.latest_checkpoint(CHECKPOINT_PATH)\n",
    "if checkpoint is not None:\n",
    "    print(checkpoint)\n",
    "    saver.restore(sess, checkpoint)\n",
    "    print('restored')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input \n",
    "datapath = 'cifar10/cifar-10-batches-py/'\n",
    "test_file=['test_batch']\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_num = 105\n",
    "data = unpickle(datapath+test_file[0])\n",
    "print(type(data))\n",
    "for val in data.keys():\n",
    "    print(val)\n",
    "print(data[b'labels'][data_num])\n",
    "print(LIST_CLASS[data[b'labels'][data_num]])\n",
    "print(data[b'filenames'][data_num])\n",
    "print(data[b'data'][data_num])\n",
    "input_img = tf.cast(data[b'data'][data_num], tf.float32)\n",
    "\n",
    "reshape_img = np.reshape(data[b'data'][data_num], [3, 32, 32])\n",
    "img = np.transpose(reshape_img, (1,2,0))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Res = ResNet(INPUT_SIDE, INPUT_SIDE, N_CHANNEL, input_img, weights, biases, 'ResNet', training)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHOW FEATURE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer_name in Res:\n",
    "    if layer_name.startswith('dense'): break\n",
    "    print(layer_name)\n",
    "    feature = sess.run(Res[layer_name], feed_dict={training: False})\n",
    "    # feature \n",
    "    print(feature.shape)\n",
    "    for no in range(feature.shape[3]): #feature no.\n",
    "        plt.matshow(feature[0,:,:,no], cmap=plt.cm.gray_r)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#show feature\n",
    "for layer_name in Res:\n",
    "    if layer_name.startswith('dense'): break\n",
    "    print(layer_name)\n",
    "    plt.matshow(Res[layer_name].eval(session=sess, feed_dict={training: False})[0, :, :, 1], cmap=plt.cm.gray)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHOW WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = sess.run(weights)\n",
    "for key, value in weight.items():\n",
    "    if key.startswith('dense'): continue\n",
    "    print(key)\n",
    "    print(value.shape)\n",
    "    \n",
    "    if key.endswith('1x1') or key.endswith('16') or key.endswith('32') or key.endswith('64'): \n",
    "        for i in range(value.shape[2]):\n",
    "            for o in range(value.shape[3]):\n",
    "                print(\"%d , %d : %g\" %(i,o,value[0,0,i,o]))\n",
    "        continue\n",
    "    for i in range(value.shape[2]):\n",
    "        for o in range(value.shape[3]):\n",
    "            plt.imshow(value[:,:,i,o], cmap=plt.cm.gray)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
