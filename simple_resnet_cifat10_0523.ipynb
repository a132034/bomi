{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT\n",
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "print(\"IMPORT\")\n",
    "import tensorflow as tf #tensorflow\n",
    "print(tf.__version__)\n",
    "import numpy as np #numpy > save loss .. \n",
    "from collections import OrderedDict #layer ..\n",
    "import os, random #dir, random..\n",
    "import pickle #save & load\n",
    "\n",
    "# cifar 10 \n",
    "#wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "#tar xzf cifar-10-python.tar.gz\n",
    "\n",
    "#resnet\n",
    "#https://arxiv.org/abs/1512.03385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATHS\n",
      "VARIABLES\n",
      "input image size : 1024\n",
      "image channel : 3\n",
      "batch size : 64\n",
      "num of class : 10\n",
      "training epochs : 100\n",
      "learning rate : 0.01\n",
      "learning decay rate : 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"PATHS\")\n",
    "#path\n",
    "DATA_PATH = 'cifar10/cifar-10-batches-py/'\n",
    "CHECKPOINT = 'simple_res_net.ckpt'\n",
    "SAVE_PATH = 'checkpoint/simple_res_net/'\n",
    "BOARD_PATH = './tensorboard/board_res_net'\n",
    "print(\"VARIABLES\")\n",
    "#parameters\n",
    "INPUT_SIDE = 32\n",
    "INPUT_SIZE = INPUT_SIDE * INPUT_SIDE\n",
    "N_CHANNEL = 3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LR = 0.01\n",
    "LR_DECAY_RATE = 0.5\n",
    "\n",
    "LIST_CLASS=['airplane', 'automobile', 'birds', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "N_CLASSES = len(LIST_CLASS)\n",
    "\n",
    "#train&test batch\n",
    "train_file=['data_batch_1','data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5']\n",
    "test_file=['cifar10/cifar-10-batches-py/test_batch']\n",
    "\n",
    "#input & output \n",
    "x = tf.placeholder(\"float\", [BATCH_SIZE, INPUT_SIZE * N_CHANNEL]) #batch x image size\n",
    "y = tf.placeholder(\"float\", [BATCH_SIZE, N_CLASSES]) #batch x class`\n",
    "\n",
    "\n",
    "print(\"input image size : {}\".format(INPUT_SIZE))\n",
    "print(\"image channel : {}\".format(N_CHANNEL))\n",
    "print(\"batch size : {}\".format(BATCH_SIZE))\n",
    "print(\"num of class : {}\".format(N_CLASSES))\n",
    "print(\"training epochs : {}\".format(EPOCHS))\n",
    "print(\"learning rate : {}\".format(LR))\n",
    "print(\"learning decay rate : {}\".format(LR_DECAY_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETWORK PARAMETERS\n"
     ]
    }
   ],
   "source": [
    "#NETWORK PARAMETERS\n",
    "\n",
    "print(\"NETWORK PARAMETERS\")\n",
    "\n",
    "stddev = 0.1\n",
    "\n",
    "weights = {\n",
    "     'conv' : tf.Variable(tf.random_normal([3, 3, N_CHANNEL, 16], stddev=stddev), name='conv'),\n",
    "    'conv1_1x1' : tf.Variable(tf.random_normal([1, 1, 16, 4], stddev=stddev)),\n",
    "    'conv1_3x3' : tf.Variable(tf.random_normal([3, 3, 4, 4], stddev=stddev)),\n",
    "    'conv1_1x1_16' : tf.Variable(tf.random_normal([1, 1, 4, 16], stddev=stddev)),\n",
    "    'conv2_1x1' : tf.Variable(tf.random_normal([1, 1, 16, 4], stddev=stddev)),\n",
    "    'conv2_3x3' : tf.Variable(tf.random_normal([3, 3, 4, 4], stddev=stddev)),\n",
    "    'conv2_1x1_16' : tf.Variable(tf.random_normal([1, 1, 4, 16], stddev=stddev)),\n",
    "    \n",
    "    # conv 16 + conv2 16 = 32filters \n",
    "    \n",
    "    'conv3_1x1' : tf.Variable(tf.random_normal([1, 1, 32, 8], stddev=stddev)),\n",
    "    'conv3_3x3' : tf.Variable(tf.random_normal([3, 3, 8, 8], stddev=stddev)),\n",
    "    'conv3_1x1_32' : tf.Variable(tf.random_normal([1, 1, 8, 32], stddev=stddev)),\n",
    "    'conv4_1x1' : tf.Variable(tf.random_normal([1, 1, 32, 8], stddev=stddev)),\n",
    "    'conv4_3x3' : tf.Variable(tf.random_normal([3, 3, 8, 8], stddev=stddev)),\n",
    "    'conv4_1x1_32' : tf.Variable(tf.random_normal([1, 1, 8, 32], stddev=stddev)),\n",
    "    \n",
    "    # conv2 지난거32 + conv4 32 = 64\n",
    "    \n",
    "    'conv5_1x1' : tf.Variable(tf.random_normal([1, 1, 64, 16], stddev=stddev)),\n",
    "    'conv5_3x3' : tf.Variable(tf.random_normal([3, 3, 16, 16], stddev=stddev)),\n",
    "    'conv5_1x1_64' : tf.Variable(tf.random_normal([1, 1, 16, 64], stddev=stddev)),\n",
    "    'conv6_1x1' : tf.Variable(tf.random_normal([1, 1, 64, 16], stddev=stddev)),\n",
    "    'conv6_3x3' : tf.Variable(tf.random_normal([3, 3, 16, 16], stddev=stddev)),\n",
    "    'conv6_1x1_64' : tf.Variable(tf.random_normal([1, 1, 16, 64], stddev=stddev)),\n",
    "    \n",
    "    #conv4 지난거 64 + conv6 64 = 128\n",
    "    \n",
    "    'dense1' : tf.Variable(tf.random_normal([16*16*128, 1000], stddev=stddev)),\n",
    "    'dense2' : tf.Variable(tf.random_normal([1000, N_CLASSES], stddev=stddev))    \n",
    "}\n",
    "biases = {\n",
    "    'conv' : tf.Variable(tf.random_normal([16], stddev=stddev)),\n",
    "    'conv1_1x1' : tf.Variable(tf.random_normal([4], stddev=stddev)),\n",
    "    'conv1_3x3' : tf.Variable(tf.random_normal([4], stddev=stddev)),\n",
    "    'conv1_1x1_16' : tf.Variable(tf.random_normal([16], stddev=stddev)),\n",
    "    'conv2_1x1' : tf.Variable(tf.random_normal([4], stddev=stddev)),\n",
    "    'conv2_3x3' :tf.Variable(tf.random_normal([4], stddev=stddev)),\n",
    "    'conv2_1x1_16' : tf.Variable(tf.random_normal([16], stddev=stddev)),\n",
    "    \n",
    "    'conv3_1x1' : tf.Variable(tf.random_normal([8], stddev=stddev)),\n",
    "    'conv3_3x3' : tf.Variable(tf.random_normal([8], stddev=stddev)),\n",
    "    'conv3_1x1_32' : tf.Variable(tf.random_normal([32], stddev=stddev)),\n",
    "    'conv4_1x1' : tf.Variable(tf.random_normal([8], stddev=stddev)),\n",
    "    'conv4_3x3' : tf.Variable(tf.random_normal([8], stddev=stddev)),\n",
    "    'conv4_1x1_32' : tf.Variable(tf.random_normal([32], stddev=stddev)),\n",
    "    \n",
    "    'conv5_1x1' : tf.Variable(tf.random_normal([16], stddev=stddev)),\n",
    "    'conv5_3x3' : tf.Variable(tf.random_normal([16], stddev=stddev)),\n",
    "    'conv5_1x1_64' : tf.Variable(tf.random_normal([64], stddev=stddev)),\n",
    "    'conv6_1x1' : tf.Variable(tf.random_normal([16], stddev=stddev)),\n",
    "    'conv6_3x3' : tf.Variable(tf.random_normal([16], stddev=stddev)),\n",
    "    'conv6_1x1_64' : tf.Variable(tf.random_normal([64], stddev=stddev)),\n",
    "    \n",
    "    'dense1' : tf.Variable(tf.random_normal([1000], stddev=stddev)),\n",
    "    'dense2' : tf.Variable(tf.random_normal([N_CLASSES], stddev=stddev))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETWORK FUNCTION\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "#http://laonple.blog.me/220764986252 - bottleneck \n",
    "#conv 3x3\n",
    "#conv (1x1, 3x3, 1x1) - relu > 16\n",
    "#conv (1x1, 3x3, 1x1) relu > 32\n",
    "#conv (1x1, 3x3, 1x1) relu > 64\n",
    "#avg pooling \n",
    "#fc\n",
    "#softmax\n",
    "\n",
    "print(\"NETWORK FUNCTION\")\n",
    "\n",
    "def SimpleResNet(img_width, img_height, img_channel, _x, _w, _b, scope='SimpleResNet'):\n",
    "    network = OrderedDict() #network layers\n",
    "\n",
    "    # X RESHAPE\n",
    "    _x_r = tf.reshape(_x, shape=[-1,img_width,img_height, img_channel])\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        with tf.name_scope('conv') as scope:\n",
    "            conv = tf.nn.conv2d(_x_r, _w['conv'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv = tf.nn.bias_add(conv, _b['conv'])\n",
    "            conv = tf.nn.relu(conv)\n",
    "            network['conv'] = conv\n",
    "        \n",
    "        #16\n",
    "        with tf.name_scope('conv2') as scope:\n",
    "            conv1_1x1 = tf.nn.conv2d(conv, _w['conv1_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv1_1x1 = tf.nn.bias_add(conv1_1x1, _b['conv1_1x1'])\n",
    "            conv1_1x1 = tf.nn.relu(conv1_1x1)\n",
    "            conv1_3x3 = tf.nn.conv2d(conv1_1x1, _w['conv1_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv1_3x3 = tf.nn.bias_add(conv1_3x3, _b['conv1_3x3'])\n",
    "            conv1_3x3 = tf.nn.relu(conv1_3x3)\n",
    "            conv1_1x1_16 = tf.nn.conv2d(conv1_3x3, _w['conv1_1x1_16'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv1_1x1_16 = tf.nn.bias_add(conv1_1x1_16, _b['conv1_1x1_16'])\n",
    "            conv1_1x1_16 = tf.nn.relu(conv1_1x1_16)\n",
    "            network['conv1_1x1_16'] = conv1_1x1_16\n",
    "        \n",
    "        #16\n",
    "        with tf.name_scope('conv3') as scope:\n",
    "            conv2_1x1 = tf.nn.conv2d(conv1_1x1_16, _w['conv2_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv2_1x1 = tf.nn.bias_add(conv2_1x1, _b['conv2_1x1'])\n",
    "            conv2_1x1 = tf.nn.relu(conv2_1x1)\n",
    "            conv2_3x3 = tf.nn.conv2d(conv2_1x1, _w['conv2_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv2_3x3 = tf.nn.bias_add(conv2_3x3, _b['conv2_3x3'])\n",
    "            conv2_3x3 = tf.nn.relu(conv2_3x3)\n",
    "            conv2_1x1_16 = tf.nn.conv2d(conv2_3x3, _w['conv2_1x1_16'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv2_1x1_16 = tf.nn.bias_add(conv2_1x1_16, _b['conv2_1x1_16'])\n",
    "            #print(conv2_1x1_16.shape)\n",
    "            #32\n",
    "            conv2_1x1_16 = tf.concat([conv, conv2_1x1_16], 3) \n",
    "            conv2_1x1_16 = tf.nn.relu(conv2_1x1_16)\n",
    "            network['conv2_1x1_16'] = conv2_1x1_16\n",
    "       \n",
    "        #print(conv2_1x1_16.shape)\n",
    "        #32       32 x 32 x 16+16 >>> \n",
    "        with tf.name_scope('conv4') as scope:\n",
    "            conv3_1x1 = tf.nn.conv2d(conv2_1x1_16, _w['conv3_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv3_1x1 = tf.nn.bias_add(conv3_1x1, _b['conv3_1x1'])\n",
    "            conv3_1x1 = tf.nn.relu(conv3_1x1)\n",
    "            conv3_3x3 = tf.nn.conv2d(conv3_1x1, _w['conv3_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv3_3x3 = tf.nn.bias_add(conv3_3x3, _b['conv3_3x3'])\n",
    "            conv3_3x3 = tf.nn.relu(conv3_3x3)\n",
    "            conv3_1x1_32 = tf.nn.conv2d(conv3_3x3, _w['conv3_1x1_32'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv3_1x1_32 = tf.nn.bias_add(conv3_1x1_32, _b['conv3_1x1_32'])\n",
    "            conv3_1x1_32 = tf.nn.relu(conv3_1x1_32)\n",
    "            network['conv3_1x1_32'] = conv3_1x1_32\n",
    "        \n",
    "        with tf.name_scope('conv5') as scope:\n",
    "            conv4_1x1 = tf.nn.conv2d(conv3_1x1_32, _w['conv4_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv4_1x1 = tf.nn.bias_add(conv4_1x1, _b['conv4_1x1'])\n",
    "            conv4_1x1 = tf.nn.relu(conv4_1x1)\n",
    "            conv4_3x3 = tf.nn.conv2d(conv4_1x1, _w['conv4_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv4_3x3 = tf.nn.bias_add(conv4_3x3, _b['conv4_3x3'])\n",
    "            conv4_3x3 = tf.nn.relu(conv4_3x3)\n",
    "            conv4_1x1_32 = tf.nn.conv2d(conv4_3x3, _w['conv4_1x1_32'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv4_1x1_32 = tf.nn.bias_add(conv4_1x1_32, _b['conv4_1x1_32'])\n",
    "\n",
    "            #64\n",
    "            conv4_1x1_32 = tf.concat([conv2_1x1_16, conv4_1x1_32 ], 3)\n",
    "            conv4_1x1_32 = tf.nn.relu(conv4_1x1_32)\n",
    "            network['conv4_1x1_32'] = conv4_1x1_32\n",
    "    \n",
    "        with tf.name_scope('conv6') as scope:\n",
    "            conv5_1x1 = tf.nn.conv2d(conv4_1x1_32, _w['conv5_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv5_1x1 = tf.nn.bias_add(conv5_1x1, _b['conv5_1x1'])\n",
    "            conv5_1x1 = tf.nn.relu(conv5_1x1)\n",
    "            conv5_3x3 = tf.nn.conv2d(conv5_1x1, _w['conv5_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv5_3x3 = tf.nn.bias_add(conv5_3x3, _b['conv5_3x3'])\n",
    "            conv5_3x3 = tf.nn.relu(conv5_3x3)\n",
    "            conv5_1x1_64 = tf.nn.conv2d(conv5_3x3, _w['conv5_1x1_64'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv5_1x1_64 = tf.nn.bias_add(conv5_1x1_64, _b['conv5_1x1_64'])\n",
    "            conv5_1x1_64 = tf.nn.relu(conv5_1x1_64)\n",
    "            network['conv5_1x1_64'] = conv5_1x1_64\n",
    "        \n",
    "        with tf.name_scope('conv7') as scope:\n",
    "            conv6_1x1 = tf.nn.conv2d(conv5_1x1_64, _w['conv6_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv6_1x1 = tf.nn.bias_add(conv6_1x1, _b['conv6_1x1'])\n",
    "            conv6_1x1 = tf.nn.relu(conv6_1x1)\n",
    "            conv6_3x3 = tf.nn.conv2d(conv6_1x1, _w['conv6_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv6_3x3 = tf.nn.bias_add(conv6_3x3, _b['conv6_3x3'])\n",
    "            conv6_3x3 = tf.nn.relu(conv6_3x3)\n",
    "            conv6_1x1_64 = tf.nn.conv2d(conv6_3x3, _w['conv6_1x1_64'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            conv6_1x1_64 = tf.nn.bias_add(conv6_1x1_64, _b['conv6_1x1_64'])\n",
    "\n",
    "            #128\n",
    "            conv6_1x1_64 = tf.concat([conv4_1x1_32, conv6_1x1_64],3)\n",
    "            conv6_1x1_64 = tf.nn.relu(conv6_1x1_64)\n",
    "            network['conv6_1x1_64'] = conv6_1x1_64\n",
    "        \n",
    "        with tf.name_scope('pool') as scope:\n",
    "            pool = tf.nn.avg_pool(conv6_1x1_64, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "            network['pool'] = pool\n",
    "        \n",
    "        with tf.name_scope('dense1') as scope:\n",
    "            dense = tf.reshape(pool, [-1, _w['dense1'].get_shape().as_list()[0]])\n",
    "            dense1 = tf.add(tf.matmul(dense, _w['dense1']), _b['dense1'])\n",
    "            dense1 = tf.nn.relu(dense1)\n",
    "            network['dense1'] = dense1\n",
    "            \n",
    "        with tf.name_scope('logit') as scope:\n",
    "            logit = tf.add(tf.matmul(dense1, _w['dense2']), _b['dense2'])\n",
    "            network['logit'] = logit\n",
    "        \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVER READY\n"
     ]
    }
   ],
   "source": [
    "#save\n",
    "saver = tf.train.Saver(max_to_keep=3) #최근 3개까지만 저장\n",
    "save_step = 100 #save for 100 epoch\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "print (\"SAVER READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK LAYERS\n",
      "Tensor(\"Placeholder:0\", shape=(64, 3072), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(64, 10), dtype=float32)\n",
      "conv Tensor(\"SimpleResNet/Relu:0\", shape=(64, 32, 32, 16), dtype=float32)\n",
      "conv1_1x1_16 Tensor(\"SimpleResNet/Relu_3:0\", shape=(64, 32, 32, 16), dtype=float32)\n",
      "conv2_1x1_16 Tensor(\"SimpleResNet/Relu_6:0\", shape=(64, 32, 32, 32), dtype=float32)\n",
      "conv3_1x1_32 Tensor(\"SimpleResNet/Relu_9:0\", shape=(64, 32, 32, 32), dtype=float32)\n",
      "conv4_1x1_32 Tensor(\"SimpleResNet/Relu_12:0\", shape=(64, 32, 32, 64), dtype=float32)\n",
      "conv5_1x1_64 Tensor(\"SimpleResNet/Relu_15:0\", shape=(64, 32, 32, 64), dtype=float32)\n",
      "conv6_1x1_64 Tensor(\"SimpleResNet/Relu_18:0\", shape=(64, 32, 32, 128), dtype=float32)\n",
      "pool Tensor(\"SimpleResNet/AvgPool:0\", shape=(64, 16, 16, 128), dtype=float32)\n",
      "dense1 Tensor(\"SimpleResNet/Relu_19:0\", shape=(64, 1000), dtype=float32)\n",
      "logit Tensor(\"SimpleResNet/Add_1:0\", shape=(64, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "out = SimpleResNet(INPUT_SIDE, INPUT_SIDE, N_CHANNEL, x, weights, biases, 'SimpleResNet')\n",
    "print(\"CHECK LAYERS\")\n",
    "print(x)\n",
    "print(y)\n",
    "for key, value in out.items():\n",
    "    print (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS FUNCTION\n",
      "LERANING RATE : Tensor(\"Maximum:0\", shape=(), dtype=float32)\n",
      "OPTIMIZER 1 : name: \"Adam\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam/update_conv/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_1/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_2/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_3/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_4/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_5/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_6/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_7/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_8/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_9/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_10/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_11/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_12/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_13/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_14/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_15/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_16/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_17/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_18/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_19/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_20/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_21/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_22/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_23/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_24/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_25/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_26/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_27/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_28/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_29/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_30/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_31/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_32/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_33/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_34/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_35/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_36/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_37/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_38/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_39/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_40/ApplyAdam\"\n",
      "input: \"^Adam/Assign\"\n",
      "input: \"^Adam/Assign_1\"\n",
      "\n",
      "OPTIMIZER 2 : name: \"GradientDescent\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent/update_conv/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_1/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_2/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_3/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_4/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_5/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_6/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_7/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_8/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_9/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_10/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_11/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_12/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_13/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_14/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_15/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_16/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_17/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_18/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_19/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_20/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_21/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_22/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_23/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_24/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_25/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_26/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_27/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_28/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_29/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_30/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_31/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_32/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_33/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_34/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_35/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_36/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_37/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_38/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_39/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_40/ApplyGradientDescent\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=out['logit']))\n",
    "tf.summary.scalar(\"loss\", cost)\n",
    "print(\"LOSS FUNCTION\")\n",
    "\n",
    "#learning rate\n",
    "global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "learning_rate = tf.train.exponential_decay(learning_rate=LR,\n",
    "                                           global_step=global_step,\n",
    "                                           decay_steps=500,\n",
    "                                           decay_rate=LR_DECAY_RATE,\n",
    "                                           staircase=True,\n",
    "                                           name=\"learning_rate\")\n",
    "learning_rate = tf.maximum(learning_rate, 0.0001)\n",
    "tf.summary.scalar(\"learning_rate\", learning_rate)\n",
    "print(\"LERANING RATE : {}\".format(learning_rate))\n",
    "\n",
    "#optimizer\n",
    "adam = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "sgd = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "print(\"OPTIMIZER 1 : {}\".format(adam))\n",
    "print(\"OPTIMIZER 2 : {}\".format(sgd))\n",
    "\n",
    "corr = tf.equal(tf.argmax(out['logit'], 1), tf.argmax(y,1))\n",
    "accr = tf.reduce_mean(tf.cast(corr, \"float\"))\n",
    "tf.summary.scalar(\"accuracy\", accr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint/simple_res_net/simple_res_net.ckpt-0\n"
     ]
    }
   ],
   "source": [
    "#Session\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "summary_op = tf.summary.merge_all() #tensor board\n",
    "summary_writer = tf.summary.FileWriter(BOARD_PATH, sess.graph) #tensor board\n",
    "checkpoint = tf.train.latest_checkpoint(SAVE_PATH)\n",
    "if checkpoint is not None:\n",
    "    print(checkpoint)\n",
    "    saver.restore(sess, checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#npz - python numpy 파일 포맷. > dictionary로 불러옴 (Save several arrays into a single file in uncompressed .npz format)\n",
    "def load_npz(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "    \n",
    "## Make batch_iterator for npz data\n",
    "def make_batch_index(_data, batch_size=128, allow_small_batch=True):\n",
    "    num_images = len(_data[b'data']) #데이터 갯수\n",
    "    start_idx = list(range(0, num_images, batch_size)) #각 배치별 시작 인덱스 리스트\n",
    "    end_idx = list(range(batch_size, num_images + 1, batch_size))#각 배치별 끝 인덱스 \n",
    "    if allow_small_batch and end_idx[-1] < num_images : #스몰배치 허용시 마지막 배치\n",
    "        start_idx.append(end_idx[-1])\n",
    "        end_idx.append(num_images)\n",
    "    return zip(start_idx, end_idx)\n",
    "\n",
    "#one hot encoding\n",
    "def one_hot_encode(x, numclass):\n",
    "    return np.eye(numclass)[x] #numclass 크기의 항등행렬 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[100 nNumBatch] train_cost = 2.30357, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.3034, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30349, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30353, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30354, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30413, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30424, acc = 0.1875\n",
      "checkpoint/simple_res_net/simple_res_net.ckpt-0\n",
      "[0 epoch]test acc=0.10006\n",
      "\t[100 nNumBatch] train_cost = 2.30956, acc = 0.15625\n",
      "\t[200 nNumBatch] train_cost = 2.30755, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30618, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30557, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30523, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30499, acc = 0.1875\n",
      "\t[700 nNumBatch] train_cost = 2.30478, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.3038, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.3039, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30355, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30351, acc = 0.109375\n",
      "\t[500 nNumBatch] train_cost = 2.30383, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30385, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30382, acc = 0.0625\n",
      "\t[100 nNumBatch] train_cost = 2.30414, acc = 0.046875\n",
      "\t[200 nNumBatch] train_cost = 2.30405, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30378, acc = 0.015625\n",
      "\t[400 nNumBatch] train_cost = 2.30388, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30378, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.3038, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30376, acc = 0.109375\n",
      "\t[100 nNumBatch] train_cost = 2.30363, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30368, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30359, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30362, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30364, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30365, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30365, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30347, acc = 0.15625\n",
      "\t[200 nNumBatch] train_cost = 2.30363, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.3036, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30363, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30364, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30365, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30364, acc = 0.0625\n",
      "\t[100 nNumBatch] train_cost = 2.30385, acc = 0.15625\n",
      "\t[200 nNumBatch] train_cost = 2.30382, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30373, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30372, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30364, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30369, acc = 0.1875\n",
      "\t[700 nNumBatch] train_cost = 2.30375, acc = 0.109375\n",
      "\t[100 nNumBatch] train_cost = 2.30335, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30365, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30351, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30349, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30365, acc = 0.078125\n",
      "\t[600 nNumBatch] train_cost = 2.30368, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30367, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30346, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30365, acc = 0.125\n",
      "\t[300 nNumBatch] train_cost = 2.30378, acc = 0.03125\n",
      "\t[400 nNumBatch] train_cost = 2.30362, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30356, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30363, acc = 0.1875\n",
      "\t[700 nNumBatch] train_cost = 2.30365, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30347, acc = 0.15625\n",
      "\t[200 nNumBatch] train_cost = 2.30368, acc = 0.171875\n",
      "\t[300 nNumBatch] train_cost = 2.30378, acc = 0.03125\n",
      "\t[400 nNumBatch] train_cost = 2.30362, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30356, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30363, acc = 0.1875\n",
      "\t[700 nNumBatch] train_cost = 2.30357, acc = 0.109375\n",
      "\t[100 nNumBatch] train_cost = 2.30402, acc = 0.046875\n",
      "\t[200 nNumBatch] train_cost = 2.30377, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30384, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30373, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30362, acc = 0.09375\n",
      "\t[600 nNumBatch] train_cost = 2.30362, acc = 0.171875\n",
      "\t[700 nNumBatch] train_cost = 2.30362, acc = 0.0625\n",
      "checkpoint/simple_res_net/simple_res_net.ckpt-10\n",
      "[10 epoch]test acc=0.0998598\n",
      "\t[100 nNumBatch] train_cost = 2.30415, acc = 0.046875\n",
      "\t[200 nNumBatch] train_cost = 2.30395, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30379, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30383, acc = 0.125\n",
      "\t[500 nNumBatch] train_cost = 2.3038, acc = 0.078125\n",
      "\t[600 nNumBatch] train_cost = 2.30381, acc = 0.1875\n",
      "\t[700 nNumBatch] train_cost = 2.30378, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30365, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30372, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30379, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30359, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30379, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30372, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30371, acc = 0.1875\n",
      "\t[100 nNumBatch] train_cost = 2.30359, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30368, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30377, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30357, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30377, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.3037, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30369, acc = 0.1875\n",
      "\t[100 nNumBatch] train_cost = 2.30359, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30387, acc = 0.0625\n",
      "\t[300 nNumBatch] train_cost = 2.30366, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30368, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30367, acc = 0.09375\n",
      "\t[600 nNumBatch] train_cost = 2.30361, acc = 0.171875\n",
      "\t[700 nNumBatch] train_cost = 2.30368, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30346, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30365, acc = 0.125\n",
      "\t[300 nNumBatch] train_cost = 2.30378, acc = 0.03125\n",
      "\t[400 nNumBatch] train_cost = 2.30372, acc = 0.125\n",
      "\t[500 nNumBatch] train_cost = 2.30374, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30366, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.3036, acc = 0.0625\n",
      "\t[100 nNumBatch] train_cost = 2.30349, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30357, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30344, acc = 0.015625\n",
      "\t[400 nNumBatch] train_cost = 2.30363, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30358, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30363, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30367, acc = 0.1875\n",
      "\t[100 nNumBatch] train_cost = 2.30335, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30365, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30351, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30349, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30352, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30361, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30365, acc = 0.1875\n",
      "\t[100 nNumBatch] train_cost = 2.30319, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30324, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30351, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30357, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.3037, acc = 0.078125\n",
      "\t[600 nNumBatch] train_cost = 2.30372, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30366, acc = 0.109375\n",
      "\t[100 nNumBatch] train_cost = 2.30374, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.3035, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30369, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.3037, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30381, acc = 0.078125\n",
      "\t[600 nNumBatch] train_cost = 2.30381, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30374, acc = 0.109375\n",
      "\t[100 nNumBatch] train_cost = 2.30383, acc = 0.15625\n",
      "\t[200 nNumBatch] train_cost = 2.3039, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30365, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30367, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30371, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30373, acc = 0.1875\n",
      "\t[700 nNumBatch] train_cost = 2.30365, acc = 0.109375\n",
      "checkpoint/simple_res_net/simple_res_net.ckpt-20\n",
      "[20 epoch]test acc=0.0998598\n",
      "\t[100 nNumBatch] train_cost = 2.30363, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30371, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30379, acc = 0.09375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[400 nNumBatch] train_cost = 2.30359, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30374, acc = 0.078125\n",
      "\t[600 nNumBatch] train_cost = 2.30379, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30372, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30366, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30364, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30349, acc = 0.015625\n",
      "\t[400 nNumBatch] train_cost = 2.30379, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.3038, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30371, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.3037, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30348, acc = 0.15625\n",
      "\t[200 nNumBatch] train_cost = 2.3037, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30354, acc = 0.015625\n",
      "\t[400 nNumBatch] train_cost = 2.30383, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30383, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30373, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30365, acc = 0.109375\n",
      "\t[100 nNumBatch] train_cost = 2.30375, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30369, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30352, acc = 0.015625\n",
      "\t[400 nNumBatch] train_cost = 2.30382, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30382, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30373, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30371, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30346, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.3037, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30354, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30352, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30367, acc = 0.078125\n",
      "\t[600 nNumBatch] train_cost = 2.3037, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30369, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30351, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30365, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30374, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30377, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30374, acc = 0.09375\n",
      "\t[600 nNumBatch] train_cost = 2.30367, acc = 0.171875\n",
      "\t[700 nNumBatch] train_cost = 2.30369, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30365, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30392, acc = 0.0625\n",
      "\t[300 nNumBatch] train_cost = 2.30369, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30373, acc = 0.125\n",
      "\t[500 nNumBatch] train_cost = 2.30371, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30374, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30368, acc = 0.109375\n",
      "\t[100 nNumBatch] train_cost = 2.30375, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.3038, acc = 0.125\n",
      "\t[300 nNumBatch] train_cost = 2.30387, acc = 0.03125\n",
      "\t[400 nNumBatch] train_cost = 2.3037, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30362, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30368, acc = 0.1875\n",
      "\t[700 nNumBatch] train_cost = 2.30369, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30354, acc = 0.046875\n",
      "\t[200 nNumBatch] train_cost = 2.30373, acc = 0.0625\n",
      "\t[300 nNumBatch] train_cost = 2.30354, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30352, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30356, acc = 0.0625\n",
      "\t[600 nNumBatch] train_cost = 2.30351, acc = 0.171875\n",
      "\t[700 nNumBatch] train_cost = 2.30359, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30355, acc = 0.046875\n",
      "\t[200 nNumBatch] train_cost = 2.30373, acc = 0.0625\n",
      "\t[300 nNumBatch] train_cost = 2.30354, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30335, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30349, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30358, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30359, acc = 0.0625\n",
      "checkpoint/simple_res_net/simple_res_net.ckpt-30\n",
      "[30 epoch]test acc=0.0998598\n",
      "\t[100 nNumBatch] train_cost = 2.30415, acc = 0.046875\n",
      "\t[200 nNumBatch] train_cost = 2.30384, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30389, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30377, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30365, acc = 0.09375\n",
      "\t[600 nNumBatch] train_cost = 2.30364, acc = 0.171875\n",
      "\t[700 nNumBatch] train_cost = 2.30364, acc = 0.0625\n",
      "\t[100 nNumBatch] train_cost = 2.30374, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30349, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30356, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30358, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30358, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30366, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30369, acc = 0.1875\n",
      "\t[100 nNumBatch] train_cost = 2.30335, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30365, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30351, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30357, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30363, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30366, acc = 0.1875\n",
      "\t[700 nNumBatch] train_cost = 2.30368, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30346, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.3037, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30354, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30359, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30356, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30362, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30362, acc = 0.0625\n",
      "\t[100 nNumBatch] train_cost = 2.30349, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30357, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30344, acc = 0.015625\n",
      "\t[400 nNumBatch] train_cost = 2.30363, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30358, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30363, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30367, acc = 0.1875\n",
      "\t[100 nNumBatch] train_cost = 2.30359, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30364, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30357, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30361, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30362, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30364, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30364, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30351, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30365, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30375, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30377, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30378, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30369, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30362, acc = 0.109375\n",
      "\t[100 nNumBatch] train_cost = 2.30374, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.3035, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30369, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30351, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30363, acc = 0.078125\n",
      "\t[600 nNumBatch] train_cost = 2.30368, acc = 0.1875\n",
      "\t[700 nNumBatch] train_cost = 2.30375, acc = 0.109375\n",
      "\t[100 nNumBatch] train_cost = 2.30359, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30368, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30377, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30379, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30376, acc = 0.09375\n",
      "\t[600 nNumBatch] train_cost = 2.30368, acc = 0.171875\n",
      "\t[700 nNumBatch] train_cost = 2.3037, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30383, acc = 0.046875\n",
      "\t[200 nNumBatch] train_cost = 2.30369, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30378, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30369, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30362, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30367, acc = 0.1875\n",
      "\t[700 nNumBatch] train_cost = 2.30361, acc = 0.109375\n",
      "checkpoint/simple_res_net/simple_res_net.ckpt-40\n",
      "[40 epoch]test acc=0.0998598\n",
      "\t[100 nNumBatch] train_cost = 2.30363, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30371, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30379, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30359, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30374, acc = 0.078125\n",
      "\t[600 nNumBatch] train_cost = 2.30379, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30372, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30384, acc = 0.15625\n",
      "\t[200 nNumBatch] train_cost = 2.30388, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30366, acc = 0.015625\n",
      "\t[400 nNumBatch] train_cost = 2.30379, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30377, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30376, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.3037, acc = 0.109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[100 nNumBatch] train_cost = 2.30402, acc = 0.046875\n",
      "\t[200 nNumBatch] train_cost = 2.30396, acc = 0.0625\n",
      "\t[300 nNumBatch] train_cost = 2.3037, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30373, acc = 0.125\n",
      "\t[500 nNumBatch] train_cost = 2.30371, acc = 0.09375\n",
      "\t[600 nNumBatch] train_cost = 2.30365, acc = 0.171875\n",
      "\t[700 nNumBatch] train_cost = 2.30364, acc = 0.0625\n",
      "\t[100 nNumBatch] train_cost = 2.30415, acc = 0.046875\n",
      "\t[200 nNumBatch] train_cost = 2.30395, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30379, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30383, acc = 0.125\n",
      "\t[500 nNumBatch] train_cost = 2.3038, acc = 0.078125\n",
      "\t[600 nNumBatch] train_cost = 2.30381, acc = 0.1875\n",
      "\t[700 nNumBatch] train_cost = 2.30378, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30383, acc = 0.046875\n",
      "\t[200 nNumBatch] train_cost = 2.30369, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30378, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30358, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30379, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30371, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30364, acc = 0.0625\n",
      "\t[100 nNumBatch] train_cost = 2.30414, acc = 0.046875\n",
      "\t[200 nNumBatch] train_cost = 2.30384, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30388, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30384, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30381, acc = 0.0625\n",
      "\t[600 nNumBatch] train_cost = 2.30372, acc = 0.171875\n",
      "\t[700 nNumBatch] train_cost = 2.30374, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30384, acc = 0.15625\n",
      "\t[200 nNumBatch] train_cost = 2.3039, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30366, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30344, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30357, acc = 0.078125\n",
      "\t[600 nNumBatch] train_cost = 2.30363, acc = 0.1875\n",
      "\t[700 nNumBatch] train_cost = 2.3037, acc = 0.109375\n",
      "\t[100 nNumBatch] train_cost = 2.30342, acc = 0.15625\n",
      "\t[200 nNumBatch] train_cost = 2.3036, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30358, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30371, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30373, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30365, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30359, acc = 0.0625\n",
      "\t[100 nNumBatch] train_cost = 2.30385, acc = 0.15625\n",
      "\t[200 nNumBatch] train_cost = 2.30388, acc = 0.171875\n",
      "\t[300 nNumBatch] train_cost = 2.30391, acc = 0.03125\n",
      "\t[400 nNumBatch] train_cost = 2.30372, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30364, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30369, acc = 0.1875\n",
      "\t[700 nNumBatch] train_cost = 2.30362, acc = 0.109375\n",
      "\t[100 nNumBatch] train_cost = 2.30352, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30334, acc = 0.125\n",
      "\t[300 nNumBatch] train_cost = 2.30328, acc = 0.046875\n",
      "\t[400 nNumBatch] train_cost = 2.30321, acc = 0.046875\n",
      "\t[500 nNumBatch] train_cost = 2.30325, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30313, acc = 0.0625\n",
      "\t[700 nNumBatch] train_cost = 2.3031, acc = 0.125\n",
      "checkpoint/simple_res_net/simple_res_net.ckpt-50\n",
      "[50 epoch]test acc=0.0998598\n",
      "\t[100 nNumBatch] train_cost = 2.30285, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30279, acc = 0.125\n",
      "\t[300 nNumBatch] train_cost = 2.30277, acc = 0.015625\n",
      "\t[400 nNumBatch] train_cost = 2.30277, acc = 0.09375\n",
      "\t[500 nNumBatch] train_cost = 2.3027, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30271, acc = 0.140625\n",
      "\t[700 nNumBatch] train_cost = 2.30274, acc = 0.125\n",
      "\t[100 nNumBatch] train_cost = 2.30268, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30267, acc = 0.125\n",
      "\t[300 nNumBatch] train_cost = 2.30262, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30266, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30267, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30266, acc = 0.140625\n",
      "\t[700 nNumBatch] train_cost = 2.30266, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30266, acc = 0.109375\n",
      "\t[200 nNumBatch] train_cost = 2.30266, acc = 0.125\n",
      "\t[300 nNumBatch] train_cost = 2.30265, acc = 0.015625\n",
      "\t[400 nNumBatch] train_cost = 2.30265, acc = 0.15625\n",
      "\t[500 nNumBatch] train_cost = 2.30266, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30265, acc = 0.109375\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.0625\n",
      "\t[100 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30265, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30265, acc = 0.03125\n",
      "\t[400 nNumBatch] train_cost = 2.30265, acc = 0.203125\n",
      "\t[500 nNumBatch] train_cost = 2.30265, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.1875\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.15625\n",
      "\t[100 nNumBatch] train_cost = 2.30262, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30259, acc = 0.171875\n",
      "\t[300 nNumBatch] train_cost = 2.30263, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30263, acc = 0.046875\n",
      "\t[500 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30262, acc = 0.109375\n",
      "\t[200 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[300 nNumBatch] train_cost = 2.30263, acc = 0.015625\n",
      "\t[400 nNumBatch] train_cost = 2.30264, acc = 0.0625\n",
      "\t[500 nNumBatch] train_cost = 2.30265, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30265, acc = 0.0625\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.171875\n",
      "\t[100 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[200 nNumBatch] train_cost = 2.30263, acc = 0.046875\n",
      "\t[300 nNumBatch] train_cost = 2.30265, acc = 0.125\n",
      "\t[400 nNumBatch] train_cost = 2.30263, acc = 0.125\n",
      "\t[500 nNumBatch] train_cost = 2.30263, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30266, acc = 0.109375\n",
      "\t[200 nNumBatch] train_cost = 2.30265, acc = 0.046875\n",
      "\t[300 nNumBatch] train_cost = 2.30266, acc = 0.171875\n",
      "\t[400 nNumBatch] train_cost = 2.30265, acc = 0.125\n",
      "\t[500 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[600 nNumBatch] train_cost = 2.30265, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.109375\n",
      "\t[100 nNumBatch] train_cost = 2.30267, acc = 0.109375\n",
      "\t[200 nNumBatch] train_cost = 2.30267, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30265, acc = 0.15625\n",
      "\t[500 nNumBatch] train_cost = 2.30266, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30266, acc = 0.140625\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.109375\n",
      "\t[100 nNumBatch] train_cost = 2.30266, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30263, acc = 0.171875\n",
      "\t[300 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30265, acc = 0.046875\n",
      "\t[500 nNumBatch] train_cost = 2.30265, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30266, acc = 0.125\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "checkpoint/simple_res_net/simple_res_net.ckpt-60\n",
      "[60 epoch]test acc=0.0998598\n",
      "\t[100 nNumBatch] train_cost = 2.30265, acc = 0.0625\n",
      "\t[200 nNumBatch] train_cost = 2.30265, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30262, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30261, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.3026, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30263, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30263, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30263, acc = 0.03125\n",
      "\t[500 nNumBatch] train_cost = 2.30264, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30255, acc = 0.15625\n",
      "\t[200 nNumBatch] train_cost = 2.3026, acc = 0.046875\n",
      "\t[300 nNumBatch] train_cost = 2.30262, acc = 0.125\n",
      "\t[400 nNumBatch] train_cost = 2.30263, acc = 0.203125\n",
      "\t[500 nNumBatch] train_cost = 2.30265, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.140625\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30258, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30263, acc = 0.09375\n",
      "\t[300 nNumBatch] train_cost = 2.30264, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30263, acc = 0.046875\n",
      "\t[500 nNumBatch] train_cost = 2.30264, acc = 0.140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30263, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30263, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30265, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.03125\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.171875\n",
      "\t[100 nNumBatch] train_cost = 2.30262, acc = 0.0625\n",
      "\t[200 nNumBatch] train_cost = 2.30263, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30265, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.0625\n",
      "\t[100 nNumBatch] train_cost = 2.30262, acc = 0.0625\n",
      "\t[200 nNumBatch] train_cost = 2.30261, acc = 0.046875\n",
      "\t[300 nNumBatch] train_cost = 2.30263, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[500 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[600 nNumBatch] train_cost = 2.30263, acc = 0.171875\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.15625\n",
      "\t[100 nNumBatch] train_cost = 2.30263, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30262, acc = 0.125\n",
      "\t[400 nNumBatch] train_cost = 2.3026, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30261, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.171875\n",
      "\t[100 nNumBatch] train_cost = 2.30262, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30261, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30261, acc = 0.109375\n",
      "\t[400 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.171875\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.046875\n",
      "\t[100 nNumBatch] train_cost = 2.30263, acc = 0.109375\n",
      "\t[200 nNumBatch] train_cost = 2.30264, acc = 0.140625\n",
      "\t[300 nNumBatch] train_cost = 2.30263, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30264, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30265, acc = 0.171875\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "checkpoint/simple_res_net/simple_res_net.ckpt-70\n",
      "[70 epoch]test acc=0.0998598\n",
      "\t[100 nNumBatch] train_cost = 2.30259, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30256, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30256, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.3026, acc = 0.109375\n",
      "\t[500 nNumBatch] train_cost = 2.30261, acc = 0.078125\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.15625\n",
      "\t[100 nNumBatch] train_cost = 2.30261, acc = 0.15625\n",
      "\t[200 nNumBatch] train_cost = 2.30264, acc = 0.125\n",
      "\t[300 nNumBatch] train_cost = 2.30264, acc = 0.015625\n",
      "\t[400 nNumBatch] train_cost = 2.30262, acc = 0.09375\n",
      "\t[500 nNumBatch] train_cost = 2.30264, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.0625\n",
      "\t[100 nNumBatch] train_cost = 2.3026, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30258, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.3026, acc = 0.03125\n",
      "\t[400 nNumBatch] train_cost = 2.30261, acc = 0.15625\n",
      "\t[500 nNumBatch] train_cost = 2.30263, acc = 0.0625\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.125\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30259, acc = 0.109375\n",
      "\t[200 nNumBatch] train_cost = 2.30261, acc = 0.140625\n",
      "\t[300 nNumBatch] train_cost = 2.30261, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30263, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30263, acc = 0.078125\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.3026, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30258, acc = 0.046875\n",
      "\t[300 nNumBatch] train_cost = 2.30262, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30257, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30262, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30259, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30259, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30261, acc = 0.03125\n",
      "\t[400 nNumBatch] train_cost = 2.30262, acc = 0.15625\n",
      "\t[500 nNumBatch] train_cost = 2.30264, acc = 0.0625\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.125\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.171875\n",
      "\t[100 nNumBatch] train_cost = 2.3026, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.3026, acc = 0.25\n",
      "\t[300 nNumBatch] train_cost = 2.30262, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30264, acc = 0.0625\n",
      "\t[500 nNumBatch] train_cost = 2.30264, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30261, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30261, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30262, acc = 0.03125\n",
      "\t[400 nNumBatch] train_cost = 2.30262, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30263, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.171875\n",
      "\t[100 nNumBatch] train_cost = 2.30263, acc = 0.109375\n",
      "\t[200 nNumBatch] train_cost = 2.30266, acc = 0.09375\n",
      "\t[300 nNumBatch] train_cost = 2.30263, acc = 0.015625\n",
      "\t[400 nNumBatch] train_cost = 2.3026, acc = 0.09375\n",
      "\t[500 nNumBatch] train_cost = 2.30261, acc = 0.078125\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.15625\n",
      "\t[100 nNumBatch] train_cost = 2.30261, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30259, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30261, acc = 0.03125\n",
      "\t[400 nNumBatch] train_cost = 2.30262, acc = 0.203125\n",
      "\t[500 nNumBatch] train_cost = 2.30263, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "checkpoint/simple_res_net/simple_res_net.ckpt-80\n",
      "[80 epoch]test acc=0.0998598\n",
      "\t[100 nNumBatch] train_cost = 2.30262, acc = 0.0625\n",
      "\t[200 nNumBatch] train_cost = 2.3026, acc = 0.046875\n",
      "\t[300 nNumBatch] train_cost = 2.30263, acc = 0.171875\n",
      "\t[400 nNumBatch] train_cost = 2.30264, acc = 0.15625\n",
      "\t[500 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[600 nNumBatch] train_cost = 2.30265, acc = 0.125\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30256, acc = 0.15625\n",
      "\t[200 nNumBatch] train_cost = 2.30263, acc = 0.125\n",
      "\t[300 nNumBatch] train_cost = 2.30264, acc = 0.015625\n",
      "\t[400 nNumBatch] train_cost = 2.30265, acc = 0.0625\n",
      "\t[500 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.171875\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.15625\n",
      "\t[100 nNumBatch] train_cost = 2.30263, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30263, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30263, acc = 0.03125\n",
      "\t[400 nNumBatch] train_cost = 2.30264, acc = 0.203125\n",
      "\t[500 nNumBatch] train_cost = 2.30265, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.140625\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30262, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30261, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30264, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30264, acc = 0.0625\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.125\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30259, acc = 0.109375\n",
      "\t[200 nNumBatch] train_cost = 2.30263, acc = 0.125\n",
      "\t[300 nNumBatch] train_cost = 2.30261, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30264, acc = 0.0625\n",
      "\t[500 nNumBatch] train_cost = 2.30265, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.140625\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30263, acc = 0.109375\n",
      "\t[200 nNumBatch] train_cost = 2.30265, acc = 0.125\n",
      "\t[300 nNumBatch] train_cost = 2.30264, acc = 0.015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[400 nNumBatch] train_cost = 2.30264, acc = 0.0625\n",
      "\t[500 nNumBatch] train_cost = 2.30265, acc = 0.15625\n",
      "\t[600 nNumBatch] train_cost = 2.30265, acc = 0.03125\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.171875\n",
      "\t[100 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[200 nNumBatch] train_cost = 2.30264, acc = 0.140625\n",
      "\t[300 nNumBatch] train_cost = 2.30263, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30262, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30263, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30265, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[100 nNumBatch] train_cost = 2.30265, acc = 0.0625\n",
      "\t[200 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[400 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[500 nNumBatch] train_cost = 2.30265, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[200 nNumBatch] train_cost = 2.30266, acc = 0.09375\n",
      "\t[300 nNumBatch] train_cost = 2.30264, acc = 0.015625\n",
      "\t[400 nNumBatch] train_cost = 2.30265, acc = 0.0625\n",
      "\t[500 nNumBatch] train_cost = 2.30265, acc = 0.0625\n",
      "\t[600 nNumBatch] train_cost = 2.30263, acc = 0.171875\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.15625\n",
      "\t[100 nNumBatch] train_cost = 2.30261, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30259, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30263, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30265, acc = 0.109375\n",
      "\t[500 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.0625\n",
      "checkpoint/simple_res_net/simple_res_net.ckpt-90\n",
      "[90 epoch]test acc=0.0998598\n",
      "\t[100 nNumBatch] train_cost = 2.30263, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30264, acc = 0.15625\n",
      "\t[500 nNumBatch] train_cost = 2.30264, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[100 nNumBatch] train_cost = 2.30258, acc = 0.15625\n",
      "\t[200 nNumBatch] train_cost = 2.30261, acc = 0.140625\n",
      "\t[300 nNumBatch] train_cost = 2.30261, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.3026, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30262, acc = 0.125\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.171875\n",
      "\t[100 nNumBatch] train_cost = 2.30264, acc = 0.109375\n",
      "\t[200 nNumBatch] train_cost = 2.30266, acc = 0.09375\n",
      "\t[300 nNumBatch] train_cost = 2.30263, acc = 0.015625\n",
      "\t[400 nNumBatch] train_cost = 2.3026, acc = 0.09375\n",
      "\t[500 nNumBatch] train_cost = 2.30262, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.0625\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.0625\n",
      "\t[100 nNumBatch] train_cost = 2.30262, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30259, acc = 0.109375\n",
      "\t[300 nNumBatch] train_cost = 2.30261, acc = 0.03125\n",
      "\t[400 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[500 nNumBatch] train_cost = 2.30263, acc = 0.078125\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.109375\n",
      "\t[100 nNumBatch] train_cost = 2.30262, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30263, acc = 0.078125\n",
      "\t[300 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[400 nNumBatch] train_cost = 2.30262, acc = 0.140625\n",
      "\t[500 nNumBatch] train_cost = 2.30261, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30263, acc = 0.140625\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.15625\n",
      "\t[100 nNumBatch] train_cost = 2.30262, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30262, acc = 0.03125\n",
      "\t[300 nNumBatch] train_cost = 2.30263, acc = 0.03125\n",
      "\t[400 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[500 nNumBatch] train_cost = 2.30265, acc = 0.109375\n",
      "\t[600 nNumBatch] train_cost = 2.30265, acc = 0.078125\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.171875\n",
      "\t[100 nNumBatch] train_cost = 2.30262, acc = 0.15625\n",
      "\t[200 nNumBatch] train_cost = 2.30262, acc = 0.046875\n",
      "\t[300 nNumBatch] train_cost = 2.30264, acc = 0.125\n",
      "\t[400 nNumBatch] train_cost = 2.30264, acc = 0.203125\n",
      "\t[500 nNumBatch] train_cost = 2.30264, acc = 0.140625\n",
      "\t[600 nNumBatch] train_cost = 2.30264, acc = 0.1875\n",
      "\t[700 nNumBatch] train_cost = 2.30264, acc = 0.15625\n",
      "\t[100 nNumBatch] train_cost = 2.30263, acc = 0.09375\n",
      "\t[200 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[300 nNumBatch] train_cost = 2.30262, acc = 0.15625\n",
      "\t[400 nNumBatch] train_cost = 2.30264, acc = 0.15625\n",
      "\t[500 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[600 nNumBatch] train_cost = 2.30265, acc = 0.09375\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.171875\n",
      "\t[100 nNumBatch] train_cost = 2.3026, acc = 0.078125\n",
      "\t[200 nNumBatch] train_cost = 2.30262, acc = 0.09375\n",
      "\t[300 nNumBatch] train_cost = 2.30263, acc = 0.140625\n",
      "\t[400 nNumBatch] train_cost = 2.30262, acc = 0.03125\n",
      "\t[500 nNumBatch] train_cost = 2.30264, acc = 0.09375\n",
      "\t[600 nNumBatch] train_cost = 2.30265, acc = 0.140625\n",
      "\t[700 nNumBatch] train_cost = 2.30265, acc = 0.0625\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "loss_for_plot = []\n",
    "acc_for_plot = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    sample_list_new = random.sample(train_file, len(train_file)) #변환할 부분 - training file shuffle\n",
    "    nNumBatch = 0 #배치수\n",
    "    AvgBatchCost = 0 #batch cost\n",
    "    \n",
    "    for index, file_name in enumerate(sample_list_new): #sample file list 돌면서 index, filename을 받아온다\n",
    "        file_name = DATA_PATH + file_name #해당 파일 이름\n",
    "        load_data = load_npz(file_name) #해당 파일 이름으로 불러온다. \n",
    "        batch_index = make_batch_index(load_data, BATCH_SIZE, False) #배치의 시작과 끝 인덱스를 zip으로 받아온다. \n",
    "        \n",
    "        for start, end in batch_index:\n",
    "            batch_xs = load_data[b'data'][start:end] #start~end까지의 x데이터(image)를 준비\n",
    "            batch_ys = one_hot_encode(load_data[b'labels'][start:end], N_CLASSES) # label을 원핫인코딩으로 변환해줌. \n",
    "            #print(batch_xs.shape)\n",
    "            feed_dictionary = {x : batch_xs, y : batch_ys} #feed dict에 x, y준비\n",
    "\n",
    "            #실제 실행 -> optimizer 고를듯..\n",
    "            #sess.run(adam, feed_dict = feed_dictionary)\n",
    "            nNumBatch += 1\n",
    "            if epoch < EPOCHS*0.5:\n",
    "                _, tmp_cost = sess.run([adam, cost], feed_dict = feed_dictionary) #optimizer는 결과값중요하지 않으니 _로 받고, cost를 받음\n",
    "            else:\n",
    "                _, tmp_cost = sess.run([sgd, cost], feed_dict = feed_dictionary) \n",
    "            \n",
    "            AvgBatchCost += tmp_cost\n",
    "            \n",
    "        #매 배치가 끝난 후 \n",
    "            if nNumBatch % 100 == 0: #100개 배치마다 출력\n",
    "                train_acc = sess.run(accr, feed_dict = feed_dictionary)\n",
    "                print('\\t[%d nNumBatch] train_cost = %g, acc = %g'%(nNumBatch, AvgBatchCost/nNumBatch, train_acc))\n",
    "                loss_for_plot.append(AvgBatchCost/nNumBatch)\n",
    "                acc_for_plot.append(train_acc)\n",
    "\n",
    "        \n",
    "    if epoch % 10 == 0: #10epoch마다 테스트데이터를 이용해 테스트\n",
    "        save_path = saver.save(sess, SAVE_PATH+CHECKPOINT, global_step=epoch) #10epoch마다 저장\n",
    "        print(save_path)\n",
    "        test_acc = 0\n",
    "        avg_acc = 0\n",
    "        num_batch = 0\n",
    "        load_testdata=load_npz(test_file[0]) #test를 위한 테스트에디터 로드\n",
    "        \n",
    "        testdata_label = one_hot_encode(load_testdata[b'labels'], N_CLASSES)\n",
    "        test_batch_index = make_batch_index(load_testdata, BATCH_SIZE, False)\n",
    "\n",
    "        for start, end in test_batch_index:\n",
    "            num_batch += 1\n",
    "            batch_xs = load_testdata[b'data'][start:end]\n",
    "            batch_ys = one_hot_encode(load_testdata[b'labels'][start:end], N_CLASSES)\n",
    "            test_acc = sess.run(accr, feed_dict={x:batch_xs,y:batch_ys})\n",
    "            avg_acc += test_acc\n",
    "            \n",
    "        print('[%d epoch]test acc=%g'%(epoch, avg_acc/num_batch))\n",
    "        summary_writer.add_summary(avg_acc/num_batch ,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss, accracy graph\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'Tensor' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e02c67048b68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_for_plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"red\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'Tensor' has no len()"
     ]
    }
   ],
   "source": [
    "x = np.linspace(0, len(y), len(y))\n",
    "y = loss_for_plot\n",
    "plt.plot(x,y, color=\"red\")\n",
    "plt.plot()\n",
    "plt.xlabel(\"batch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"LOSS\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, len(y_ac), len(y_ac))\n",
    "y_ac = acc_for_plot\n",
    "plt.plot(x,y_ac, color=\"blue\")\n",
    "plt.plot()\n",
    "plt.xlabel(\"batch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"ACCURACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "남은것\n",
    "1. augmentation - flip, blurr, sharp, crop..? \n",
    "2. data restore(save는 함) 111\n",
    "3. 텐서보드(summary writer) https://www.tensorflow.org/get_started/summaries_and_tensorboard\n",
    "4. visualization(filter weight값)\n",
    "5. queue로 입력 받기\n",
    "6. miss classification된 label, file_name 저장 > 나중에 확인\n",
    "7. loss 파일 저장 > plot 1111\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CIFAR 데이터 읽어오기 \n",
    "def read_dataset(filename_queue):\n",
    "    class DataRecord(object):\n",
    "        pass\n",
    "    \n",
    "    result = DataRecord()\n",
    "    \n",
    "    label_bytes = 1\n",
    "    result.height = 32\n",
    "    result.width = 32\n",
    "    result.depth = 3\n",
    "    image_bytes = result.height * result.width * result.depth\n",
    "    record_bytes = label_bytes + image_bytes\n",
    "    \n",
    "    reader = tf.FixedLengthRecordReader(record_bytes = record_bytes)\n",
    "    result.key, value = reader.read(filename_queue)\n",
    "    print (value)\n",
    "    record_bytes = tf.decode_raw(value, tf.unit8)\n",
    "    \n",
    "    result.label = tf.cast(tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32) #input, begin, end로 잘라냄 > 0~1\n",
    "    \n",
    "    depth_major = tf.reshape(tf.strided_slice(record_bytes, [label_bytes], # 1부터 image_bytes까지 image를 잘라낸 후 \n",
    "                                              [label_bytes + image_bytes]), #channel x height x width로 변환함.\n",
    "                             [result.depth, result.height, result.width])\n",
    "    \n",
    "    result.uint8image = tf.transpose(depth_major, [1,2,0]) #channel x height x width >>> height x width x chennl로 변경\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#label, image 세팅해줌 \n",
    "def _generate_image_and_label_batch(image, label, min_queue_examples,\n",
    "                                    batch_size, shuffle):\n",
    "    \"\"\"Construct a queued batch of images and labels.\n",
    "    Args:\n",
    "      image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "      label: 1-D Tensor of type.int32\n",
    "      min_queue_examples: int32, minimum number of samples to retain\n",
    "        in the queue that provides of batches of examples.\n",
    "      batch_size: Number of images per batch.\n",
    "      shuffle: boolean indicating whether to use a shuffling queue.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    # Create a queue that shuffles the examples, and then\n",
    "    # read 'batch_size' images + labels from the example queue.\n",
    "    num_preprocess_threads = 16 #프로세스 스레드 \n",
    "    if shuffle: #셔플 하면 \n",
    "        images, label_batch = tf.train.shuffle_batch([image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size,\n",
    "            min_after_dequeue=min_queue_examples) #이거만 해주면 batch와 동일함. \n",
    "    #Minimum number elements in the queue after a dequeue, used to ensure a level of mixing of elements.\n",
    "    else:\n",
    "        images, label_batch = tf.train.batch([image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "    # Display the training images in the visualizer.\n",
    "    tf.summary.image('images', images) #걍 보드용인듯\n",
    "\n",
    "    return images, tf.reshape(label_batch, [batch_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distorted_inputs(data_dir, batch_size): #좀 드럽게 인풋받아오기 \n",
    "    \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "    Args:\n",
    "      data_dir: Path to the CIFAR-10 data directory.\n",
    "      batch_size: Number of images per batch.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n",
    "               for i in xrange(1, 6)] \n",
    "    for f in filenames:\n",
    "        if not tf.gfile.Exists(f):\n",
    "            raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "    # Create a queue that produces the filenames to read.\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "    # Read examples from files in the filename queue.\n",
    "    read_input = read_cifar10(filename_queue)\n",
    "    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "    height = IMAGE_SIZE\n",
    "    width = IMAGE_SIZE\n",
    "\n",
    "    # Image processing for training the network.  Note the many random\n",
    "    # distortions applied to the image.\n",
    "\n",
    "    # Randomly crop a [height, width] section of the image.\n",
    "    distorted_image = tf.random_crop(reshaped_image, [height, width, 3])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "\n",
    "    # Because these operations are not commutative, consider randomizing\n",
    "    # the order their operation.\n",
    "    distorted_image = tf.image.random_brightness(distorted_image,\n",
    "                                               max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(distorted_image,\n",
    "                                             lower=0.2, upper=1.8)\n",
    "\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    float_image = tf.image.per_image_standardization(distorted_image)\n",
    "\n",
    "    # Set the shapes of tensors.\n",
    "    float_image.set_shape([height, width, 3])\n",
    "    read_input.label.set_shape([1])\n",
    "\n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * min_fraction_of_examples_in_queue)\n",
    "    print('Filling queue with %d CIFAR images before starting to train. '\n",
    "         'This will take a few minutes.' % min_queue_examples)\n",
    "\n",
    "    # Generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(float_image, read_input.label,\n",
    "                                         min_queue_examples, batch_size,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images, labels = cifar10.distorted_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-60bcad50cbb0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-60bcad50cbb0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Image to image translation\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Image to image translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-aab1e3f1db43>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-aab1e3f1db43>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Plug and play generative networks\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Plug and play generative networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Condtional gan 종류 dense captioning\n",
    "\n",
    "Faster rcnn    squize       yolo     mask rcnn      sdd      squzeedet squeezeDETㅅ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
