{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf #tensorflow\n",
    "import numpy as np #numpy > save loss .. \n",
    "from collections import OrderedDict #layer ..\n",
    "import os, random #dir, random..\n",
    "import pickle #save & load\n",
    "import math #xavier..\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path\n",
    "#DATA_PATH = './cifar10/cifar-10-batches-py/' #python pickle\n",
    "DATA_PATH = './cifar10/cifar-10-batches-bin/' #binary\n",
    "CHECKPOINT = 'simple_res_net_0606.ckpt'\n",
    "SAVE_PATH = './checkpoint/res_0606/'\n",
    "BOARD_PATH = './tensorboard/board_res_0606/'\n",
    "TEST_FILE_PATH='./cifar10/cifar-10-batches-py/test_batch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "\n",
    "INPUT_SIDE = 32\n",
    "INPUT_SIZE = INPUT_SIDE * INPUT_SIDE\n",
    "N_CHANNEL = 3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1500\n",
    "LR = 0.1\n",
    "LR_DECAY_RATE = 0.5\n",
    "\n",
    "LABEL_BYTES = 1 \n",
    "NUM_EXAMPLES_PER_EPOCH = 50000 #NUMBER OF TRAIN DATA SET\n",
    "NUM_BATCHES_PER_EPOCH = NUM_EXAMPLES_PER_EPOCH / BATCH_SIZE\n",
    "NUM_TESTSET_PER_EPOCH = 10000\n",
    "NUM_TEST_BATCHES_PER_EPOCH = NUM_TESTSET_PER_EPOCH / BATCH_SIZE\n",
    "\n",
    "LIST_CLASS=['airplane', 'automobile', 'birds', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "N_CLASSES = len(LIST_CLASS)\n",
    "\n",
    "#loss & accuracy save\n",
    "TRAIN_OUT_FILE_NAME = 'RES_NET_CIFAR10_0606.log'\n",
    "train_loss_out = open('TRAIN_LOSS'+TRAIN_OUT_FILE_NAME, 'w')\n",
    "train_accr_out = open('TRAIN_ACCURACY'+TRAIN_OUT_FILE_NAME, 'w')\n",
    "\n",
    "TEST_OUT_FILE_NAME = 'RES_NET_CIFAR10_0606.log'\n",
    "test_loss_out = open('TEST_LOSS'+TEST_OUT_FILE_NAME, 'w')\n",
    "test_accr_out = open('TEST_ACCURACY'+TEST_OUT_FILE_NAME, 'w')\n",
    "\n",
    "print(\"input image size : {}\".format(INPUT_SIZE))\n",
    "print(\"image channel : {}\".format(N_CHANNEL))\n",
    "print(\"batch size : {}\".format(BATCH_SIZE))\n",
    "print(\"num of class : {}\".format(N_CLASSES))\n",
    "print(\"training epochs : {}\".format(EPOCHS))\n",
    "print(\"learning rate : {}\".format(LR))\n",
    "print(\"learning decay rate : {}\".format(LR_DECAY_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xavier initialization\n",
    "def xavier_init(n_inputs, n_outputs, uniform=True):\n",
    "    \"\"\"Set the parameter initialization using the method described.\n",
    "    This method is designed to keep the scale of the gradients roughly the same\n",
    "    in all layers.\n",
    "    Xavier Glorot and Yoshua Bengio (2010):\n",
    "           Understanding the difficulty of training deep feedforward neural\n",
    "           networks. International conference on artificial intelligence and\n",
    "           statistics.\n",
    "    Args:\n",
    "    n_inputs: The number of input nodes into each output.\n",
    "    n_outputs: The number of output nodes for each input.\n",
    "    uniform: If true use a uniform distribution, otherwise use a normal.\n",
    "    Returns:\n",
    "    An initializer.\n",
    "    \"\"\"\n",
    "    if uniform:\n",
    "        # 6 was used in the paper.\n",
    "        init_range = math.sqrt(6.0 / (n_inputs + n_outputs))\n",
    "        return tf.random_uniform_initializer(-init_range, init_range)\n",
    "    else:\n",
    "        # 3 gives us approximately the same limits as above since this repicks\n",
    "        # values greater than 2 standard deviations from the mean.\n",
    "        stddev = math.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "        return tf.truncated_normal_initializer(stddev=stddev)\n",
    "\n",
    "#CIFAR 데이터 읽어오기 \n",
    "def read_dataset(filename_queue):\n",
    "    class DataRecord(object):\n",
    "        pass\n",
    "    \n",
    "    result = DataRecord()\n",
    "    \n",
    "    label_bytes = LABEL_BYTES\n",
    "    result.height = INPUT_SIDE\n",
    "    result.width = INPUT_SIDE\n",
    "    result.depth = N_CHANNEL\n",
    "    image_bytes = result.height * result.width * result.depth\n",
    "    record_bytes = label_bytes + image_bytes\n",
    "    \n",
    "    reader = tf.FixedLengthRecordReader(record_bytes = record_bytes)\n",
    "    result.key, value = reader.read(filename_queue)\n",
    "    print (value)\n",
    "    record_bytes = tf.decode_raw(value, tf.uint8)\n",
    "    \n",
    "    result.label = tf.cast(tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32) #input, begin, end로 잘라냄 > 0~1\n",
    "    \n",
    "    depth_major = tf.reshape(tf.strided_slice(record_bytes, [label_bytes], # 1부터 image_bytes까지 image를 잘라낸 후 \n",
    "                                              [label_bytes + image_bytes]), #channel x height x width로 변환함.\n",
    "                             [result.depth, result.height, result.width])\n",
    "    \n",
    "    result.uint8image = tf.transpose(depth_major, [1,2,0]) #channel x height x width >>> height x width x chennl로 변경\n",
    "    \n",
    "    return result\n",
    "\n",
    "#label, image 세팅해줌 \n",
    "def _generate_image_and_label_batch(image, label, min_queue_examples,\n",
    "                                    batch_size, shuffle):\n",
    "    \"\"\"Construct a queued batch of images and labels.\n",
    "    Args:\n",
    "      image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "      label: 1-D Tensor of type.int32\n",
    "      min_queue_examples: int32, minimum number of samples to retain\n",
    "        in the queue that provides of batches of examples.\n",
    "      batch_size: Number of images per batch.\n",
    "      shuffle: boolean indicating whether to use a shuffling queue.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    # Create a queue that shuffles the examples, and then\n",
    "    # read 'batch_size' images + labels from the example queue.\n",
    "    num_preprocess_threads = 16 #프로세스 스레드 \n",
    "    if shuffle: #셔플 하면 \n",
    "        images, label_batch = tf.train.shuffle_batch([image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size,\n",
    "            min_after_dequeue=min_queue_examples) #이거만 해주면 batch와 동일함. \n",
    "    #Minimum number elements in the queue after a dequeue, used to ensure a level of mixing of elements.\n",
    "    else:\n",
    "        images, label_batch = tf.train.batch([image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "    # Display the training images in the visualizer.\n",
    "    tf.summary.image('images', images) #걍 보드용인듯\n",
    "\n",
    "    return images, tf.reshape(label_batch, [batch_size])\n",
    "\n",
    "\n",
    "def distorted_inputs(data_dir, batch_size): #좀 드럽게 인풋받아오기 \n",
    "    \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "    Args:\n",
    "      data_dir: Path to the CIFAR-10 data directory.\n",
    "      batch_size: Number of images per batch.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)] \n",
    "    for f in filenames:\n",
    "        if not tf.gfile.Exists(f):\n",
    "            raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "    # Create a queue that produces the filenames to read.\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "    # Read examples from files in the filename queue.\n",
    "    read_input = read_dataset(filename_queue)\n",
    "    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "    height = INPUT_SIDE\n",
    "    width = INPUT_SIDE\n",
    "\n",
    "    # Image processing for training the network.  Note the many random\n",
    "    # distortions applied to the image.\n",
    "\n",
    "    # Randomly crop a [height, width] section of the image.\n",
    "    distorted_image = tf.random_crop(reshaped_image, [height, width, 3]) # 랜덤으로 이미지를 크롭 h x w x c\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    distorted_image = tf.image.random_flip_left_right(distorted_image) # 또 랜덤으로 좌우 플립 random_flip_up_down도 있긴 함\n",
    "    #이런 느낌..? 으로 맥스텔타가지고 유니폼으로 어쩌구저쩌구\n",
    "    #delta = random_ops.random_uniform([], -max_delta, max_delta, seed=seed)\n",
    "    #return adjust_brightness(image, delta)\n",
    "\n",
    "    # Because these operations are not commutative, consider randomizing\n",
    "    # the order their operation.\n",
    "    distorted_image = tf.image.random_brightness(distorted_image,    #랜덤으로 밝기 조절 \n",
    "                                               max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(distorted_image,      #콘트라스트 조절 랜덤. 기존 픽셀값의 최소 0.2 최대 1.8\n",
    "                                             lower=0.2, upper=1.8)\n",
    "\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    float_image = tf.image.per_image_standardization(distorted_image) #표준화시킴. mean으로빼고 var로 나눔\n",
    "\n",
    "    # Set the shapes of tensors.\n",
    "    float_image.set_shape([height, width, 3])\n",
    "    read_input.label.set_shape([1])\n",
    "\n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH * min_fraction_of_examples_in_queue)\n",
    "    print('Filling queue with %d CIFAR images before starting to train. '\n",
    "         'This will take a few minutes.' % min_queue_examples)\n",
    "\n",
    "    # Generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(float_image, read_input.label,\n",
    "                                         min_queue_examples, batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "\n",
    "def inputs(eval_data, data_dir, batch_size):\n",
    "    \"\"\"Construct input for CIFAR evaluation using the Reader ops.\n",
    "    Args:\n",
    "    eval_data: bool, indicating if one should use the train or eval data set.\n",
    "    data_dir: Path to the CIFAR-10 data directory.\n",
    "    batch_size: Number of images per batch.\n",
    "    Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    if not eval_data:\n",
    "        filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n",
    "                     for i in xrange(1, 6)]\n",
    "        num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH\n",
    "    else:\n",
    "        filenames = [os.path.join(data_dir, 'test_batch.bin')]\n",
    "        num_examples_per_epoch = NUM_TESTSET_PER_EPOCH\n",
    "\n",
    "    for f in filenames:\n",
    "        if not tf.gfile.Exists(f):\n",
    "             raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "    # Create a queue that produces the filenames to read.\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "    # Read examples from files in the filename queue.\n",
    "    read_input = read_dataset(filename_queue)\n",
    "    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "    height = INPUT_SIDE\n",
    "    width = INPUT_SIDE\n",
    "\n",
    "    # Image processing for evaluation.\n",
    "    # Crop the central [height, width] of the image.\n",
    "    resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,\n",
    "                                                         height, width)\n",
    "\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    float_image = tf.image.per_image_standardization(resized_image)\n",
    "\n",
    "    # Set the shapes of tensors.\n",
    "    float_image.set_shape([height, width, 3])\n",
    "    read_input.label.set_shape([1])\n",
    "\n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH * min_fraction_of_examples_in_queue)\n",
    "\n",
    "    # Generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(float_image, read_input.label,\n",
    "                                         min_queue_examples, batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "\n",
    "print(\"FUNCTIONS READY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NETWORK PARAMETERS\n",
    "\n",
    "stddev = 0.1\n",
    "\n",
    "weights = {\n",
    "    #'conv' : tf.Variable(tf.random_normal([3, 3, N_CHANNEL, 16], stddev=stddev), name='conv'),\n",
    "    'conv' : tf.get_variable(name=\"conv\", shape=[3, 3, N_CHANNEL, 16], initializer=xavier_init(N_CHANNEL, 16)),\n",
    "    'conv1_1x1' : tf.get_variable(name=\"conv1_1x1\", shape=[1, 1, 16, 4], initializer=xavier_init(16, 4)),\n",
    "    'conv1_3x3' : tf.get_variable(name=\"conv1_3x3\", shape=[3, 3, 4, 4], initializer=xavier_init(4, 4)),\n",
    "    'conv1_1x1_16' : tf.get_variable(name=\"conv1_1x1_16\", shape=[1, 1, 4, 16], initializer=xavier_init(4, 16)),\n",
    "    'conv2_1x1' : tf.get_variable(name=\"conv2_1x1\", shape=[1, 1, 16, 4], initializer=xavier_init(16, 4)),\n",
    "    'conv2_3x3' : tf.get_variable(name=\"conv2_3x3\", shape=[3, 3, 4, 4], initializer=xavier_init(4, 4)),\n",
    "    'conv2_1x1_16' : tf.get_variable(name=\"conv2_1x1_16\", shape=[1, 1, 4, 16], initializer=xavier_init(4, 16)),\n",
    "    \n",
    "    # conv 16 + conv2 16 = 32filters \n",
    "    \n",
    "    'conv3_1x1' : tf.get_variable(name=\"conv3_1x1\", shape=[1, 1, 32, 8], initializer=xavier_init(32, 8)),\n",
    "    'conv3_3x3' : tf.get_variable(name=\"conv3_3x3\", shape=[3, 3, 8, 8], initializer=xavier_init(8, 8)),\n",
    "    'conv3_1x1_32' : tf.get_variable(name=\"conv3_1x1_32\", shape=[1, 1, 8, 32], initializer=xavier_init(8, 32)),\n",
    "    'conv4_1x1' : tf.get_variable(name=\"conv4_1x1\", shape=[1, 1, 32, 8], initializer=xavier_init(32, 8)),\n",
    "    'conv4_3x3' : tf.get_variable(name=\"conv4_3x3\", shape=[3, 3, 8, 8], initializer=xavier_init(8, 8)),\n",
    "    'conv4_1x1_32' : tf.get_variable(name=\"conv4_1x1_32\", shape=[1, 1, 8, 32], initializer=xavier_init(8, 32)),\n",
    "    \n",
    "    # conv2 지난거32 + conv4 32 = 64\n",
    "    \n",
    "    'conv5_1x1' : tf.get_variable(name=\"conv5_1x1\", shape=[1, 1, 64, 16], initializer=xavier_init(64, 16)),\n",
    "    'conv5_3x3' : tf.get_variable(name=\"conv5_3x3\", shape=[3, 3, 16, 16], initializer=xavier_init(16, 16)),\n",
    "    'conv5_1x1_64' : tf.get_variable(name=\"conv5_1x1_64\", shape=[1, 1, 16, 64], initializer=xavier_init(16, 64)),\n",
    "    'conv6_1x1' : tf.get_variable(name=\"conv6_1x1\", shape=[1, 1, 64, 16], initializer=xavier_init(64, 16)),\n",
    "    'conv6_3x3' : tf.get_variable(name=\"conv6_3x3\", shape=[3, 3, 16, 16], initializer=xavier_init(16, 16)),\n",
    "    'conv6_1x1_64' : tf.get_variable(name=\"conv6_1x1_64\", shape=[1, 1, 16, 64], initializer=xavier_init(16, 64)),\n",
    "    \n",
    "    #conv4 지난거 64 + conv6 64 = 128\n",
    "    \n",
    "    'dense1' : tf.get_variable(name=\"dense1\", shape=[16*16*128, 1000], initializer=xavier_init(16*16*128, 1000)),\n",
    "    'dense2' : tf.get_variable(name=\"dense2\", shape=[1000, N_CLASSES], initializer=xavier_init(1000, N_CLASSES)),   \n",
    "    'logit' : tf.get_variable(name=\"logit\", shape=[16*16*128, N_CLASSES], initializer=xavier_init(16*16*128, N_CLASSES))     \n",
    "}\n",
    "#conv net biases 현재 사용하지 않음. \n",
    "biases = {\n",
    "    'conv' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv_b')),\n",
    "    'conv1_1x1' : tf.Variable(tf.random_normal([4], stddev=stddev, name='conv1_1x1_b')),\n",
    "    'conv1_3x3' : tf.Variable(tf.random_normal([4], stddev=stddev, name='conv1_3x3_b')),\n",
    "    'conv1_1x1_16' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv1_1x1_16_b')),\n",
    "    'conv2_1x1' : tf.Variable(tf.random_normal([4], stddev=stddev, name='conv2_1x1_b')),\n",
    "    'conv2_3x3' :tf.Variable(tf.random_normal([4], stddev=stddev, name='conv2_3x3_b')),\n",
    "    'conv2_1x1_16' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv2_1x1_16_b')),\n",
    "    \n",
    "    'conv3_1x1' : tf.Variable(tf.random_normal([8], stddev=stddev, name='conv3_1x1_b')),\n",
    "    'conv3_3x3' : tf.Variable(tf.random_normal([8], stddev=stddev, name='conv3_3x3_b')),\n",
    "    'conv3_1x1_32' : tf.Variable(tf.random_normal([32], stddev=stddev, name='conv3_1x1_32_b')),\n",
    "    'conv4_1x1' : tf.Variable(tf.random_normal([8], stddev=stddev, name='conv4_1x1_b')),\n",
    "    'conv4_3x3' : tf.Variable(tf.random_normal([8], stddev=stddev, name='conv4_3x3_b')),\n",
    "    'conv4_1x1_32' : tf.Variable(tf.random_normal([32], stddev=stddev, name='conv4_1x1_32_b')),\n",
    "    \n",
    "    'conv5_1x1' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv5_1x1_b')),\n",
    "    'conv5_3x3' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv5_3x3_b')),\n",
    "    'conv5_1x1_64' : tf.Variable(tf.random_normal([64], stddev=stddev, name='conv5_1x1_64_b')),\n",
    "    'conv6_1x1' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv6_1x1_b')),\n",
    "    'conv6_3x3' : tf.Variable(tf.random_normal([16], stddev=stddev, name='conv6_3x3_b')),\n",
    "    'conv6_1x1_64' : tf.Variable(tf.random_normal([64], stddev=stddev, name='conv6_1x1_64_b')),\n",
    "    \n",
    "    'dense1' : tf.Variable(tf.random_normal([1000], stddev=stddev, name='dense1_b')),\n",
    "    'dense2' : tf.Variable(tf.random_normal([N_CLASSES], stddev=stddev, name='dense2_b'))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://blog.naver.com/PostView.nhn?blogId=skkong89&logNo=220710161978&parentCategoryNo=46&categoryNo=&viewDate=&isShowPopularPosts=false&from=postView\n",
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model\n",
    "#http://laonple.blog.me/220764986252 - bottleneck \n",
    "#conv 3x3\n",
    "#conv (1x1, 3x3, 1x1) - relu > 16\n",
    "#conv (1x1, 3x3, 1x1) relu > 32\n",
    "#conv (1x1, 3x3, 1x1) relu > 64\n",
    "#avg pooling \n",
    "#fc\n",
    "#softmax\n",
    "def ResNet(img_width, img_height, img_channel, _x, _w, _b, scope='ResNet', training=False):\n",
    "    network = OrderedDict() #network layers\n",
    "\n",
    "    # X RESHAPE\n",
    "    _x_r = tf.reshape(_x, shape=[-1,img_width,img_height, img_channel])\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        with tf.name_scope('conv') as scope:\n",
    "            conv = tf.nn.conv2d(_x_r, _w['conv'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv = tf.nn.bias_add(conv, _b['conv'])\n",
    "            #conv = batch_norm(conv, conv[0].shape[2], training)#배치노말라이제이션만 해주자 \n",
    "            #conv = tf.layers.batch_normalization(conv, training=training, name='bn_conv')\n",
    "            conv = tf.nn.relu(conv)\n",
    "            network['conv'] = conv\n",
    "        \n",
    "        #16\n",
    "        with tf.name_scope('conv2') as scope:\n",
    "            conv1_1x1 = tf.nn.conv2d(conv, _w['conv1_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv1_1x1 = tf.nn.bias_add(conv1_1x1, _b['conv1_1x1'])\n",
    "            conv1_1x1 = tf.nn.relu(conv1_1x1)\n",
    "            conv1_3x3 = tf.nn.conv2d(conv1_1x1, _w['conv1_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv1_3x3 = tf.nn.bias_add(conv1_3x3, _b['conv1_3x3'])\n",
    "            conv1_3x3 = tf.nn.relu(conv1_3x3)\n",
    "            conv1_1x1_16 = tf.nn.conv2d(conv1_3x3, _w['conv1_1x1_16'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv1_1x1_16 = tf.nn.bias_add(conv1_1x1_16, _b['conv1_1x1_16'])\n",
    "            #conv1_1x1_16 = batch_norm(conv1_1x1_16, conv1_1x1_16[0].shape[2], training)\n",
    "            #conv1_1x1_16 = tf.layers.batch_normalization(conv1_1x1_16, training=training, name='bn_conv1')\n",
    "            conv1_1x1_16 = tf.nn.relu(conv1_1x1_16)\n",
    "            network['conv1_1x1_16'] = conv1_1x1_16\n",
    "        \n",
    "        #16\n",
    "        with tf.name_scope('conv3') as scope:\n",
    "            conv2_1x1 = tf.nn.conv2d(conv1_1x1_16, _w['conv2_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv2_1x1 = tf.nn.bias_add(conv2_1x1, _b['conv2_1x1'])\n",
    "            conv2_1x1 = tf.nn.relu(conv2_1x1)\n",
    "            conv2_3x3 = tf.nn.conv2d(conv2_1x1, _w['conv2_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv2_3x3 = tf.nn.bias_add(conv2_3x3, _b['conv2_3x3'])\n",
    "            conv2_3x3 = tf.nn.relu(conv2_3x3)\n",
    "            conv2_1x1_16 = tf.nn.conv2d(conv2_3x3, _w['conv2_1x1_16'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv2_1x1_16 = tf.nn.bias_add(conv2_1x1_16, _b['conv2_1x1_16'])\n",
    "            #conv2_1x1_16 = batch_norm(conv2_1x1_16, conv2_1x1_16[0].shape[2], training)\n",
    "            #conv2_1x1_16 = tf.layers.batch_normalization(conv2_1x1_16, training=training, name='bn_conv2')\n",
    "            #print(conv2_1x1_16.shape)\n",
    "            #32\n",
    "            conv2_1x1_16 = tf.concat([conv, conv2_1x1_16], 3) \n",
    "            conv2_1x1_16 = tf.nn.relu(conv2_1x1_16)\n",
    "            network['conv2_1x1_16'] = conv2_1x1_16\n",
    "       \n",
    "        #print(conv2_1x1_16.shape)\n",
    "        #32       32 x 32 x 16+16 >>> \n",
    "        with tf.name_scope('conv4') as scope:\n",
    "            conv3_1x1 = tf.nn.conv2d(conv2_1x1_16, _w['conv3_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv3_1x1 = tf.nn.bias_add(conv3_1x1, _b['conv3_1x1'])\n",
    "            conv3_1x1 = tf.nn.relu(conv3_1x1)\n",
    "            conv3_3x3 = tf.nn.conv2d(conv3_1x1, _w['conv3_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv3_3x3 = tf.nn.bias_add(conv3_3x3, _b['conv3_3x3'])\n",
    "            conv3_3x3 = tf.nn.relu(conv3_3x3)\n",
    "            conv3_1x1_32 = tf.nn.conv2d(conv3_3x3, _w['conv3_1x1_32'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv3_1x1_32 = tf.nn.bias_add(conv3_1x1_32, _b['conv3_1x1_32'])\n",
    "            #conv3_1x1_32 = batch_norm(conv3_1x1_32, conv3_1x1_32[0].shape[2], training)\n",
    "            #conv3_1x1_32 = tf.layers.batch_normalization(conv3_1x1_32, training=training, name='bn_conv3')\n",
    "            conv3_1x1_32 = tf.nn.relu(conv3_1x1_32)\n",
    "            network['conv3_1x1_32'] = conv3_1x1_32\n",
    "        \n",
    "        with tf.name_scope('conv5') as scope:\n",
    "            conv4_1x1 = tf.nn.conv2d(conv3_1x1_32, _w['conv4_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv4_1x1 = tf.nn.bias_add(conv4_1x1, _b['conv4_1x1'])\n",
    "            conv4_1x1 = tf.nn.relu(conv4_1x1)\n",
    "            conv4_3x3 = tf.nn.conv2d(conv4_1x1, _w['conv4_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv4_3x3 = tf.nn.bias_add(conv4_3x3, _b['conv4_3x3'])\n",
    "            conv4_3x3 = tf.nn.relu(conv4_3x3)\n",
    "            conv4_1x1_32 = tf.nn.conv2d(conv4_3x3, _w['conv4_1x1_32'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv4_1x1_32 = tf.nn.bias_add(conv4_1x1_32, _b['conv4_1x1_32'])\n",
    "            #conv4_1x1_32 = batch_norm(conv4_1x1_32, conv4_1x1_32[0].shape[2], training)\n",
    "            #conv4_1x1_32 = tf.layers.batch_normalization(conv4_1x1_32, training=training, name='bn_conv4')\n",
    "\n",
    "            #64\n",
    "            conv4_1x1_32 = tf.concat([conv2_1x1_16, conv4_1x1_32 ], 3)\n",
    "            conv4_1x1_32 = tf.nn.relu(conv4_1x1_32)\n",
    "            network['conv4_1x1_32'] = conv4_1x1_32\n",
    "    \n",
    "        with tf.name_scope('conv6') as scope:\n",
    "            conv5_1x1 = tf.nn.conv2d(conv4_1x1_32, _w['conv5_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv5_1x1 = tf.nn.bias_add(conv5_1x1, _b['conv5_1x1'])\n",
    "            conv5_1x1 = tf.nn.relu(conv5_1x1)\n",
    "            conv5_3x3 = tf.nn.conv2d(conv5_1x1, _w['conv5_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv5_3x3 = tf.nn.bias_add(conv5_3x3, _b['conv5_3x3'])\n",
    "            conv5_3x3 = tf.nn.relu(conv5_3x3)\n",
    "            conv5_1x1_64 = tf.nn.conv2d(conv5_3x3, _w['conv5_1x1_64'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv5_1x1_64 = tf.nn.bias_add(conv5_1x1_64, _b['conv5_1x1_64'])\n",
    "            #conv5_1x1_64 = batch_norm(conv5_1x1_64, conv5_1x1_64[0].shape[2], training)\n",
    "            #conv5_1x1_64 = tf.layers.batch_normalization(conv5_1x1_64, training=training, name='bn_conv5')\n",
    "            conv5_1x1_64 = tf.nn.relu(conv5_1x1_64)\n",
    "            network['conv5_1x1_64'] = conv5_1x1_64\n",
    "        \n",
    "        with tf.name_scope('conv7') as scope:\n",
    "            conv6_1x1 = tf.nn.conv2d(conv5_1x1_64, _w['conv6_1x1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv6_1x1 = tf.nn.bias_add(conv6_1x1, _b['conv6_1x1'])\n",
    "            conv6_1x1 = tf.nn.relu(conv6_1x1)\n",
    "            conv6_3x3 = tf.nn.conv2d(conv6_1x1, _w['conv6_3x3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv6_3x3 = tf.nn.bias_add(conv6_3x3, _b['conv6_3x3'])\n",
    "            conv6_3x3 = tf.nn.relu(conv6_3x3)\n",
    "            conv6_1x1_64 = tf.nn.conv2d(conv6_3x3, _w['conv6_1x1_64'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "            #conv6_1x1_64 = tf.nn.bias_add(conv6_1x1_64, _b['conv6_1x1_64'])\n",
    "            #conv6_1x1_64 = batch_norm(conv6_1x1_64, conv6_1x1_64[0].shape[2], training)\n",
    "            #conv6_1x1_64 = tf.layers.batch_normalization(conv6_1x1_64, training=training, name='bn_conv6')\n",
    "            \n",
    "            #128\n",
    "            conv6_1x1_64 = tf.concat([conv4_1x1_32, conv6_1x1_64],3)\n",
    "            conv6_1x1_64 = tf.nn.relu(conv6_1x1_64)\n",
    "            network['conv6_1x1_64'] = conv6_1x1_64\n",
    "        \n",
    "        with tf.name_scope('pool') as scope:\n",
    "            pool = tf.nn.avg_pool(conv6_1x1_64, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "            network['pool'] = pool\n",
    "        \n",
    "        with tf.name_scope('dense1') as scope:\n",
    "            dense = tf.reshape(pool, [-1, _w['dense1'].get_shape().as_list()[0]])\n",
    "            dense1 = tf.add(tf.matmul(dense, _w['dense1']), _b['dense1'])\n",
    "            #dense1 = batch_norm(dense1, 1, training)\n",
    "            dense1 =  tf.layers.batch_normalization(dense1, training=training, name='bn_dense')\n",
    "            dense1 = tf.nn.relu(dense1)\n",
    "            network['dense1'] = dense1\n",
    "            \n",
    "        #with tf.name_scope('dropout') as scope:\n",
    "        #    if training:\n",
    "        #        dropout = tf.nn.dropout(dense1, 0.5, name='dropout')\n",
    "            \n",
    "        with tf.name_scope('logit') as scope:\n",
    "            logit = tf.add(tf.matmul(dense1, _w['dense2']), _b['dense2'])\n",
    "            network['logit'] = logit\n",
    "        \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATASET & CHECK LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = distorted_inputs(DATA_PATH, 64)\n",
    "\n",
    "#labels = tf.cast(labels, tf.float32)\n",
    "labels = tf.one_hot(indices=labels, depth=10, on_value=1, off_value=0, axis=1)\n",
    "\n",
    "print(labels.shape)\n",
    "\n",
    "out = ResNet(INPUT_SIDE, INPUT_SIDE, N_CHANNEL, images, weights, biases, 'ResNet', True)\n",
    "\n",
    "for key, value in out.items():\n",
    "    print (key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSS & OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=out['logit']))\n",
    "tf.summary.scalar(\"loss\", loss) #save loss \n",
    "print(\"LOSS FUNCTION\")\n",
    "\n",
    "#learning rate\n",
    "#global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "global_step = 0 #global_step: A scalar int32 or int64 Tensor or a Python number.  \n",
    "#글로벌 스텝을 텐서로 쓰려면 tf.contrib를 사용해야 할 것 같다.. \n",
    "#train_op = tf.contrib.training.create_train_op(total_loss, optimizer, global_step=global_step) 이런느낌? \n",
    "learning_rate = tf.train.exponential_decay(learning_rate=LR,\n",
    "                                           global_step=global_step,\n",
    "                                           decay_steps=300,\n",
    "                                           decay_rate=LR_DECAY_RATE,\n",
    "                                           staircase=True,\n",
    "                                           name=\"learning_rate\")\n",
    "learning_rate = tf.maximum(learning_rate, 0.0001)\n",
    "tf.summary.scalar(\"learning_rate\", learning_rate) #learning rate\n",
    "print(\"LERANING RATE : {}\".format(learning_rate))\n",
    "\n",
    "#optimizer\n",
    "adam = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "sgd = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "\n",
    "corr = tf.equal(tf.argmax(out['logit'], 1), tf.argmax(labels,1))\n",
    "accr = tf.reduce_mean(tf.cast(corr, \"float\"))\n",
    "tf.summary.scalar(\"accuracy\", accr) #save accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SESSION & SAVER & TENSORBOARD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SESSION INITIALIZE\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "#SAVER\n",
    "saver = tf.train.Saver(max_to_keep=3) #최근 3개까지만 저장\n",
    "save_step = 100 #save for 100 epoch\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "    \n",
    "#restore checkpoint\n",
    "checkpoint = tf.train.latest_checkpoint(SAVE_PATH)\n",
    "if checkpoint is not None:\n",
    "    print(checkpoint)\n",
    "    #saver.restore(sess, checkpoint)\n",
    "    \n",
    "#TENSOR BOARD\n",
    "summary_op = tf.summary.merge_all()\n",
    "summary_writer = tf.summary.FileWriter(BOARD_PATH, sess.graph)\n",
    "\n",
    "#QUEUE\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "\n",
    "print(\"initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "train_loss_for_plot = []\n",
    "train_acc_for_plot = []\n",
    "test_loss_for_plot = []\n",
    "test_acc_for_plot = []\n",
    "\n",
    "print('start')\n",
    "for epoch in range(EPOCHS):\n",
    "    print(epoch)\n",
    "    global_stop = epoch #lr decay\n",
    "    nNumBatch = 0 # batch 수\n",
    "    AvgBatchCost = 0 #cost 합산\n",
    "    \n",
    "    for i in range(int(NUM_BATCHES_PER_EPOCH)):\n",
    "        nNumBatch += 1\n",
    "        if epoch < EPOCHS * 0.5:\n",
    "            _, tmp_cost = sess.run([adam, loss])\n",
    "        else:\n",
    "            #print('use sgd')\n",
    "            _, tmp_cost = sess.run([sgd, loss])\n",
    "            \n",
    "        AvgBatchCost += tmp_cost\n",
    "    \n",
    "        if nNumBatch % 100 == 0:#print\n",
    "            train_acc = sess.run(accr)\n",
    "            print('\\t[%d nNumBatch] train cost = %g, acc = %g' %(nNumBatch, AvgBatchCost/nNumBatch, train_acc ))\n",
    "            lr = sess.run(learning_rate)\n",
    "            print('\\t\\t learning rate = %g'%(lr))\n",
    "            train_loss_for_plot.append(AvgBatchCost/nNumBatch)\n",
    "            train_acc_for_plot.append(train_acc)\n",
    "            \n",
    "    if epoch % 10 == 0: #test\n",
    "        save_path = saver.save(sess, SAVE_PATH + CHECKPOINT, global_step=epoch)\n",
    "        print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord.request_stop()\n",
    "coord.join(thresds)\n",
    "print('thread is stopped')\n",
    "sess.close()\n",
    "print('session closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
